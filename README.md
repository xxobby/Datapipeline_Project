# ì¸í„°ë„· ì‡¼í•‘ëª° ë¦¬ë·°ë¥¼ í†µí•œ NLPê°ì„±ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

1. [ì„œë¡ ](#11-í”„ë¡œì íŠ¸-ê°œìš”)
    1. [í”„ë¡œì íŠ¸ ê°œìš”](#11-í”„ë¡œì íŠ¸-ê°œìš”)
        1. [ì£¼ì œ ì„ ì • ë™ê¸°](#111-ì£¼ì œ-ì„ ì •-ë™ê¸°)
        2. [AS-IS, TO-BE](#112-as-is-to-be)
        3. [ê¸°ëŒ€ íš¨ê³¼](#113-ê¸°ëŒ€-íš¨ê³¼)
        4. [í”„ë¡œì íŠ¸ ì—­í•  ë¶„ë‹´](#114-í”„ë¡œì íŠ¸-ì—­í• -ë¶„ë‹´)
        5. [í”„ë¡œì íŠ¸ ì¼ì •](#115-í”„ë¡œì íŠ¸-ì¼ì •)
    2. [í”„ë¡œì íŠ¸ í™˜ê²½](#12-í”„ë¡œì íŠ¸-í™˜ê²½)
        1. [í™˜ê²½ êµ¬ì„±](#121-í™˜ê²½-êµ¬ì„±)
        2. [í™œìš© ë„êµ¬](#122-í™œìš©-ë„êµ¬)
2. [ë³¸ë¡ ](#21-ìˆ˜ìš”-ë¶„ì„)
    1. [ìˆ˜ìš” ë¶„ì„](#21-ìˆ˜ìš”-ë¶„ì„)
    2. [í”„ë¡œì„¸ìŠ¤ ë¶„ì„](#22-í”„ë¡œì„¸ìŠ¤-ë¶„ì„)
        1. [ì„œë¹„ìŠ¤ í”Œë¡œìš°](#221-ì„œë¹„ìŠ¤-í”Œë¡œìš°)
        2. [ê¸°ëŠ¥ í”Œë¡œìš°](#222-ê¸°ëŠ¥-í”Œë¡œìš°)
        3. [ë°ì´í„° í”Œë¡œìš°](#223-ë°ì´í„°-í”Œë¡œìš°)
        4. [ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­ ëª…ì„¸](#224-ì¸í”„ë¼-ìš”êµ¬ì‚¬í•­-ëª…ì„¸)
    3. [í”„ë¡œì„¸ìŠ¤ ì„¤ê³„](#23-í”„ë¡œì„¸ìŠ¤-ì„¤ê³„)
        1. [í”„ë¡œì„¸ìŠ¤ ì„¤ê³„](#231-í”„ë¡œì„¸ìŠ¤-ì„¤ê³„)
        2. [ì‹œìŠ¤í…œ êµ¬ì„±](#232-ì‹œìŠ¤í…œ-êµ¬ì„±)
        3. [Usecase ì‹œë‚˜ë¦¬ì˜¤](#233-usecase-ì‹œë‚˜ë¦¬ì˜¤)
        4. [ë°ì´í„° ì—°ë™ ê·œê²©](#234-ë°ì´í„°-ì—°ë™-ê·œê²©)
    4. [í”„ë¡œì„¸ìŠ¤ êµ¬í˜„](#24-í”„ë¡œì„¸ìŠ¤-êµ¬í˜„)
        1. [ì¸í”„ë¼ êµ¬í˜„](#241-ì¸í”„ë¼-êµ¬í˜„)
        2. [Usecase ì‹œë‚˜ë¦¬ì˜¤ ì‹œí–‰](#242-usecase-ì‹œë‚˜ë¦¬ì˜¤-ì‹œí–‰)
        3. [ì •ìƒ ì‘ë™í™•ì¸](#243-ì •ìƒ-ì‘ë™í™•ì¸)
3. [ê²°ë¡ ](#31-ê²°ê³¼ë¬¼-í™œìš©-ë°©ì•ˆ)
    1. [ê²°ê³¼ë¬¼ í™œìš© ë°©ë²•](#31-ê²°ê³¼ë¬¼-í™œìš©-ë°©ì•ˆ)
    2. [ë°œìƒ ë¬¸ì œ ë° í•´ê²° ë°©ì•ˆ](#32-ë°œìƒ-ë¬¸ì œì—ëŸ¬-ë°-í•´ê²°-ë°©ì•ˆ)
    3. [í”„ë¡œì íŠ¸ ê²°ê³¼ ë° í–¥í›„ ê°œì„ ì ](#33-í”„ë¡œì íŠ¸-ê²°ê³¼-ë°-í–¥í›„-ê°œì„ ì )

# 1.1. í”„ë¡œì íŠ¸ ê°œìš”


## 1.1.1. ì£¼ì œ ì„ ì • ë™ê¸°

ì‡¼í•‘ëª°ì˜ ìˆ˜ìµì„±ì„ ë†’ì´ê¸° ìœ„í•´ì„œ ì‡¼í•‘ëª° í”Œë«í¼ ìš´ì˜ìëŠ” ì†Œë¹„ì ë‹ˆì¦ˆë¥¼ íŒŒì•…í•˜ì—¬ ê³ ê°ì˜ ì œí’ˆ êµ¬ë§¤ë¥¼ ìœ ë„í•´ì•¼ í•œë‹¤. ë™ì‹œì— ìˆ˜ìš”ê°€ ë‚®ì€ ì œí’ˆì€ ì–´ë–¤ ë¶€ë¶„(ë°°ì†¡ ì„œë¹„ìŠ¤, ì œí’ˆ ìì²´ ë“±)ì—ì„œ ë¶€ì •ì ì¸ ë°˜ì‘ì´ ìƒì„±ë˜ì—ˆëŠ”ì§€ íŒŒì•…í•˜ì—¬ ë³´ì™„ì„ í•´ì•¼ í•œë‹¤. í•˜ì§€ë§Œ ì‡¼í•‘ëª° í”Œë«í¼ ìš´ì˜ìëŠ” ë‹¨ì‹œê°„ì— ë§ì€ ì†Œë¹„ìì˜ ë°˜ì‘ì„ ì¼ì¼ì´ í™•ì¸í•˜ê¸° í˜ë“¤ë‹¤.

ë”°ë¼ì„œ ë³¸ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë¨¸ì‹  ëŸ¬ë‹ì„ í†µí•´ í•™ìŠµí•œ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¦¬ë·° ê°ì„± ë¶„ì„ì„ ì§„í–‰í•˜ì—¬ íƒ€ê²Ÿ í‚¤ì›Œë“œë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•¨ìœ¼ë¡œì¨ ì‡¼í•‘ëª° í”Œë«í¼ ìš´ì˜ìê°€ ì§ì ‘ ë¦¬ë·°ë¥¼ ì½ì§€ ì•Šì•„ë„ ë‹¨ì‹œê°„ì— ìƒí’ˆì— ëŒ€í•œ ì†Œë¹„ì ë°˜ì‘ì„ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

## 1.1.2. AS-IS, TO-BE

**[ AS-IS ]**

![Untitled](img/Untitled.png)

ì˜¨ë¼ì¸ ì‡¼í•‘ëª° íŒë§¤ìê°€ ì‡¼í•‘ëª°ì˜ ìˆ˜ìµì„ ë†’ì´ê¸° ìœ„í•´ì„œëŠ” ê³ ê°ì˜ ë¦¬ë·°ë¥¼ ì½ê³  ë¶„ì„í•  í•„ìš”ê°€ ìˆë‹¤. í•˜ì§€ë§Œ íŒë§¤ ê¸°ê°„ì´ ê¸¸ì–´ì§ˆìˆ˜ë¡ ë¦¬ë·°ì˜ ê°œìˆ˜ëŠ” ì ì  ì¦ê°€í•  ê²ƒì´ê³  ê·¸ì— ë”°ë¼ ì‡¼í•‘ëª° íŒë§¤ìê°€ ê³ ê°ì˜ ë¦¬ë·°ë¥¼ ì¼ì¼íˆ ì½ê³  ì†Œë¹„ì ë°˜ì‘ì„ ë¶„ì„í•˜ëŠ” ê²ƒì€ ë”ìš± í˜ë“¤ì–´ì§ˆ ê²ƒì´ë‹¤.

![Untitled](img/Untitled%201.png)

íŒë§¤ìê°€ ë¦¬ë·°ë¥¼ ê°„ëµí•˜ê²Œ íŒŒì•…í•˜ê¸°ì— ìš©ì´í•œ ë°©ë²•ìœ¼ë¡œ ë³„ì ì´ ìˆì§€ë§Œ ë³„ì ê³¼ ì‹¤ì œ ë¦¬ë·°ê°„ì— ê°­ì´ ìƒë‹¹ìˆ˜ ì¡´ì¬í•˜ë©° ì´ëŸ¬í•œ ê°­ì€ ì‹¤ì œë¡œ íŒë§¤ìì—ê²Œ í˜¼ë™ì„ ì¤„ìˆ˜ ìˆëŠ” ìš”ì¸ì´ë‹¤.

**[ TO-BE ]**

![Untitled](img/Untitled%202.png)

ê³ ê° ì‡¼í•‘ëª°ì—ì„œ íŒë§¤í•˜ëŠ” ì œí’ˆì˜ ë¦¬ë·° ì¤‘ ì†Œë¹„ìê°€ ê¸ì •ì ì¸ ë°˜ì‘ì„ ë³´ì´ê³  ìˆëŠ” ë¦¬ë·°ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³ , ë¶€ì •ì ì¸ ë°˜ì‘ì„ ë³´ì´ê³  ìˆëŠ” ë¦¬ë·°ì˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ì†Œë¹„ìê°€ ì–´ë– í•œ ì´ìœ ë¡œ ê³ ê° ì‡¼í•‘ëª°ì˜ ì œí’ˆì„ êµ¬ì…í•˜ëŠ”ì§€ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. ë˜í•œ ë™ì¼ ì œí’ˆì„ íŒë§¤í•˜ê³  ìˆëŠ” íƒ€ì‚¬ì˜ ì‡¼í•‘ëª° ë¦¬ë·°ì—ì„œ ìì‚¬ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í‚¤ì›Œë“œ ê°œìˆ˜ë¥¼ ì¶”ì¶œí•˜ì—¬ ê³ ê° ì‡¼í•‘ëª°ê³¼ íƒ€ì‚¬ ì‡¼í•‘ëª°ì´ ì–´ë–¤ ì ì—ì„œ ì†Œë¹„ìë“¤ì˜ ë°˜ì‘ ì°¨ì´ê°€ ë°œìƒí•˜ê³  ìˆëŠ”ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ”ë‹¤. ë˜í•œ ë³„ì ê³¼ ë¦¬ë·° ì‚¬ì´ì˜ ê¸ë¶€ì • ë°˜ì‘ ê°­ì´ ì–¼ë§ˆë‚˜ ì¡´ì¬í•˜ëŠ”ì§€ íŒŒì•…í•˜ì—¬ ì‡¼í•‘ëª° ìš´ì˜ì„ ìœ„í•œ ì§€í‘œë¡œ ì œê³µí•˜ê³ ì í•œë‹¤.

## 1.1.3. ê¸°ëŒ€ íš¨ê³¼

**ì‚¬ìš©ì ì¸¡ë©´**
- ìƒí’ˆì— ëŒ€í•œ ì†Œë¹„ì ë°˜ì‘ì„ ë¶„ì„í•´ì„œ í‚¤ì›Œë“œë¡œ íŒŒì•…ì´ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
- íƒ€ê²Ÿ í‚¤ì›Œë“œë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•œ ë¦¬ì„œì¹˜ì‹œê°„ì„ ì¤„ì¸ë‹¤.

**ë¹„ì¦ˆë‹ˆìŠ¤ ì¸¡ë©´**
- ìƒí’ˆì— ëŒ€í•œ ì†Œë¹„ì ë°˜ì‘ì„ ë¶„ì„í•´ì„œ í‚¤ì›Œë“œë¡œ íŒŒì•…ì´ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.
- íƒ€ê²Ÿ í‚¤ì›Œë“œë¥¼ ì„¤ì •í•˜ê¸° ìœ„í•œ ë¦¬ì„œì¹˜ì‹œê°„ì„ ì¤„ì¸ë‹¤.

## 1.1.4. í”„ë¡œì íŠ¸ ì—­í•  ë¶„ë‹´

| ì´ë¦„ | ì§ì±… | ì—­í•  |
| --- | --- | --- |
| ë„íš¨ì£¼ | PM | í”„ë¡œì íŠ¸ ì „ì²´ ì¼ì • ê´€ë¦¬, ë¬¸ì„œ ì‘ì—…, ëŒ€ì‹œë³´ë“œ êµ¬í˜„ |
| ì„ ìš°ì§€í›ˆ | íŒ€ì› | í…ìŠ¤íŠ¸ ë°ì´í„° ì •ì œ ë° ì €ì¥, ëŒ€ì‹œë³´ë“œ êµ¬í˜„, ì¸í”„ë¼ êµ¬ì¶•(opensearch, logstash, kibana, kafka) |
| ì˜¤ìŠ¹ìš° | íŒ€ì› | í”„ë¡œì íŠ¸ ê°œìš” ê¸°íš, ëŒ€ì‹œë³´ë“œ êµ¬í˜„, ë°ì´í„° í”„ë ˆì„ êµ¬ì¶• |
| ì „ì¤‘ì„ | íŒ€ì› | ë°ì´í„° í¬ë¡¤ë§ ë° NLP ì²˜ë¦¬, ë°ì´í„° í”„ë ˆì„ êµ¬ì¶•, ì¸í”„ë¼ êµ¬ì¶•, ëŒ€ì‹œë³´ë“œ êµ¬í˜„ |

## 1.1.5. í”„ë¡œì íŠ¸ ì¼ì •

![Untitled](img/Untitled%203.png)

# 1.2. í”„ë¡œì íŠ¸ í™˜ê²½


## 1.2.1. í™˜ê²½ êµ¬ì„±

| Software | Reason for use |
| --- | --- |
| Virtual Box | Window í™˜ê²½ì—ì„œ Ubuntu í™˜ê²½ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ì„¤ì¹˜í•œ
ê°€ìƒí™” ì†Œí”„íŠ¸ì›¨ì–´ |
| Windows Terminal | ëª…ë ¹ì¤„ ì…¸ì— ëŒ€í•œ í˜¸ìŠ¤íŠ¸ ì• í”Œë¦¬ì¼€ì´ì…˜ |
| Vscode | ì½”ë“œ ì…ë ¥ì„ ìš©ì´í•˜ê²Œ í•´ì£¼ëŠ” ì†ŒìŠ¤ ì½”ë“œ ì—ë””í„° |
| Ubuntu | ë¦¬ëˆ…ìŠ¤ ì‹œìŠ¤í…œ ìë™í™”ì— ì í•©í•œ OS |

## 1.2.2. í™œìš© ë„êµ¬

| Software | Reason for use |
| --- | --- |
| Python | ì‚¬ìš©ì ì‡¼í•‘ëª° ëŒ“ê¸€ ì¶”ì¶œ ë° ìì—°ì–´ ì²˜ë¦¬ì— ì‚¬ìš©ë˜ëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ |
| AWS CLI | Amazon ì„œë¹„ìŠ¤ í†µí•© ê´€ë¦¬ (AWS EKS) |
| Terraform | í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë”ì— IaC ë°°í¬ ìë™í™” |
| Docker | í¬ë¡¤ë§ íŒŒë“œ ì´ë¯¸ì§€ ìƒì„± |
| Amazon EKS | AWS ìƒì—ì„œ ì»¨í…Œì´ë„ˆí™” ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ê´€ë¦¬ ìë™í™” |
| ChromeDriver | ì‡¼í•‘ëª° ëŒ“ê¸€ ì¶”ì¶œ ì‹œ ëœë”ë§ ë˜ëŠ” ì›¹ ë“œë¼ì´ë²„ |
| Kafka | ì‡¼í•‘ëª° ì¶”ì¶œ ëŒ“ê¸€ ìœ ì‹¤ ë°©ì§€ |
| CUDA | GPUì˜ ê°€ìƒ ëª…ë ¹ì–´ì…‹ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì£¼ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ë ˆì´ì–´ |
| cuDNN | ì‹¬ì¸µ ì‹ ê²½ë§ì„ ìœ„í•œ GPU ê°€ì† í”„ë¦¬ë¯¸í‹°ë¸Œ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| Anaconda | ê³¼í•™ ì—°êµ¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì•¼ì— ì í•©í•œ Python ë° R ì–¸ì–´ì˜ íŒ¨í‚¤ì§€/ì˜ì¡´ì„± ê´€ë¦¬ ë° ë°°í¬ë¥¼ í¸ë¦¬í•˜ê²Œ í•´ì£¼ëŠ” íŒ¨í‚¤ì§€ ê´€ë¦¬ì |
| Jupyter Notebook | íƒìƒ‰ì  ë°ì´í„° ë¶„ì„, ë°ì´í„° ì •ë¦¬ ë° ë³€í™˜, ë°ì´í„° ì‹œê°í™”, í†µê³„ì  ëª¨ë¸ë§, ë¨¸ì‹  ëŸ¬ë‹, ë”¥ëŸ¬ë‹ ë“±ì˜ ê°ì¢… ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤ ë¬¸ì„œ ìƒì„± ì• í”Œë¦¬ì¼€ì´ì…˜ |
| tensorflow | ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¤‘ í•˜ë‚˜ì´ë©° Pythonì„ í™œìš©í•˜ì—¬ ì—°ì‚°ì²˜ë¦¬ ì‘ì„± |
| mecab | ì¼ë³¸ì–´ì™€ í•œêµ­ì–´ì˜ ìœ ì‚¬ì ìœ¼ë¡œ í•œê¸€ ë¶„ì„ì—ë„ ë™ì‘í•˜ëŠ” ê²ƒì„ í™•ì¸í•˜ê³  ê°œë°œí•œ í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° |
| Opensearch | ì‡¼í•‘ëª° ëŒ“ê¸€ ë°ì´í„°, ê°ì„± ë¶„ì„ ê²°ê³¼ ë°ì´í„° ì ì¬ |
| Logstash | - Kafkaì— ì €ì¥ëœ ë°ì´í„° ìˆ˜ì§‘ (Consumer), ì‡¼í•‘ëª° ëŒ“ê¸€ ë°ì´í„° ì •ì œ ë° ì¸ë±ì‹± |
| Kibana | ëŒ“ê¸€ ê°ì„± ë¶„ì„ ê²°ê³¼ ì‹œê°í™” |

# 2.1. ìˆ˜ìš” ë¶„ì„


í•´ë‹¹ ì„œë¹„ìŠ¤ëŠ” íŠ¹ì • ì‡¼í•‘ëª°ì— ì…ì í•´ìˆëŠ” ì‚¬ì—…ì, ì‡¼í•‘ëª° ì œì‘ ì†”ë£¨ì…˜ ì—…ì²´ë‚˜ ê°œì¸ ì‡¼í•‘ëª°ì„ ìš´ì˜í•˜ëŠ” ì‚¬ì—…ìë“¤ì„ ì†Œë¹„ìë¡œ ì„ ì •í•œë‹¤. 

### ì‹œì¥ë¶„ì„

2021ë…„ ì´ì»¤ë¨¸ìŠ¤ ì‹œì¥ ê·œëª¨ëŠ” ì•½ 186ì¡° ì›ìœ¼ë¡œ ì „ë…„ ëŒ€ë¹„ ì•½ 15% ì¦ê°€í–ˆë‹¤. ë¹„ëŒ€ë©´ ì†Œë¹„ì˜ í™•ì¥, ì´ì»¤ë¨¸ìŠ¤ ì‚°ì—…ì˜ ë°œì „ë“±ìœ¼ë¡œ ì„±ì¥ ì¶”ì´ëŠ” ì§€ì†ë  ê²ƒìœ¼ë¡œ ì „ë§ëœë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-08-04 á„‹á…©á„’á…® 1.41.13.png](img/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2022-08-04_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.41.13.png)

ì´ì»¤ë¨¸ìŠ¤ ì—…ì¢… ê´‘ê³ ë¹„ëŠ” ì „ë…„ ëŒ€ë¹„ 1,230ì–µì´ ì¦ê°€í–ˆë‹¤. ë¬´ì‹ ì‚¬, ì˜¬ë¦¬ë¸Œì˜ ê³¼ ê°™ì€ ì•ˆì •ì ì¸ ë§¤ì¶œê³¼ ê³ ê°ì„ í™•ë³´í•œ ì „ë¬¸ ì‡¼í•‘ëª°ë“¤ì´ ì¹´í…Œê³ ë¦¬ë¥¼ í™•ì¥í•´ ë‚˜ê°€ë©´ì„œ ì‚¬ì—…ê·œëª¨ë¥¼ í™•ëŒ€í•˜ê³  ìˆê³  ì ì  ê²½ìŸì´ ì¹˜ì—´í•´ì§€ëŠ” ì¤‘ì´ë‹¤.

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-08-04 á„‹á…©á„’á…® 1.43.06.png](img/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2022-08-04_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.43.06.png)

ì´ì»¤ë¨¸ìŠ¤ ì†Œë¹„ìë“¤ì„ ëŒ€ìƒìœ¼ë¡œ í•œ ì¡°ì‚¬ë¥¼ ì§„í–‰

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-08-04 á„‹á…©á„’á…® 1.45.42.png](img/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2022-08-04_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.45.42.png)

ì§„í–‰ ê²°ê³¼ ì´ì»¤ë¨¸ìŠ¤ ì†Œë¹„ìë“¤ì´ ê°€ì¥ í¬ê²Œ ê´€ì‹¬ì„ ê°–ëŠ” ì •ë³´ëŠ” êµ¬ì…,ë°°ì†¡ í›„ê¸°ì˜€ê³  ì£¼ ì´ìš© ì˜¨ë¼ì¸ ì‡¼í•‘ ì±„ë„ì€ ë„¤ì´ë²„ì™€ ì¿ íŒ¡ì„ ê°€ì¥ ë§ì´ ì´ìš©í–ˆë‹¤. (ì—°ë ¹ëŒ€ë³„ë¡œ ë‹¤ì†Œ ì°¨ì´ê°€ ì¡´ì¬í•¨)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-08-04 á„‹á…©á„’á…® 1.46.45.png](img/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2022-08-04_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.46.45.png)

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-08-04 á„‹á…©á„’á…® 1.47.32.png](img/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2022-08-04_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.47.32.png)

ì‡¼í•‘ ì±„ë„ ì£¼ ì„ íƒ ìš”ì¸ì€ ê°€ê²©ê³¼ ì‚¬ìš©í›„ê¸°ë¡œ ì†Œë¹„ìë“¤ì€ ì˜¨ë¼ì¸ ì‡¼í•‘ ì±„ë„ì„ ì„ íƒí• ë•Œ ê°€ê²©ê³¼ ì‚¬ìš©í›„ê¸°ë¥¼ ì£¼ì˜ê¹Šê²Œ ë³´ëŠ” ê²ƒì„ í™•ì¸í• ìˆ˜ ìˆì—ˆë‹¤. 

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-08-04 á„‹á…©á„’á…® 1.48.40.png](img/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2022-08-04_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.48.40.png)

ì¶”ê°€ë¡œ ì˜¨ë¼ì¸ì—ì„œ êµ¬ë§¤í•˜ëŠ” ì œí’ˆì˜ ì •ë³´ëŠ” ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ê³¼ í¬í„¸ì‚¬ì´íŠ¸ì—ì„œ íšë“í•¨ 

ì˜¨ë¼ì¸ êµ¬ë§¤ì‹œ ì‡¼í•‘ëª°ì—ì„œ ì¦‰ì‹œ íƒìƒ‰í•˜ëŠ” ê²½ìš°ê°€ ê°€ì¥ ë§ì•˜ê³  í•´ë‹¹ ì •ë³´ì¤‘ ê°€ì¥ ì‹ ë¢°í•˜ëŠ” ë¶€ë¶„ì€ í›„ê¸°, ë¦¬ë·°

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-08-04 á„‹á…©á„’á…® 1.50.04.png](img/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2022-08-04_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_1.50.04.png)

ì´ì²˜ëŸ¼ ì´ì»¤ë¨¸ìŠ¤ ì‹œì¥ì˜ ê¸‰ì† ì„±ì¥ê³¼ ë™ì‹œì— í•´ë‹¹ ì‹œì¥ì˜ ê²½ìŸì´ ì¹˜ì—´í•´ì§€ê³  ìˆë‹¤. ì†Œë¹„ìë“¤ì´ ì œí’ˆ êµ¬ë§¤ì‹œ ê°€ì¥ í¬ê²Œ ì˜í–¥ì„ ë°›ëŠ” ë¦¬ë·°ë¥¼ ê´€ë¦¬í•˜ëŠ” ì „ëµìœ¼ë¡œ ê²½ìŸì—ì„œì˜ ìš°ìœ„ë¥¼ ì í• ìˆ˜ ìˆë‹¤.

# 2.2. í”„ë¡œì„¸ìŠ¤ ë¶„ì„


## 2.2.1. ì„œë¹„ìŠ¤ í”Œë¡œìš°


![Untitled](img/Untitled%204.png)

## **ì‡¼í•‘ëª° ëŒ“ê¸€ ë¶„ì„ ìš”ì²­í•˜ê¸°**

1. ì‚¬ìš©ìê°€ ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ëŒ“ê¸€ ë¶„ì„ì„ ìš”ì²­í•œë‹¤.
2. ì—”ì§€ë‹ˆì–´ëŠ” í¬ë¡¤ëŸ¬ì—ê²Œ ì‚¬ìš©ì ì‡¼í•‘ëª°ì˜ ëŒ“ê¸€ ì¶”ì¶œì„ ìš”ì²­í•œë‹¤.
3. í¬ë¡¤ëŸ¬ëŠ” ì‚¬ìš©ìì˜ ì‡¼í•‘ëª°ì— ì ‘ê·¼í•œì—¬ ëŒ“ê¸€, ë³„ì , ì‘ì„±ì¼ìë¥¼ ì¶”ì¶œí•œë‹¤.
4. í¬ë¡¤ëŸ¬ëŠ” ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ì¹´í”„ì¹´ ë¸Œë¡œì»¤ì˜ í† í”½ì— ì €ì¥í•œë‹¤.

## **ì‡¼í•‘ëª° ëŒ“ê¸€ ë°ì´í„° ì •ì œ ë° ì €ì¥í•˜ê¸°**

1. í† í”½ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ê³  JSON í¬ë©§ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
2. ì •ì œëœ ë°ì´í„°ë¥¼ ì¸ë±ì‹±í•˜ì—¬ ë°ì´í„° ì ì¬ ì„œë²„(Opensearch)ì— ì €ì¥í•œë‹¤.

## **ì‡¼í•‘ëª° ëŒ“ê¸€ NLP ì²˜ë¦¬**

1. GRUë¥¼ ì‚¬ìš©í•˜ì—¬ ìì‚¬Â·íƒ€ì‚¬Â·ìœ ì‚¬ ì‡¼í•‘ ë¦¬ë·° ê°ì„± ë¶„ë¥˜ë¥¼ ì§„í–‰í•œë‹¤.
2. ë°ì´í„° ì ì¬ ì„œë²„ì— ì €ì¥ ëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ ìì—°ì–´ ì²˜ë¦¬ë¥¼ í•œë‹¤.
3. ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ë°ì´í„° ì ì¬ ì„œë²„ì— ì €ì¥í•œë‹¤.

## **ë¶„ì„ ê²°ê³¼ ì‹œê°í™”**

1. ì €ì¥ ëœ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ í˜•íƒœë¡œ ì‹œê°í™”í•œë‹¤.
2. ì‚¬ìš©ìì—ê²Œ í•´ë‹¹ ëŒ€ì‹œë³´ë“œì˜ ì£¼ì†Œë¥¼ ì œê³µí•œë‹¤

## 2.2.2 ê¸°ëŠ¥ í”Œë¡œìš°


![Untitled](img/Untitled%205.png)

![Untitled](img/Untitled%206.png)

![Untitled](img/Untitled%207.png)

### **ì‡¼í•‘ëª° URL í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**

í¬ë¡¤ë§ íŒŒë“œ ìƒì„± ì‹œ, ì‡¼í•‘ëª° URLì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•˜ì—¬ í¬ë¡¤ë§í•  ì‡¼í•‘ëª°ì„ ì§€ì •í•œë‹¤.

### **í¬ë¡¤ë§**

í¬ë¡¤ëŸ¬ íŒŒë“œëŠ” ì§€ì • ëœ ì‡¼í•‘ëª°ì˜ ëŒ“ê¸€ ë°ì´í„°(ë³„ì , ëŒ“ê¸€, ì‘ì„±ì¼ì)ë¥¼ ì¶”ì¶œí•œ ë‹¤. ì¶”ì¶œëœ ë°ì´í„°ëŠ” íì‰ ì„œë²„ì˜ ê° í† í”½ìœ¼ë¡œ ì „ì†¡í•œë‹¤.

### **í† í”½ ë³„ ë°ì´í„° Queueing**

ë°ì´í„°ë¥¼ íì‰ ì„œë²„ì— ì €ì¥í•˜ê²Œ ë˜ë©´ ë°ì´í„°ì˜ ìœ ì‹¤ì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. ê° ì œí’ˆ ë³„ë¡œ í† í”½ì´ ìƒì„±ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— í¬ë¡¤ëŸ¬ íŒŒë“œëŠ” ìì‹ ì˜ ì œí’ˆì— í•´ë‹¹í•˜ëŠ” í† í”½ì— ë°ì´í„°ë¥¼ ì „ì†¡í•œë‹¤.

### **ë°ì´í„° ì •ì œ**

ë°ì´í„° ì •ì œ ì„œë²„ëŠ” (ì–´ë–¤ í† í”½ì¸ì§€ ë” ìì„¸í•˜ê²Œ)í† í”½ì„ êµ¬ë…í•˜ê³  ìˆë‹¤ê°€ í† í”½ì— ëŒ“ê¸€ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ë°ì´í„°ë¥¼ ëŒì–´ì™€ íŠ¹ìˆ˜ ë¬¸ìë¥¼ ì œê±°í•˜ê³  í•´ë‹¹ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•˜ëŠ” í˜•íƒœë¡œ ì¸ë±ì‹±í•œ ë‹¤ìŒ JSON í¬ë©§ìœ¼ë¡œ ë³€í™˜í•œë‹¤.

### **ë°ì´í„° ì ì¬**

ì •ì œë¥¼ ë§ˆì¹œ ë°ì´í„°ëŠ” ë°ì´í„° ì ì¬ ì„œë²„ë¡œ ì „ì†¡ëœë‹¤.

### **Slack ì•ŒëŒ**

ë°ì´í„° ì ì¬ ì„œë²„ì— ë°ì´í„°ê°€ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ë©´ Slackì— ì ì¬ ì™„ë£Œ ì•Œë¦¼ì´ ì „ì†¡ëœë‹¤.

### **ML ìì—°ì–´ ì²˜ë¦¬**

ë°ì´í„° ì ì¬ ì„œë²„ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ìì—°ì–´ ì²˜ë¦¬(Word2Vec, Word Cloud, ê°ì„± ë¶„ì„, ë¶„ì„ ì •í™•ë„, ë‹¨ì–´ ê°„ ìœ ì‚¬ë„)ë¥¼ ì§„í–‰í•œë‹¤.

### **ì²˜ë¦¬ ê²°ê³¼ ì €ì¥**

ìì—°ì–´ ì²˜ë¦¬ ê²°ê³¼ë¥¼ ë°ì´í„° ì ì¬ ì„œë²„ì— ì €ì¥í•œë‹¤.

### **ì‹œê°í™” (ëŒ€ì‹œë³´ë“œ)**

ë°ì´í„° ì ì¬ ì„œë²„ì—ì„œ ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ ì „ì†¡ ë°›ì•„ íƒ€ê²Ÿ í‚¤ì›Œë“œë¥¼ ë‹¤ì–‘í•œ ì°¨íŠ¸(Stackbar, Markdown, Data Table ë“±)ë¥¼ í†µí•´ ë‚˜íƒ€ë‚¸ë‹¤.

## 2.2.3. ë°ì´í„° í”Œë¡œìš°


![Untitled](img/Untitled%208.png)

HTML í¬ë©§ ì‡¼í•‘ëª° ëŒ“ê¸€ì€ íŒŒì´ì¬ í¬ë¡¤ëŸ¬ì— ì˜í•´ ì¶”ì¶œ ë˜ì–´ ì¼ë ¬ì˜ JSON í¬ë©§ìœ¼ë¡œ ë³€í™˜ë˜ê³ , ì´ ë°ì´í„°ê°€ Logstashë¥¼ ê±°ì¹˜ë©´ì„œ ì¸ë±ì‹± ë° ì •ì œê°€ ë˜ì–´ multi-row í˜•íƒœì˜ JSON í¬ë©§ìœ¼ë¡œ ë³€í™˜ëœë‹¤.

## 2.2.4. ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­ ëª…ì„¸


## ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­ ê°œìš”

[Google Docs - ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­ ê°œìš”](https://docs.google.com/spreadsheets/d/1AvcnUb9na_x5Q2_Ze3zOfuonSRSo6wXi8fp-E4ITsbY/edit#gid=1931931552)

## ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­ ëª…ì„¸

[Google Docs - ì¸í”„ë¼ ìš”êµ¬ì‚¬í•­ ëª…ì„¸](https://docs.google.com/spreadsheets/d/1AvcnUb9na_x5Q2_Ze3zOfuonSRSo6wXi8fp-E4ITsbY/edit#gid=1058604997)

# 2.3. í”„ë¡œì„¸ìŠ¤ ì„¤ê³„

### 2.3.1. í”„ë¡œì„¸ìŠ¤ ì„¤ê³„

![Untitled](img/Untitled%209.png)

## 2.3.2. ì‹œìŠ¤í…œ êµ¬ì„±

## ğŸƒ Python Crawler

> **í¬ë¡¤ëŸ¬ ìƒì„± ì‹œ ì‚¬ìš©í•œ ì´ë¯¸ì§€**
> 

ì›í•˜ëŠ” Crawler ê·œê²©ì— ë§ëŠ” Docker ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ ë°°í¬ì— ì‚¬ìš©í•œë‹¤.

- **ì´ë¯¸ì§€** : ddung1203/kafkacrawler:10
    - OS : Ubuntu 20.04

[Docker Hub](https://hub.docker.com/repository/docker/ddung1203/kafkacrawler)

> **ì†Œí”„íŠ¸ì›¨ì–´ ë²„ì „**
> 

í¬ë¡¤ëŸ¬ ì´ë¯¸ì§€ì— ì„¤ì¹˜ë˜ì–´ìˆëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ë²„ì „

| Software | Version |
| --- | --- |
| Python3 | 3.8 |
| Python3-pip | 20.0.2 |
| Selenium | 4.3.8 |
| Chrome Driver | 103.0.5060.134 |

## ğŸƒ Kafka

> **ì†Œí”„íŠ¸ì›¨ì–´ ë²„ì „**
> 

ì‚¬ìš©ì ì„œë²„ì— ì„¤ì¹˜ë˜ì–´ ìˆëŠ” Kafka ì†Œí”„íŠ¸ì›¨ì–´ ë²„ì „

| Software | Version |
| --- | --- |
| Ubuntu | Amazon Linux 5.10 |
| Open-jdk | 1.8.0 |
| kafka | kafka_2.12-2.5.0 |

## ğŸƒ Jupyter Notebook

> **ì†Œí”„íŠ¸ì›¨ì–´ ë²„ì „**
> 

ì‚¬ìš©ì ì„œë²„ì— ì„¤ì¹˜ë˜ì–´ìˆëŠ” Jupyter Notebook ê´€ë ¨ ì†Œí”„íŠ¸ì›¨ì–´ ë²„ì „

| Software | Version |
| --- | --- |
| Ubuntu | 20.04 |
| CUDA | 11.2 |
| cuDNN | 8.1 |
| Anaconda | 4.13.0 |
| Python | 3.9.12 |

> **í”„ë¡œê·¸ë¨ ëª¨ë“ˆ ë²„ì „**
> 

| Module | Descriptions |
| --- | --- |
| re | ì¼ì¹˜í•˜ëŠ” ë¬¸ìì—´ ì§‘í•© ì§€ì • |
| pandas | ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| numpy | í–‰ë ¬ì´ë‚˜ ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ê·œëª¨ ë‹¤ì°¨ì› ë°°ì—´ì„ ì‰½ê²Œ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| matplotlib.pyplot | MATLABê³¼ ë¹„ìŠ·í•˜ê²Œ ëª…ë ¹ì–´ ìŠ¤íƒ€ì¼ë¡œ ë™ì‘í•˜ëŠ” í•¨ìˆ˜ì˜ ëª¨ìŒ |
| boto3 | Amazon EC2 ë° Amazon S3ì™€ ê°™ì€ AWS ì„œë¹„ìŠ¤ë¥¼ ìƒì„±, êµ¬ì„± ë° ê´€ë¦¬ |
| smart_open | S3, HDFS, WebHDFS ë˜ëŠ” ë¡œì»¬ íŒŒì¼ ê°„ì— í° íŒŒì¼ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë° í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| Mecab | ì˜¤í”ˆ ì†ŒìŠ¤ í˜•íƒœì†Œ ë¶„ì„ ì—”ì§„ì¸ MeCabì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ì„ í•˜ê¸° ìœ„í•œ í”„ë¡œì íŠ¸ |
| train_test_split | ì‚¬ì´í‚·ëŸ°(scikit-learn)ì˜ model_selection íŒ¨í‚¤ì§€ ì•ˆì— train_test_split ëª¨ë“ˆì†ì‰½ê²Œ train setê³¼ test setì„ ë¶„ë¦¬ |
| tensorflow | ë‹¤ì–‘í•œ ì‘ì—…ì—ëŒ€í•´ ë°ì´í„° íë¦„ í”„ë¡œê·¸ë˜ë°ì„ ìœ„í•œ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| Elasticsearch | Elastic Searchì˜ ê³µì‹ í•˜ìœ„ í´ë¼ì´ì–¸íŠ¸íŒŒì´ì¬ì˜ ëª¨ë“  Elastic search ê´€ë ¨ ì½”ë“œë¥¼ ìœ„í•œ ê³µí†µ ê¸°ë°˜ì„ ì œê³µ |
| json_normalize | ë°˜êµ¬ì¡°í™”ëœ JSON ë°ì´í„°ë¥¼ ì¼ì°¨ì› í‘œë¡œ ì •ê·œí™” |
| datetime | ë‚ ì§œì™€ ì‹œê°„ì„ ì¡°ì‘í•˜ëŠ” í´ë˜ìŠ¤ |

## ğŸƒ ELK Stack

ELK ìŠ¤íƒì€ EKS ìœ„ì— DockerHubì— ì—…ë¡œë“œ ë˜ì–´ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°í¬í•œë‹¤.

- **Logstash ì´ë¯¸ì§€ :** docker.elastic.co/logstash/logstash:7.10.2
- **Opensearch ì´ë¯¸ì§€** : opendistro-for-elasticsearch:1.13.2
- **Kibana ì´ë¯¸ì§€** : tjswl950/ek_kib01:pluginRemove

## 2.3.3. Usecase ì‹œë‚˜ë¦¬ì˜¤

## ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­

[Google Docs - ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­](https://docs.google.com/spreadsheets/d/1AvcnUb9na_x5Q2_Ze3zOfuonSRSo6wXi8fp-E4ITsbY/edit#gid=899949135)

## ë°ì´í„° ìš”êµ¬ì‚¬í•­

[Google Docs - ë°ì´í„° ìš”êµ¬ì‚¬í•­](https://docs.google.com/spreadsheets/d/1AvcnUb9na_x5Q2_Ze3zOfuonSRSo6wXi8fp-E4ITsbY/edit#gid=799061625)

## 2.3.4. ë°ì´í„° ì—°ë™ ê·œê²©

**Crawler - Kafka ì—°ë™ ê·œê²©**

**[ Python Crawler ]**

ì¸í„°ë„· ì‡¼í•‘ëª° ë¦¬ë·°ë¥¼ í¬ë¡¤ë§í•œ í›„ JSON(Dictionary) í˜•íƒœë¡œ ì €ì¥í•˜ê³  ì§€ì •í•œ Kafkaì˜ Topicìœ¼ë¡œ ì „ì†¡í•˜ëŠ”ë° ì‚¬ìš©í•œë‹¤.

![Untitled](img/Untitled%2010.png)

**Kafka - Opensearch ì—°ë™ ê·œê²©**

**[ Inbound ]**

Kafkaì—ì„œ Logstashë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•  ë•Œ ì‚¬ìš©í•œë‹¤.

![Untitled](img/Untitled%2011.png)

```yaml
input {
      kafka {
        bootstrap_servers => "ì¹´í”„ì¹´ ë¸Œë¡œì»¤ ì„œë¹„ìŠ¤ DNS ì£¼ì†Œ" 
        topics => [í† í”½ ì´ë¦„ ë¦¬ìŠ¤íŠ¸]
        consumer_threads => 3
        isolation_level => "read_committed"
        value_deserializer_class => "org.apache.kafka.common.serialization.StringDeserializer"
        auto_offset_reset => "earliest"
        group_id => "smartstore"
      }
    }
```

**[ Filter ]**

```yaml
mutate {
		gsub => ["message", "[\"/{}]", ""]
}
```

â€˜gsubâ€™ Filter Pluginì„ ì´ìš©í•˜ì—¬ íŠ¹ìˆ˜ë¬¸ì ì œê±°í•œë‹¤.

```yaml
kv {
		field_split => "," 
		value_split => ":"
}
```

LogstashëŠ” í•˜ë‚˜ì˜ message í•„ë“œì— ëª¨ë“  ì •ë³´ë¥¼ ë‹´ì•„ì˜¨ë‹¤.

message í•„ë“œ ì•ˆì— ê°’ì„ â€œ,â€ ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ê³ , â€œ.â€ì„ ê¸°ì¤€ìœ¼ë¡œ key:value í˜•íƒœë¡œ ë³€í˜•í•˜ì—¬Â  ê°ê°ì˜ í•„ë“œë¡œ ìƒì„±í•œë‹¤.

```yaml
mutate {
		remove_field => [ "port","@version","host","message","@timestamp", "yy", "mm", "dd" ]
		rename => {" comment" => "comment"}
		rename => {" date" => "date"}
		rename => { " star" => "star" }
}
```

ë¶„ì„ì— í•„ìš”í•˜ì§€ ì•Šì€ Port, version, host, message í•„ë“œë¥¼ ì œê±°í•œë‹¤. gsubë¡œ íŠ¹ìˆ˜ë¬¸ì ì œê±° ì‹œ, í•„ë“œëª… ë§¨ ì•ì— ê³µë°±ì´ ë¶™ìœ¼ë¯€ë¡œ í•„ë“œ ì´ë¦„ì„ ì¬ì„¤ì •í•´ì£¼ì–´ì•¼í•œë‹¤.

```yaml
mutate {
		convert => {
		"star" => "integer"
		}
}
```

Stringìœ¼ë¡œ ì„¤ì •ë˜ì–´ìˆëŠ” star í•„ë“œ ê°’ì„ integer í˜•íƒœë¡œ ë³€í™˜í•œë‹¤.

**[ Outbound ]**

![Untitled](img/Untitled%2012.png)

```yaml
output {
      stdout { codec => rubydebug }
      # ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ ëª¨ì Topic
      if [topic] =~ "smartstore.goodnara.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.goodnara.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.drstyle.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.drstyle.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.thecheaper.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.thecheaper.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      }
# if end
      # ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ í‹°ì…”ì¸  Topic
      else if [topic] =~ "smartstore.180store.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.180store.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.cloony.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.cloony.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.theshopsw.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.theshopsw.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
    } # output end
```

Stdoutë¥¼ ì‚¬ìš©í•˜ì—¬ Opensearchë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•œë‹¤. index ì´ë¦„ì€ â€œí† í”½ ì´ë¦„ + ë‚ ì§œâ€ í˜•ì‹ìœ¼ë¡œ í˜•ì‹ìœ¼ë¡œ ì§€ì •í•œë‹¤. ë°ì´í„°ëŠ” ìµœì¢…ì ìœ¼ë¡œ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœë‹¤.

# 2.4. í”„ë¡œì„¸ìŠ¤ êµ¬í˜„

## 2.4.1. ì¸í”„ë¼ êµ¬í˜„

# 2.4.1.1. EKS

í”„ë¡œì íŠ¸ì˜ ì†Œí”„íŠ¸ì›¨ì–´ ì¤‘ íŒŒì´ì¬ í¬ë¡¤ëŸ¬, Logstash, Opensearch, KibanaëŠ” EKSë¥¼ í†µí•´ ë°°í¬í•œë‹¤.

## EKS ì‚¬ìš© ëª©ì 

Amazon EKSëŠ” ìì²´ì ìœ¼ë¡œ ì—¬ëŸ¬ ê°€ìš© ì˜ì—­ì—ì„œ Kubernetes ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì„ ì‹¤í–‰í•˜ê³  í™•ì¥ì‹œì¼œì£¼ê¸° ë•Œë¬¸ì— ê³ ê°€ìš©ì„±ê³¼ í™•ì¥ì„±ì´ ë³´ì¥ëœë‹¤. ë˜í•œ ë¶€í•˜ì— ë”°ë¼ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìë™ í™•ì¥í•˜ê³  í—¬ìŠ¤ ì²´í¬ë¥¼ í†µí•´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ êµì²´í•˜ë©° ë²„ì „ ì—…ë°ì´íŠ¸ ë° íŒ¨ì¹˜ ê¸°ëŠ¥ì„ ì œê³µí•˜ê¸° ë•Œë¬¸ì— AWS ìƒì—ì„œ ì»¨í…Œì´ë„ˆí™”ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ê´€ë¦¬ë¥¼ ìë™í™”í•˜ê¸° ìš©ì´í•˜ë‹¤.

## Terraformì„ í†µí•œ EKS ë°°í¬

> **ë°°í¬ ëª¨ë“ˆ ì •ë³´**
> 

- ëª¨ë“ˆëª…  : Young-ook/terraform-aws-eks

- ëª¨ë“ˆ ì½”ë“œ
    
    Terrafrom registry ì£¼ì†Œ
    
    [Terraform Registry](https://registry.terraform.io/modules/Young-ook/eks/aws/latest)
    

> **ëª¨ë“ˆ ì½”ë“œ ìƒì„¸ ì„¤ëª…**
> 

EKS ì½”ë“œ íŠ¸ë¦¬

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/terraform/EKS`

```bash
â”œâ”€â”€ default.auto.tfvars
â”œâ”€â”€ fixture.tc1.tfvars
â”œâ”€â”€ main.tf
â”œâ”€â”€ modules
â”‚   â”œâ”€â”€addonalb-ingress
â”‚   â”œâ”€â”€app-mesh
â”‚   â”œâ”€â”€cluster-autoscaler
â”‚   â”œâ”€â”€container-insights 
â”‚   â”œâ”€â”€ecr
â”‚   â”œâ”€â”€iam-role-for-service-account
â”‚   â”œâ”€â”€karpenter
â”‚   â”œâ”€â”€lb-contoller
â”‚   â”œâ”€â”€metrics-server
â”‚   â”œâ”€â”€node-termination-handler
â”‚   â”œâ”€â”€prometheus
â”œâ”€â”€ outputs.tf
â””â”€â”€ variables.tf
```

Terraform êµ¬ì„± íŒŒì¼

 íŒŒì¼ëª… :  `fixture.tc1.tfvars`

```yaml
aws_region      = "ap-northeast-2"
azs             = ["ap-northeast-2a", "ap-northeast-2b", "ap-northeast-2c"]
cidr       = "10.1.0.0/16"
enable_igw = true
enable_ngw = true
single_ngw = true
name            = "eks-autoscaling-tc1"
tags = {
  env  = "dev"
  test = "tc1"
}
kubernetes_version  = "1.21"
enable_ssm          = true
managed_node_groups = [
  {
    name          = "crawler"
    min_size      = 1
    max_size      = 6
    desired_size  = 1
    instance_type = "t3.medium"
  },
	{
    name          = "ElasticSearch-master"
    min_size      = 1
    max_size      = 3
    desired_size  = 1
    instance_type = "t3.large"
  }, 
	{
    name          = "ElasticSearch-data"
    min_size      = 1
    max_size      = 3
    desired_size  = 1
    instance_type = "t3.large"
  }, 
	{
    name          = "ElasticSearch-client"
    min_size      = 1
    max_size      = 3
    desired_size  = 1
    instance_type = "t3.large"
  }, 
	{
    name          = "Kibana"
    min_size      = 1
    max_size      = 3
    desired_size  = 1
    instance_type = "t3.medium"
  },
  {
    name          = "Logstash"
    min_size      = 1
    max_size      = 3
    desired_size  = 1
    instance_type = "t3.large"
  }
]
node_groups = []
fargate_profiles = []
```

EKS ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì˜€ê¸° ë•Œë¬¸ì— ìœ„ì˜ êµ¬ì„±íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•œ ì˜µì…˜ì„ ì„¤ì •í•˜ì—¬ ë°°í¬í•  ìˆ˜ ìˆë‹¤.

ì„œìš¸ ë¦¬ì „(ap-northeast-2)ì— 1.21 ë²„ì „ì˜ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•œë‹¤. 3ê°œì˜ ê°€ìš© ì˜ì—­(ap-northeast-2a, ap-northeast-2b, ap-northeast-2c)ì— ì†Œí”„íŠ¸ì›¨ì–´ ë³„ë¡œ ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì„ ë°°í¬í•œë‹¤. ê° ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì‚¬ìš©í•˜ëŠ” í¬ê¸°ì— ë§ê²Œ ë…¸ë“œ ê·¸ë£¹ì˜ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ì„ ì„¤ì •í•˜ê³  ìµœì†Œ ê°œìˆ˜, ìµœëŒ€ ê°œìˆ˜, ì›í•˜ëŠ” ê°œìˆ˜ë¥¼ ì§€ì •í•œë‹¤.

> **EKS ë°°í¬**
> 

1. í…Œë¼í¼ìœ¼ë¡œ EKSë¥¼ ë°°í¬í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„  í…Œë¼í¼ì„ ì‹¤í–‰í•´ì•¼í•œë‹¤. í•´ë‹¹ ë””ë ‰í† ë¦¬ë¥¼ ì´ˆê¸°í™” í•œë‹¤.
    
    ```bash
    $ terraform init
    ```
    
2. ì•ì„œ ì„¤ì •í•œ ì‚¬ìš©ì ì •ì˜ ë§¤ê°œ ë³€ìˆ˜ì— ëŒ€í•œ ì˜µì…˜ì´ ì ìš© ëœ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•œë‹¤. ë§¤ê°œ ë³€ìˆ˜ ì˜µì…˜ì€ í…Œë¼í¼ ëª…ë ¹ì–´ì— `var-file` ì˜µì…˜ì„ ì¶”ê°€í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. apply ì‹œ ì‚¬ìš©ìì˜ ìŠ¹ì¸ ì ˆì°¨ ì—†ì´ ë°°í¬ë˜ê²Œ í•˜ê¸° ìœ„í•´ `--auto-approve` ì˜µì…˜ì„ ì‚¬ìš©í•œë‹¤.
    
    ```bash
    $ terraform plan -var-file fixture.tc1.tfvars
    $ terraform apply -var-file fixture.tc1.tfvars --auto-approve
    ```
    

> **kubeconfig íŒŒì¼ ìƒì„±**
> 

```bash
$ aws eks update-kubeconfig --region ap-northeast-2 --name eks-autoscaling-tc1
```

ê¸°ë³¸ì ìœ¼ë¡œÂ `kubectl`ì€Â `$HOME/.kube` ë””ë ‰í„°ë¦¬ì—ì„œÂ `config`ë¼ëŠ” ì´ë¦„ì˜ íŒŒì¼ì„ ì°¾ëŠ”ë‹¤. AWS EKSì—ì„œ ì¿ ë²„ë„¤í‹°ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ AWS CLIì—ì„œÂ `aws eks update-kubeconfig` ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œÂ `kubeconfig` íŒŒì¼ì„ ìƒì„±í•œë‹¤. `--region` ì˜µì…˜ì— í´ëŸ¬ìŠ¤í„°ê°€ ì¡´ì¬í•˜ëŠ” ë¦¬ì „ì„ ì§€ì •í•˜ê³  `--name` ì˜µì…˜ì— í´ëŸ¬ìŠ¤í„°ì˜ ì´ë¦„ì„ ì§€ì •í•˜ì—¬ ì•ì„œ ìƒì„±í•œ `eks-autoscaling-tc1` í´ëŸ¬ìŠ¤í„°ì—ì„œ `kubectl` ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤.

ğŸ“Œ **ì£¼ì˜ì‚¬í•­**

- AWS CLIë¡œÂ `kubeconfig`ë¥¼ ìƒì„±í•˜ë ¤ë©´ ****ë²„ì „Â `1.23.11`Â ë˜ëŠ”Â `2.6.3`Â ì´ìƒì´ ì„¤ì¹˜ë˜ì–´ìˆì–´ì•¼í•œë‹¤.
- ì§€ì •í•œ í´ëŸ¬ìŠ¤í„°ì—ì„œÂ `eks:DescribeCluster`  API ì‘ì—…ì„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¶Œí•œì´ ìˆì–´ì•¼í•œë‹¤.


# 2.4.1.2. íŒŒì´ì¬ í¬ë¡¤ëŸ¬

## íŒŒì´ì¬ í¬ë¡¤ëŸ¬ ì‚¬ìš© ëª©ì 

ì‚¬ìš©ìì˜ ì‡¼í•‘ëª° ëŒ“ê¸€ì—ì„œ ë¶„ì„ì„ ìœ„í•´ í•„ìš”í•œ í•­ëª©ë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•´ Python Crawlerë¥¼ ì‚¬ìš©í•œë‹¤.

## **í¬ë¡¤ëŸ¬ íŒŒë“œ ìƒì„±**

> **Namespace ìƒì„±**
> 

í¬ë¡¤ëŸ¬ íŒŒë“œë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ `crawler` Namespaceë¥¼ ìƒì„±í•œë‹¤.

```bash
$ kubectl create ns crawler
```

> **íŒŒë“œ ìƒì„±**
> 

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/Crawler`

íŒŒì¼ ì´ë¦„ : `kafka_producer_pod.yaml`

Format : YAML

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  namespace: crawler
  name: crawler-1
  labels:
    app: crawler
spec:
  schedule: "00 00 * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: crawler
          annotations:
            "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
        spec:
          nodeSelector:
            Name: Crawler
          containers:
          - name: crawler-1
            image: ddung1203/kafkacrawler:10
            resources:
              requests:
                memory: "3000Mi"
                cpu: "1500m"
              limits:
                memory: "3000Mi"
                cpu: "1500m"
            env:
            - name: url
              value: 'https://smartstore.naver.com/goodnara/products/371623918?'
            - name: topic
              value: smartstore.goodnara.review
            - name: server
              value: "3.38.10.106:9092,3.34.18.190:9092,13.209.146.71:9092"
            command: ["/bin/sh", "-c"]
            args: ["cd /Datapipeline_Project/crawler; ./kafka_producer.py"]
          restartPolicy: Never
```

Crawler íŒŒë“œ ìƒì„±ì„ ìœ„í•œ íŒŒì¼ì´ë‹¤.

í¬ë¡¤ë§ì„ ìœ„í•œ ì†Œí”„íŠ¸ì›¨ì–´ì™€ íŒŒì´ì¬ íŒŒì¼ `kafka_producer.py`ê°€ ì„¤ì¹˜ë˜ì–´ìˆëŠ” Ubuntu ì´ë¯¸ì§€ `dung1203/kafkacrawler:10` ë¥¼ ì‚¬ìš©í•œë‹¤. ìƒì„± ëœ íŒŒë“œ ë‚´ì—ì„œ ì§€ì • ëœ í™˜ê²½ë³€ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ `kafka_producer.py` ë¥¼ ì‹¤í–‰í•œë‹¤.

**í™˜ê²½ë³€ìˆ˜**

| ENV | Description |
| --- | --- |
| url | ëŒ“ê¸€ ë¶„ì„ì„ ìš”ì²­í•œ ì†Œë¹„ìì˜ ì‡¼í•‘ëª° url |
| topic | ì¶”ì¶œí•œ ëŒ“ê¸€ ë°ì´í„°ë¥¼ ì „ì†¡í•  Kafka Brokerì˜ Topicëª… |
| server | ì¶”ì¶œí•œ ëŒ“ê¸€ ë°ì´í„°ë¥¼ ì „ì†¡í•  Kafka Broker ì„œë²„ëª… |

ì•ì„œ ìƒì„±í•œ EKS í´ëŸ¬ìŠ¤í„°ì˜ `crawler` ë…¸ë“œ ê·¸ë£¹ì— í¬ë¡¤ëŸ¬ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤.

```bash
$ kubectl create -f kafka_producer_pod.yaml
```


# 2.4.1.3. Kafka

## Kafka **ì‚¬ìš© ëª©ì **

í¬ë¡¤ëŸ¬ì—ì„œ ì ì¬ ì„œë²„ë¡œ ì‡¼í•‘ëª°ì˜ ëŒ“ê¸€ ë°ì´í„° ì „ì†¡ ì‹œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ë°ì´í„° ìœ ì‹¤ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ Kafkaì˜ Queuing ê¸°ëŠ¥ì„ ì‚¬ìš©í•œë‹¤.

## Kafka ì¸í”„ë¼ ìƒì„±

### ì•„í‚¤í…ì²˜ êµ¬ì„±ë„

![kafka2.svg](img/kafka2.svg)

### Zookeeper ì„¤ì •

ê° ì¸ìŠ¤í„´ìŠ¤ì— ì„¤ì¹˜ëœ Kafkaì˜ `config/zookeeper.properties` íŒŒì¼ì€ í•˜ë‚˜ì˜ Zookeeperë¥¼ ì‹¤í–‰í•˜ëŠ”ë° ì“°ì´ëŠ” ì„¤ì • íŒŒì¼ì´ë‹¤. zookeeper1.properties, zookeeper2.properties, zookeeper3.properties ì™€ ê°™ì´ ì—¬ëŸ¬ ê°œì˜ ì„¤ì •íŒŒì¼ì„ ë§Œë“¤ê³  í•˜ë‚˜ì˜ ì¥ë¹„ì—ì„œ ë‹¤ì¤‘ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. ì„¤ì •íŒŒì¼ì„ ë‹¤ìŒê³¼ ê°™ì´ 3ëŒ€ì˜ ì„œë²„ì— ë™ì¼í•˜ê²Œ ì¶”ê°€í•œë‹¤.

ìƒˆë¡œ ì¶”ê°€í•œ ì„¤ì •ê°’ì€ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ëŠ”ë° í•„ìš”í•œ ì„¤ì • ê°’ë“¤ì¸ë° ì—¬ê¸°ì„œ ì£¼ì˜í•  ì ì€ ëª¨ë“  Zookeeper ì„œë²„ë“¤ì€ ë™ì¼í•œ ë³€ìˆ˜ ê°’ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•œë‹¤.

íŒŒì¼ëª… : `config/zookeeper.properties`

```yaml
# ì£¼í‚¤í¼ì˜ íŠ¸ëœì­ì…˜ ë¡œê·¸ì™€ ìŠ¤ëƒ…ìƒ·ì´ ì €ì¥ë˜ëŠ” ë°ì´í„° ì €ì¥ ê²½ë¡œ(ì¤‘ìš”)
**dataDir=/tmp/zookeeper**

# ì£¼í‚¤í¼ ì‚¬ìš© TCP Port
clientPort=2181

# íŒ”ë¡œì›Œê°€ ë¦¬ë”ì™€ ì´ˆê¸°ì— ì—°ê²°í•˜ëŠ” ì‹œê°„ì— ëŒ€í•œ íƒ€ì„ ì•„ì›ƒ tickì˜ ìˆ˜
**initLimit=5**

# íŒ”ë¡œì›Œê°€ ë¦¬ë”ì™€ ë™ê¸°í™” í•˜ëŠ” ì‹œê°„ì— ëŒ€í•œ íƒ€ì„ ì•„ì›ƒ tickì˜ ìˆ˜(ì£¼í‚¤í¼ì— ì €ì¥ëœ ë°ì´í„°ê°€ í¬ë©´ ìˆ˜ë¥¼ ëŠ˜ë ¤ì•¼í•¨)
**syncLimit=2**

# server.1ì— ìê¸° ìì‹ ì€ 0.0.0.0 ë¡œ ì…ë ¥ ex) 2ë²ˆì„œë²„ì¼ ê²½ìš° server.2ê°€ 0.0.0.0ì´ ëœë‹¤
# server.{1} -> {1} ì€ myidì´ë‹¤ ì¦‰, server.myid í˜•ì‹ìœ¼ë¡œ ë˜ì–´ìˆë‹¤.
**server.1=0.0.0.0:2888:3888

server.2=3.34.18.190:2888:3888

server.3=13.209.146.71:2888:3888**
```

ìœ„ íŒŒì¼ì€ í˜„ì¬ server.1ì˜ ì„¤ì • íŒŒì¼ì´ë‹¤. server ì´ë¦„ì€ server.{myid} í˜•ì‹ì´ë‹¤.

```powershell
mkdir /tmp/zookeeper $ echo 1 > /tmp/zookeeper/myid (ì„œë²„ 1)
mkdir /tmp/zookeeper $ echo 2 > /tmp/zookeeper/myid (ì„œë²„ 2)
mkdir /tmp/zookeeper $ echo 3 > /tmp/zookeeper/myid (ì„œë²„ 3)
```

/tmp/zookeeper ëª…ë ¹ì–´ë¡œ ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ê³  í•´ë‹¹ íŒŒì¼ì˜ myid ë¶€ë¶„ì— ê° ì„œë²„ì˜ myidë¥¼ ë„£ëŠ”ë‹¤.

- **dataDir**
    
    server.1,2,3ì˜ ìˆ«ìëŠ” ì¸ìŠ¤í„´ìŠ¤ IDì´ë‹¤.Â IDëŠ” dataDir=/tmp/zookeeper í´ë”ì— myidíŒŒì¼ì— ëª…ì‹œê°€ ë˜ì–´ì•¼ í•œë‹¤. /tmp/zookeeper ë””ë ‰í† ë¦¬ê°€ ì—†ë‹¤ë©´ ìƒì„±í•˜ê³ Â myid íŒŒì¼ì„ ìƒì„±í•˜ì—¬Â ê°ê° ì„œë²„ì˜ ê³ ìœ  IDê°’ì„ ë¶€ì—¬í•´ì•¼ í•œë‹¤.
    
- **initLimit**
    
    íŒ”ë¡œì›Œê°€ ë¦¬ë”ì™€ ì´ˆê¸°ì— ì—°ê²°í•˜ëŠ” ì‹œê°„ì— ëŒ€í•œ íƒ€ì„ì•„ì›ƒì„ ì„¤ì •í•œë‹¤.
    
- **syncLimit**
    
    íŒ”ë¡œì›Œê°€ ë¦¬ë”ì™€ ë™ê¸°í™” í•˜ëŠ”ë°ì— ëŒ€í•œ íƒ€ì„ì•„ì›ƒ. ì¦‰ ì´ í‹± ì‹œê°„ì•ˆì— íŒ”ë¡œì›Œê°€ ë¦¬ë”ì™€ ë™ê¸°í™”ê°€ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì œê±° ëœë‹¤.
    
    ğŸ“Œ **ì£¼ì˜**
    
    `initLimit` ê³¼ `syncLimit` ì€ dafault ê¸°ë³¸ê°’ì´ ì—†ê¸° ë•Œë¬¸ì— ë°˜ë“œì‹œ ì„¤ì •í•´ì•¼ í•œë‹¤.
    
- **server.1,2,3**
    
    ê° ì„œë²„ì˜ IPì£¼ì†Œì™€ Portë¥¼ ì„¤ì •í•œë‹¤. ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ì ì€ ë§Œì•½ 1ë²ˆ ì„œë²„ì˜ ì„¤ì •íŒŒì¼ì„ ë³€ê²½ ì¤‘ì´ë¼ë©´ 1ë²ˆ ì„œë²„, ì¦‰ ìê¸° ìì‹ ì— ëŒ€í•œ IPì£¼ì†ŒëŠ” ìì‹ ì˜ Public IP ì£¼ì†Œê°€ ì•„ë‹ˆë¼ `0.0.0.0`ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•œë‹¤. zookeeper ì„¤ì • ì‹œ í•´ë‹¹í•˜ëŠ” ë…¸ë“œê°€ localhostì— ìœ„ì¹˜í•´ ìˆëŠ” ê²½ìš°, ì˜ˆì™¸ìƒí™© ë°œìƒì„ ë§‰ê¸° ìœ„í•´ 0.0.0.0ìœ¼ë¡œ ì§€ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•œë‹¤.
    

### Broker ì„¤ì •

Kafkaì˜ `config/server.properties` íŒŒì¼ì€ í•˜ë‚˜ì˜ Kafkaë¥¼ ì‹¤í–‰í•˜ëŠ”ë° ì“°ì´ëŠ” ì„¤ì • íŒŒì¼ì´ë‹¤. Zookeeperì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì—¬ëŸ¬ ê°œì˜ ì„¤ì • íŒŒì¼ì„ ë§Œë“¤ê³  ë‹¤ì¤‘ ì‹¤í–‰ì„ í•  ìˆ˜ ìˆë‹¤.

ì„¤ì • íŒŒì¼ config/server.propertiesì— 3ëŒ€ ì„œë²„ ê° í™˜ê²½ì— ë§ëŠ” ì •ë³´ë¥¼ ì…ë ¥í•´ ì¤€ë‹¤.

```yaml
############################# Server Basics #############################
**broker.id=1**

############################# Socket Server Settings #############################

**listeners=PLAINTEXT://:9092 
advertised.listeners=PLAINTEXT://IP:9092**   
#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL 
# ë³´ì•ˆ ì„¤ì •ì‹œ í”„ë¡œí† ì½œ ë§¤í•‘ ì„¤ì •

num.network.threads=3       # ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ ì²˜ë¦¬ë¥¼ í• ë•Œ ì‚¬ìš©í•  ë„¤íŠ¸ì›Œí¬ ìŠ¤ë ˆë“œ ê°œìˆ˜ ì„¤ì •

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8        # ë¸Œë¡œì»¤ ë‚´ë¶€ì—ì„œ ì‚¬ìš©í•  ìŠ¤ë ˆë“œ ê°œìˆ˜ ì§€ì •

############################# Log Basics #############################

log.dirs=/tmp/kafka-logs        # í†µì‹ ì„ í†µí•´ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìœ„ì¹˜. í‹°ë ‰í† ë¦¬ê°€ ìƒì„±ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë¯€ë¡œ ë¯¸ë¦¬ ìƒì„±í•´ì•¼í•¨.

num.partitions=1                # íŒŒí‹°ì…˜ì˜ ê°œìˆ˜ë¥¼ ëª…ì‹œí•˜ì§€ ì•Šê³  í† í”½ì„ ìƒì„±í• ë•Œ ê¸°ë³¸ ì„¤ì •ë˜ëŠ” íŒŒí‹°ì…˜ì˜ ê°œìˆ˜. íŒŒí‹°ì…˜ì˜ ê°œìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ë³‘ë ¬ì²˜ë¦¬ ë°ì´í„° ì–‘ì´ ëŠ˜ì–´ë‚¨

**log.retention.hours=-1**

log.segment.bytes=1073741824        # ë¸Œë¡œì»¤ê°€ ì €ì¥í•  íŒŒì¼ì˜ ìµœëŒ€ í¬ê¸° ì§€ì • ë°ì´í„° ì–‘ì´ ë§ì•„ ì´ í¬ê¸°ë¥¼ ì±„ìš°ê²Œ ë˜ë©´ ìƒˆë¡œìš´ íŒŒì¼ ìƒì„±

log.retention.check.interval.ms=300000     # ë¸Œë¡œì»¤ê°€ ì €ì¥í•œ íŒŒì¼ì„ ì‚­ì œí•˜ê¸° ìœ„í•´ ì²´í¬í•˜ëŠ” ê°„ê²©ì„ ì§€ì •

############################# Zookeeper #############################

**zookeeper.connect=server1-ip:2181,server2-ip:2181,server3-ip:2181**      

zookeeper.connection.timeout.ms=18000       # ì£¼í‚¤í¼ ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì‹œê°„ ì„¤ì •
```

- **broker.id** : ì‹¤í–‰í•  ë¸Œë¡œì»¤ì˜ ë²ˆí˜¸ë¥¼ ì ëŠ”ë‹¤. í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•  ë•Œ ë¸Œë¡œì»¤ë“¤ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ë‹¨ í•˜ë‚˜ ë¿ì¸ ë²ˆí˜¸ë¡œ ì„¤ì •í•´ì•¼ í•œë‹¤.
- **listeners** : ì¹´í”„ì¹´ ë¸Œë¡œì»¤ê°€ í†µì‹ ì„ ìœ„í•´ ì—´ì–´ë‘˜ ì¸í„°í˜ì´ìŠ¤ IP, port, í”„ë¡œí† ì½œì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. ë”°ë¡œ ì„¤ì •í•˜ì§€ ì•Šìœ¼ë©´ ANYë¡œ ì„¤ì •ëœë‹¤.
- **advertised.listeners** : ì¹´í”„ì¹´ í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” ì¹´í”„ì¹´ ì»¤ë§¨ë“œ ë¼ì¸ íˆ´ì—ì„œ ì ‘ì†í• ë•Œ ì‚¬ìš©í•˜ëŠ” IPì™€ port ì •ë³´ë¥¼ ì„¤ì •í•œë‹¤.
- **log.retention.hours :** ë¸Œë¡œì»¤ê°€ ì €ì¥í•œ íŒŒì¼ì´ ì‚­ì œë˜ê¸°ê¹Œì§€ ê±¸ë¦¬ëŠ” ì‹œê°„ì„ ì„¤ì •í•œë‹¤. -1ë¡œ ì„¤ì •í•˜ë©´ ì˜êµ¬ë³´ì¡´ëœë‹¤.
- **zookeeper.connect :** ì¹´í”„ì¹´ ë¸Œë¡œì»¤ì™€ ì—°ë™í•  ì£¼í‚¤í¼ì˜ IPì™€ portë¥¼ ì„¤ì •í•œë‹¤.

### Zookeeper ë° Kafka ì„œë²„ êµ¬ë™

Kafkaë¥¼ êµ¬ë™í•˜ê¸° ìœ„í•´ ë¨¼ì € Zookeeperë¥¼ êµ¬ë™í•œ ë‹¤ìŒ ì´í›„ Kafkaë¥¼ êµ¬ë™í•´ì•¼ í•œë‹¤.

```yaml
$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
$ bin/kafka-server-start.sh -daemon config/server.properties
```

### í† í”½ ìƒì„±

ì¹´í”„ì¹´ì—ì„œ ì‚¬ìš©í•  í† í”½ì„ ìƒì„±í•œë‹¤. í† í”½ì€ Naming Conventionì— ë”°ë¼ ìƒì„±í•´ì•¼í•˜ë©°, ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì‡¼í•‘ëª°ì— ë”°ë¼ í† í”½ì„ ë”°ë¡œ ìƒì„±í•˜ì—¬ ê´€ë¦¬í•œë‹¤.

### **Convention**

ì¹´í”„ì¹´ì—ì„œëŠ” í† í”½ì„ ë§ì´ ìƒì„±í•´ì„œ ì‚¬ìš©í•˜ëŠ”ë° Naming Convention ì—†ì´ ì‚¬ìš©í•˜ê²Œ ëœë‹¤ë©´ ë‚˜ì¤‘ì— ë³µì¡í•´ì§ˆ ìˆ˜ë„ ìˆê¸° ë•Œë¬¸ì— í† í”½ ìƒì„±ì‹œ ì£¼ì˜í•´ì•¼í•œë‹¤.

ì¹´í”„ì¹´ì—ì„œ í† í”½ì„ ìƒì„±í•  ë•Œ ìœ íš¨í•œ ë¬¸ìëŠ” `ì˜ë¬¸, ìˆ«ì, ë§ˆì¹¨í‘œ, ì‰¼í‘œ, ì–¸ë”ë°”, í•˜ì´í”ˆ` ë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ìœ ì˜í•  ì ì€ ë§ˆì¹¨í‘œì™€ ì–¸ë”ë°”ëŠ” ì¶©ëŒí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©í•´ì•¼ í•œë‹¤.

ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” <department name>.<team name>.<dataset name> ê·œì¹™ì— ë”°ë¼ í† í”½ì„ ìƒì„±í•œë‹¤. Naming Conventionì— ë”°ë¥¸ ì‡¼í•‘ëª° í† í”½ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

```yaml
smartstore.goodnara.review (ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ goodnara)
smartstore.drstyle.review (ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ drstyle)
smartstore.thecheaper.review (ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ thecheaper)
smartstore.180store.review (ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ 180store)
smartstore.cloony.review (ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ cloony)
smartstore.theshopsw.review (ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ theshopsw)
```


# ELK ì•„í‚¤í…ì²˜

![Untitled](img/Untitled%2013.png)

```yaml
â”œâ”€â”€ kibana
â”‚   â”œâ”€â”€ kibana-configmap.yaml
â”‚   â”œâ”€â”€ kibana-deployment.yaml
â”‚   â”œâ”€â”€ kibana-service.yaml
â”‚   â””â”€â”€ Opendisro-Alerting-Slack.json
â”œâ”€â”€ logstash
â”‚   â”œâ”€â”€ logstash-configmap.yaml
â”‚   â”œâ”€â”€ logstash-deployment.yaml
â”‚   â””â”€â”€ logstash-svc-nodeport.yaml
â”œâ”€â”€ namespace.yaml
â””â”€â”€ opensearch
    â”œâ”€â”€ client-node
    â”‚   â”œâ”€â”€ elasticsearch-client-configmap.yaml
    â”‚   â”œâ”€â”€ elasticsearch-client-deployment.yaml
    â”‚   â”œâ”€â”€ elasticsearch-client-http.yaml
    â”‚   â””â”€â”€ elasticsearch-client-service.yaml
    â”œâ”€â”€ data-node
    â”‚   â”œâ”€â”€ elasticsearch-data-configmap.yaml
    â”‚   â”œâ”€â”€ elasticsearch-data-service.yaml
    â”‚   â””â”€â”€ elasticsearch-data-statefulset.yaml
    â””â”€â”€ master-node
        â”œâ”€â”€ elasticsearch-master-configmap.yaml
        â”œâ”€â”€ elasticsearch-master-deployment.yaml
        â””â”€â”€ elasticsearch-master-service.yaml
```

**Opensearch**

ì €ì¥ì€ Opensearch ê°€ ë‹´ë‹¹í•œë‹¤. ELK ìŠ¤íƒì˜ í•µì‹¬ì€ Opensearch ì´ë©°, ì´ ì €ì¥ì†Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•œë‹¤.  Opensearch ëŠ” ë£¨ì”¬ ê¸°ë°˜ì˜ ê²€ìƒ‰ ì—”ì§„ì´ë‹¤.

OpensearchëŠ” ë¬¼ë¦¬ì ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ì™€ ë…¸ë“œë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ë…¸ë“œëŠ” í¬ê²Œ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì •ë³´ë¥¼ ê´€ë¦¬í•˜ëŠ” `ë§ˆìŠ¤í„° ë…¸ë“œ`, ìƒ‰ì¸ëœ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ìˆëŠ” `ë°ì´í„° ë…¸ë“œ`, ë¬¸ì„œ ë³€í™˜ ë° ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” `ì¸ì œìŠ¤íŠ¸ ë…¸ë“œ`ë¡œ êµ¬ë¶„ëœë‹¤.

í˜„ì¬ í”„ë¡œì íŠ¸ì˜ Opensearch í´ëŸ¬ìŠ¤í„°ì—ëŠ” `ë§ˆìŠ¤í„° ë…¸ë“œ` 3ê°œì™€ `ë°ì´í„° ë…¸ë“œ` 3ê°œ , `ì¸ì œìŠ¤íŠ¸ ë…¸ë“œ` 3ê°œë¡œ ì´ 9ê°œì˜ ë…¸ë“œë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. 

**Kibana**

ì €ì¥ëœ ë°ì´í„°ë¥¼ `ë¶„ì„`í•˜ê³  `ì‹œê°í™”`í•œë‹¤. Opensearch ì— ì €ì¥ ëœ ì‡¼í•‘ëª° ë¦¬ë·° ë°ì´í„°ì— ëŒ€í•œ `Index íŒ¨í„´`ì„ ìƒì„±í•˜ê³  `ëŒ€ì‹œë³´ë“œ`ë¥¼ í†µí•´ ì‹œê°í™” í•œë‹¤. ë¡œë“œë°¸ëŸ°ì„œ íƒ€ì…ì˜ ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ì´ ê°€ëŠ¥í–ˆê³ , ë¡œë“œë°¸ëŸ°ì„œ ì£¼ì†Œì˜ 80ë²ˆ í¬íŠ¸ë¡œ ì ‘ê·¼í•˜ë©´ Kibana í´ëŸ¬ìŠ¤í„°ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±í–ˆë‹¤.

**Logstash**

Deployment ë°©ì‹ìœ¼ë¡œ Logstash íŒŒë“œë¥¼ ë°°í¬í•˜ê³  Nodeport íƒ€ì…ì˜ ì„œë¹„ìŠ¤ë¡œ ë°°í¬í•˜ì˜€ë‹¤. 

Kafka input pluginì„ ì´ìš©í•˜ì—¬ ë¸Œë¡œì»¤ì— ì ì¬ëœ ì‡¼í•‘ëª° ë°ì´í„°ë¥¼ opensearchì˜ ë°ì´í„° ë…¸ë“œì— ì ì¬í•œë‹¤. 

Logstash íŒŒì´í”„ ë¼ì¸ ì¤‘ Filter í”ŒëŸ¬ê·¸ì¸ì„ ì‚¬ìš©í•˜ì—¬ ì •ì œí•˜ë„ë¡ êµ¬ì„±í–ˆë‹¤.. Logstashë¥¼ í†µí•´ ë“¤ì–´ì˜¨ ë°ì´í„°ëŠ” `Message`ë¼ëŠ” í•„ë“œ ì•ˆì— í•œ ë²ˆì— ë“¤ì–´ì˜¤ê²Œ ëœë‹¤. ë©”ì„¸ì§€ í•„ë“œë§Œ ì €ì¥í•´ë„ ë˜ì§€ë§Œ ì¶”í›„ ì›í™œí•œ ì‹œê°í™”ë¥¼ ìœ„í•´ ë¡œê·¸ë¥¼ êµ¬ë¶„í•˜ì—¬ ê°ê°ì˜ `í•„ë“œë¥¼ ì¬ìƒì„±`í•˜ëŠ” í•„í„°ë¥¼ ì¶”ê°€í•œë‹¤.

# 2.4.1.4. Opensearch

## Opensearch ì‚¬ìš© ëª©ì 

OpenSearchëŠ” ë°ì´í„° ìˆ˜ì§‘, ê²€ìƒ‰, ì‹œê°í™” ë° ë¶„ì„ì„ ì‰½ê²Œ í•˜ëŠ” ì»¤ë®¤ë‹ˆí‹° ì¤‘ì‹¬ì˜ ê²€ìƒ‰ ë° ë¶„ì„ ì†Œí”„íŠ¸ì›¨ì–´ì´ë‹¤.Â í˜„ì¬ í”„ë¡œì íŠ¸ì—ì„œëŠ” OpenSearchë¥¼ ì‡¼í•‘ëª° ëŒ“ê¸€ ë°ì´í„° ë° ëŒ“ê¸€ ìì—°ì–´ ì²˜ë¦¬ ê²°ê³¼ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë°ì´í„° ì €ì¥ì†Œ ìš©ë„ë¡œ ì‚¬ìš©í•œë‹¤.

## Opensearch ì¸í”„ë¼ ìƒì„±

`ë§ˆìŠ¤í„°ë…¸ë“œ`ì™€ `ì¸ì œìŠ¤íŠ¸ ë…¸ë“œ`ëŠ” `Deployment` ë°©ì‹ìœ¼ë¡œ ë°°í¬í•˜ì—¬ `Pod`ë“¤ì„ ê´€ë¦¬í•˜ê³ ,  ë°ì´í„°ì˜ ì €ì¥ì„ ë‹´ë‹¹í•˜ëŠ” `ë°ì´í„° ë…¸ë“œëŠ”` `Statefulset` ë°©ì‹ìœ¼ë¡œ ìƒì„±í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ê°€ ì‚­ì œë˜ì–´ë„ ë°ì´í„°ë¥¼ ì˜êµ¬ ë³´ì¡´í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„í–ˆë‹¤.

ë§ˆì§€ë§‰ìœ¼ë¡œ ServiceëŠ” ë§ˆìŠ¤í„° ë…¸ë“œì™€ ë°ì´í„° ë…¸ë“œëŠ” `ClusterIP` í˜•íƒœì˜ ì„œë¹„ìŠ¤ë¡œ êµ¬ì„±í•˜ì—¬ ë…¸ë“œ ê°„ í†µì‹ ì€ ê°€ëŠ¥í•˜ë˜ ì™¸ë¶€ì—ì„œ ì ‘ê·¼í•  ìˆ˜ ì—†ë„ë¡ ì„¤ì •í•˜ê³ , ì¸ì œìŠ¤íŠ¸ ë…¸ë“œì˜ Serviceë¥¼ `NodePort` í˜•íƒœë¡œ ë°°í¬í•˜ì—¬ í•´ë‹¹ ë…¸ë“œë¥¼ í†µí•´ì„œë§Œ ì™¸ë¶€ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •í–ˆë‹¤.

- Namespace ìƒì„±
- Opensearch Mater Node ìƒì„±
- Opensearch Data Node ìƒì„±
- Opensearch Ingest Node ìƒì„±

### **Namespace ìƒì„±**

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/Elasticsearch`

íŒŒì¼ëª… : `namespace.yaml`

```yaml
apiVersion: v1
kind: Namespace
metadata:
    name: elk
```

Elasticsearch, Logstash, Kibanaë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê´€ë¦¬í•˜ê¸° ìœ„í•´ `elk` Namespaceë¥¼ ìƒì„±í•œë‹¤. ì´í›„ ìƒì„±ë˜ëŠ” ëª¨ë“  ë¦¬ì†ŒìŠ¤ë“¤ì€ `namespace` ë‹¨ìœ„ë¡œ êµ¬ë¶„ëœë‹¤.

### **Master-Node ìƒì„±**

Master NodeëŠ” ì¸ë±ìŠ¤ì˜ ë©”íƒ€ ë°ì´í„°, ìƒ¤ë“œì˜ ìœ„ì¹˜ì™€ ê°™ì€ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì •ë³´ë¥¼ ê´€ë¦¬í•œë‹¤.

ë§ˆìŠ¤í„° í›„ë³´ ë…¸ë“œë¥¼ í•˜ë‚˜ë§Œ ë†“ê²Œ ë˜ë©´ ê·¸ ë§ˆìŠ¤í„° ë…¸ë“œê°€ ìœ ì‹¤ë˜ì—ˆì„ ë•Œ í´ëŸ¬ìŠ¤í„° ì „ì²´ê°€ ì‘ë™ì„ ì •ì§€ í•  ìœ„í—˜ì´ ìˆìœ¼ë¯€ë¡œ ìµœì†Œ 3ê°œ ì´ìƒì˜ í™€ìˆ˜ ê°œë¥¼ ìƒì„±í•´ì•¼ í•œë‹¤.

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/Elasticsearch/opensearch/master-node`

- Master-Node Configmap ìƒì„±

íŒŒì¼ëª… : `elasticsearch-master-configmap.yaml`

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: elk
  name: elasticsearch-master-config
  labels:
    app: elasticsearch
    role: master
data:
  elasticsearch.yml: |-
    cluster.name: ${CLUSTER_NAME}
    node.name: ${NODE_NAME}
    discovery.seed_hosts: ${NODE_LIST}
    cluster.initial_master_nodes: ${MASTER_NODES}
    network.host: 0.0.0.0
    node:
      master: true
      data: false
      ingest: false
    opendistro_security.ssl.http.enabled: false
    opendistro_security.disabled: true
```

`elk` Namespace ë‚´ì— Opensearch ì„¤ì • ê°’ì„ ê°€ì§„ Master Nodeì˜ `Configmap` ì„ ìƒì„±í•œë‹¤.  ìƒì„±í•œë‹¤. í´ëŸ¬ìŠ¤í„°ì˜ ì´ë¦„, ë…¸ë“œì˜ ì´ë¦„, ë…¸ë“œì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ í†µí•´ hostë¥¼ ì°¾ë„ë¡ ì„¤ì •í•˜ê³  `master: true` ì˜µì…˜ì„ í†µí•´ ë§ˆìŠ¤í„° ë…¸ë“œë¡œ ìƒì„±í•œë‹¤.

***data* Field Parameter**

| Parameter | Description | Details |
| --- | --- | --- |
| cluster.name | í´ëŸ¬ìŠ¤í„° ì´ë¦„ | í´ëŸ¬ìŠ¤í„°ëª…ì´ ë™ì¼í•´ì•¼ ë™ì¼í•œ í´ëŸ¬ìŠ¤í„°ë¡œ ì¸ì‹ |
| node.name | ë…¸ë“œ ì´ë¦„ | - |
| discovery.seed_hosts | í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•  ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ | - |
| cluster.initial_master_nodes | master í›„ë³´ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ | - |
| network.host | ë…¸ë“œì˜ IP | ì™¸ë¶€ ì ‘ê·¼ í—ˆìš© |
| node | ë…¸ë“œì˜ ê¸°ëŠ¥ | í•´ë‹¹ ë…¸ë“œëŠ” master ë…¸ë“œë¡œ ì‚¬ìš© |
| opendistro_security.disabled | ë³´ì•ˆ í”ŒëŸ¬ê·¸ì¸ ë¹„í™œì„±í™” | - |

- Master-Node Service ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-master-service.yaml`
    

```yaml
apiVersion: v1
kind: Service
metadata:
  namespace: elk
  name: elasticsearch-master
  labels:
    app: elasticsearch
    role: master
spec:
  ports:
  - port: 9300
    name: transport
  selector:
    app: elasticsearch
    role: master
```

 `elk` Namespace ë‚´ì— Master Nodeì— ëŒ€í•œ ì„œë¹„ìŠ¤ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

í•´ë‹¹ ì„œë¹„ìŠ¤ëŠ” `app=elasticsearch`, `role=master`Â ë ˆì´ë¸”ì„ ê°€ì§„ íŒŒë“œê°€ TCP 9300 í¬íŠ¸ë¡œ ê° ë…¸ë“œë“¤ê³¼ í†µì‹ í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í–ˆë‹¤.

- Master-Node Deployment ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-master-deployment.yaml`
    

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: elk
  name: elasticsearch-master
  labels:
    app: elasticsearch
    role: master
spec:
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
      role: master
  template:
    metadata:
      labels:
        app: elasticsearch
        role: master
    spec:
      nodeSelector:
        Name: Master 
      containers:
      - name: elasticsearch-master
        image: amazon/opendistro-for-elasticsearch:1.13.2
        imagePullPolicy: Always
        env:
        - name: CLUSTER_NAME
          value: elasticsearch
        - name: NODE_NAME
          value: elasticsearch-master
        - name: NODE_LIST
          value: elasticsearch-master,elasticsearch-data,elasticsearch-client
        - name: MASTER_NODES
          value: elasticsearch-master
        - name: "ES_JAVA_OPTS"
          value: "-Xms1G -Xmx1G"
        ports:
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: config
          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          readOnly: true
          subPath: elasticsearch.yml
        - name: storage
          mountPath: /data
      volumes:
      - name: config
        configMap:
          name: elasticsearch-master-config
      - name: "storage"
        emptyDir:
          medium: ""
      initContainers:
      - name: increase-vm-max-map
        image: busybox
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
```

 `elk` Namespace ë‚´ì— Deployment ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ 3ê°œì˜ Master Node íŒŒë“œë¥¼ ë°°í¬í•œë‹¤. 

EKSì˜ master ë…¸ë“œ ê·¸ë£¹ì— ë°°ì¹˜í•˜ë„ë¡ `nodeSelector` ì˜µì…˜ì„ ì¶”ê°€í•˜ì—¬ ìŠ¤ì¼€ì¤„ë§ í•œë‹¤.

**Opensearch Master Node container**

Opendistro ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ Mater Node íŒŒë“œë¥¼ ìƒì„±í•œë‹¤. Configmapì—ì„œ ì‚¬ìš©í•  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§€ì •í•´ì£¼ê³  ë¯¸ë¦¬ ìƒì„±í•´ ë†“ì€ Master Node ì„œë¹„ìŠ¤ì˜ í¬íŠ¸ë¡œ í¬íŠ¸ í¬ì›Œë”©í•œë‹¤. ì•ì„œ ìƒì„±í•œ Configmapì´ ì ìš©ë  ìˆ˜ ìˆë„ë¡ Configmap ë³¼ë¥¨ì„ ìƒì„±í•´ Opensearchì˜ ì„¤ì • íŒŒì¼ì— ë§ˆìš´íŠ¸í•œë‹¤. ë˜í•œ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ì„ì‹œ ë³¼ë¥¨ì„ ìƒì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ì— ë§ˆìš´íŠ¸í•œë‹¤.

| Parameter | Descriptions | Details |
| --- | --- | --- |
| name | ìƒì„±í•  Deploymentì˜ ì´ë¦„ | elasticsearch-master |
| image | íŒŒë“œ ìƒì„±ì— ì‚¬ìš©í•˜ëŠ” ì´ë¯¸ì§€ | amazon/opendistro-for-elasticsearch:1.13.2 |
| imagePullPolicy | íŒŒë“œë¥¼ ìƒì„±í•  ë•Œ ì—…ë°ì´íŠ¸ ì¤‘ì— ì§€ì •ëœ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ë²• | Always : í•­ìƒ ì €ì¥ì†Œì—ì„œ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜´ |
| env | ì„¤ì • íŒŒì¼ì— ë“¤ì–´ê°ˆ í™˜ê²½ ë³€ìˆ˜ |  ES_JAVA_OPTS=1G |
| ports | ì„œë¹„ìŠ¤ í¬íŠ¸ì— ë§¤í•‘ | ì•ì„œ ìƒì„±í–ˆë˜ Master Nodeì˜ ì„œë¹„ìŠ¤ í¬íŠ¸ |
| volumeMounts | ë§ˆìš´íŠ¸í•  ë³¼ë¥¨ ê²½ë¡œ | elasticsearch.yml : Opensearch ì„¤ì • íŒŒì¼ |

**Opensearch Master Node initContainer**

Linux í™˜ê²½ì—ì„œ Elasticsearchê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê¸° ìœ„í•´ ì„¤ì •í•´ì•¼ í•  ìš”ì†Œë¥¼ ì´ˆê¸°í™”í•œë‹¤. `vm.max_map_count` ë³€ìˆ˜ ê°’ì„ ì¡°ì ˆí•˜ì—¬ Linux kernelì˜ ë©”ëª¨ë¦¬ ë§µ* ì˜ì—­ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì¡°ì‘í•œë‹¤. 

### **Data-Node ìƒì„±**

CRUD, ê²€ìƒ‰ ë° ì§‘ê³„ì™€ ê°™ì€ ë°ì´í„° ê´€ë ¨ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. íŒŒë“œê°€ ìŠ¤ì¼€ì¼ë§ ë˜ì–´ë„ ë°ì´í„°ëŠ” ì‚­ì œë˜ì§€ ì•Šê³  ìœ ì§€ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— Statefulset ì˜¤ë¸Œì íŠ¸ë¡œ ë°°í¬í•œë‹¤.

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/Elasticsearch/opensearch/data-node`

- Data-Node Configmap ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-data-configmap.yaml`
    

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: elk
  name: elasticsearch-data-config
  labels:
    app: elasticsearch
    role: data
data:
  elasticsearch.yml: |-
    cluster.name: ${CLUSTER_NAME}
    node.name: ${NODE_NAME}
    discovery.seed_hosts: ${NODE_LIST}
    cluster.initial_master_nodes: ${MASTER_NODES}
    network.host: 0.0.0.0
    node:
      master: false
      data: true
      ingest: false
    opendistro_security.ssl.http.enabled: false
    opendistro_security.disabled: true
```

`elk` Namespace ë‚´ì— Data Nodeì˜ Configmap ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤. `data: true` ì˜µì…˜ì„ í†µí•´ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë…¸ë“œë¡œ ì„¤ì •í•œë‹¤.

***data* Field Parameter**

| Parameter | Description | Details |
| --- | --- | --- |
| cluster.name | í´ëŸ¬ìŠ¤í„° ì´ë¦„ | í´ëŸ¬ìŠ¤í„°ëª…ì´ ë™ì¼í•´ì•¼ ë™ì¼í•œ í´ëŸ¬ìŠ¤í„°ë¡œ ì¸ì‹ |
| node.name | ë…¸ë“œ ì´ë¦„ | - |
| discovery.seed_hosts | í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•  ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ | - |
| cluster.initial_master_nodes | master í›„ë³´ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ | - |
| network.host | ë…¸ë“œì˜ IP | ì™¸ë¶€ ì ‘ê·¼ í—ˆìš© |
| node | ë…¸ë“œì˜ ê¸°ëŠ¥ | í•´ë‹¹ ë…¸ë“œëŠ” data ë…¸ë“œë¡œ ì‚¬ìš© |
| opendistro_security.disabled | ë³´ì•ˆ í”ŒëŸ¬ê·¸ì¸ ë¹„í™œì„±í™” | - |

- Data-Node Service ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-data-service.yaml`
    

```yaml
apiVersion: v1
kind: Service
metadata:
  namespace: elk
  name: elasticsearch-data
  labels:
    app: elasticsearch
    role: data
spec:
  ports:
  - port: 9300
    name: transport
  selector:
    app: elasticsearch
    role: data
```

 `elk` Namespace ë‚´ì— Data Nodeì— ëŒ€í•œ ì„œë¹„ìŠ¤ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

í•´ë‹¹ ì„œë¹„ìŠ¤ëŠ” `app=elasticsearch`, `role=data`Â ë ˆì´ë¸”ì„ ê°€ì§„ íŒŒë“œê°€ TCP 9300 í¬íŠ¸ë¡œ ë‹¤ë¥¸ ë…¸ë“œë“¤ê³¼ í†µì‹ í•  ìˆ˜ ìˆë„ë¡ í•˜ì˜€ë‹¤.

- Data-Node Statefulset ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-data-statefulset.yaml`
    

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  namespace: elk
  name: elasticsearch-data
  labels:
    app: elasticsearch
    role: data
spec:
  serviceName: "elasticsearch-data"
  selector:
    matchLabels:
      app: elasticsearch-data
      role: data
  replicas: 3
  template:
    metadata:
      labels:
        app: elasticsearch-data
        role: data
    spec:
      nodeSelector:
        Name: Data 
      containers:
      - name: elasticsearch-data
        image: amazon/opendistro-for-elasticsearch:1.13.2
        env:
        - name: CLUSTER_NAME
          value: elasticsearch
        - name: NODE_NAME
          value: elasticsearch-data
        - name: NODE_LIST
          value: elasticsearch-master,elasticsearch-data,elasticsearch-client
        - name: MASTER_NODES
          value: elasticsearch-master
        - name: "ES_JAVA_OPTS"
          value: "-Xms1G -Xmx1G"
        ports:
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: config
          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          readOnly: true
          subPath: elasticsearch.yml
        - name: elasticsearch-data-persistent-storage
          mountPath: /data/db
        imagePullPolicy: Always
      volumes:
      - name: config
        configMap:
          name: elasticsearch-data-config
      initContainers:
      - name: increase-vm-max-map
        image: busybox
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
  volumeClaimTemplates:
  - kind: PersistentVolumeClaim
    metadata:
      name: elasticsearch-data-persistent-storage
      annotations:
        volume.beta.kubernetes.io/storage-class: "gp2"
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: standard
      resources:
        requests:
          storage: 10Gi
```

 `elk` Namespace ë‚´ì— Data Nodeì˜ Statefulset ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ 3ê°œì˜ Data Node íŒŒë“œë¥¼ ë°°í¬í•œë‹¤. 

**Opensearch Data Node container**

Opendistro ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ Data Node íŒŒë“œë¥¼ ìƒì„±í•œë‹¤. Configmapì—ì„œ ì‚¬ìš©í•  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§€ì •í•´ì£¼ê³  ë¯¸ë¦¬ ìƒì„± í•´ ë†“ì€ Master Node ì„œë¹„ìŠ¤ì˜ í¬íŠ¸ë¡œ í¬íŠ¸ í¬ì›Œë”©í•œë‹¤. ì•ì„œ ìƒì„±í•œ Configmapì´ ì ìš©ë  ìˆ˜ ìˆë„ë¡ Configmap ë³¼ë¥¨ì„ ìƒì„±í•´ Opensearchì˜ ì„¤ì • íŒŒì¼ì— ë§ˆìš´íŠ¸í•œë‹¤. ë˜í•œ ë°ì´í„° ì €ì¥ ë° ìƒíƒœ ìœ ì§€ë¥¼ ìœ„í•´ PVC í…œí”Œë¦¿ì„ ì´ìš©í•´ì„œ elasticsearch-data-persistent-storageë¼ëŠ” ì´ë¦„ì˜ PVCë¥¼ ìƒì„±í•œë‹¤.

| Parameter | Descriptions | Details |
| --- | --- | --- |
| name | elasticsearch |  |
| image | ê° íŒŒë“œ ë³„ë¡œ ë™ì¼í•œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš© |  |
| env | Statefulsetì„ ì„¤ì •í•˜ê¸° ìœ„í•œ í™˜ê²½ë³€ìˆ˜ | elasticsearch-master,elasticsearch-data,elasticsearch-client |
| ports |  |  |
| volumeMounts |  |  |
| imagePullPolicy |  |  |

**Opensearch Data Node initContainer**

Linux í™˜ê²½ì—ì„œ Elasticsearchê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê¸° ìœ„í•´ ì„¤ì •í•´ì•¼í•  ìš”ì†Œë¥¼ ì´ˆê¸°í™”í•œë‹¤. `vm.max_map_count` ë³€ìˆ˜ ê°’ì„ ì¡°ì ˆí•˜ì—¬ Linux kernelì˜ ë©”ëª¨ë¦¬ ë§µ* ì˜ì—­ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì¡°ì‘í•œë‹¤. 

**Opensearch Data Node volumeClaimTemplates**

ë°ì´í„° ì €ì¥ ë° ìƒíƒœìœ ì§€ë¥¼ ìœ„í•´ PersistentVolumeClaimì„ ìƒì„±í•˜ì—¬ 10 ê¸°ê°€ë°”ì´íŠ¸ ìš©ëŸ‰ì˜ gp2 íƒ€ì… PersistentVolumeì„ ìƒì„±í•œë‹¤. ì½ê¸°-ì“°ê¸° ëª¨ë“œë¡œ ë³¼ë¥¨ì„ ë§ˆìš´íŠ¸í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•˜ê³  ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ì˜ ì´ë¦„ì„ standardë¡œ ì§€ì •í•˜ì—¬ PersistentVolumeClaimì„ PersistentVolumeì— ë°”ì¸ë”©í•œë‹¤.

### Ingest-Node ìƒì„±

ë¬¸ì„œ ë³€í™˜ ë° ì „ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ë©° ì¸ë±ì‹± ì „ì— ë¬¸ì„œë¥¼ ë³€í™˜í•˜ê³  ë³´ê°•í•˜ê¸° ìœ„í•´ INGEST íŒŒì´í”„ ë¼ì¸ì„ ë¬¸ì„œì— ì ìš©í•œë‹¤.

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/Elasticsearch/opensearch/client-node`

- Client-Node Configmap ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-client-configmap.yaml`
    

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: elk
  name: elasticsearch-client-config
  labels:
    app: elasticsearch
    role: client
data:
  elasticsearch.yml: |-
    cluster.name: ${CLUSTER_NAME}
    node.name: ${NODE_NAME}
    discovery.seed_hosts: ${NODE_LIST}
    cluster.initial_master_nodes: ${MASTER_NODES}
    network.host: 0.0.0.0
    node:
      master: false
      data: false
      ingest: true
    opendistro_security.ssl.http.enabled: false
    opendistro_security.disabled: true
```

`elk` Namespace ë‚´ì— Ingest Nodeì˜ Configmap ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤. `ingest: true` ì˜µì…˜ì„ ì‚¬ìš©í•´ ì¸ì œìŠ¤íŠ¸ ë…¸ë“œë¡œ ì„¤ì •í•œë‹¤.

***data* Field Parameter**

| Parameter | Description | Details |
| --- | --- | --- |
| cluster.name | í´ëŸ¬ìŠ¤í„° ì´ë¦„ | í´ëŸ¬ìŠ¤í„°ëª…ì´ ë™ì¼í•´ì•¼ ë™ì¼í•œ í´ëŸ¬ìŠ¤í„°ë¡œ ì¸ì‹ |
| node.name | ë…¸ë“œ ì´ë¦„ | - |
| discovery.seed_hosts | í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•  ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ | - |
| cluster.initial_master_nodes | master í›„ë³´ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ | - |
| network.host | ë…¸ë“œì˜ IP | ì™¸ë¶€ ì ‘ê·¼ í—ˆìš© |
| node | ë…¸ë“œì˜ ê¸°ëŠ¥ | í•´ë‹¹ ë…¸ë“œëŠ” Ingest ë…¸ë“œë¡œ ì‚¬ìš© |
| opendistro_security.disabled | ë³´ì•ˆ í”ŒëŸ¬ê·¸ì¸ ë¹„í™œì„±í™” | - |

- Client-Node Service ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-client-service.yaml`
    

```yaml
apiVersion: v1
kind: Service
metadata:
  namespace: elk
  name: elasticsearch-client
  labels:
    app: elasticsearch
    role: client
spec:
  ports:
  - port: 9300
    name: transport
  selector:
    app: elasticsearch
    role: client
```

 `elk` Namespace ë‚´ì— Ingest Nodeì— ëŒ€í•œ ì„œë¹„ìŠ¤ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤. í•´ë‹¹ ì„œë¹„ìŠ¤ëŠ” `app=elasticsearch`, `role=client`Â ë ˆì´ë¸”ì„ ê°€ì§„ íŒŒë“œê°€ TCP 9300 í¬íŠ¸ë¥¼ í†µí•´ ë‹¤ë¥¸ ë…¸ë“œì™€ í†µì‹ í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

íŒŒì¼ëª… : `elasticsearch-client-http.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  namespace: elk
  name: elasticsearch-client-http
  labels:
    app: elasticsearch
    role: client
spec:
  type: NodePort
  ports:
  - port: 9200
    name: client
    targetPort: 9200
    nodePort: 30000
  selector:
    app: elasticsearch
    role: client
```

 `elk` Namespace ë‚´ì— Ingest Nodeì— ëŒ€í•œ NodePort ì„œë¹„ìŠ¤ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.  `app=elasticsearch`, `role=client`Â ë ˆì´ë¸”ì„ ê°€ì§„ íŒŒë“œì˜ ì„œë¹„ìŠ¤ë¡œ ë™ì‘í•œë‹¤. í•´ë‹¹ ì„œë¹„ìŠ¤ì˜ ë…¸ë“œ í¬íŠ¸ 30000ì€ TCP 9200 í¬íŠ¸ë¡œ ë§¤í•‘ëœë‹¤.  ìœ„ì˜ ì„œë¹„ìŠ¤ëŠ” HTTP ì „ì†¡ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©ëœë‹¤.

- Client-Node Deployment ìƒì„±
    
    íŒŒì¼ëª… : `elasticsearch-client-deployment.yaml`
    

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: elk
  name: elasticsearch-client
  labels:
    app: elasticsearch
    role: client
spec:
  replicas: 3
  selector:
    matchLabels:
      app: elasticsearch
      role: client
  template:
    metadata:
      labels:
        app: elasticsearch
        role: client
    spec:
      nodeSelector:
        Name: Client
      containers:
      - name: elasticsearch-client
        image: amazon/opendistro-for-elasticsearch:1.13.2
        env:
        - name: CLUSTER_NAME
          value: elasticsearch
        - name: NODE_NAME
          value: elasticsearch-client
        - name: NODE_LIST
          value: elasticsearch-master,elasticsearch-data,elasticsearch-client
        - name: MASTER_NODES
          value: elasticsearch-master
        - name: "ES_JAVA_OPTS"
          value: "-Xms4G -Xmx4G"
        ports:
        - containerPort: 9200
          name: client
        - containerPort: 9300
          name: transport
        volumeMounts:
        - name: config
          mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
          readOnly: true
          subPath: elasticsearch.yml
        - name: storage
          mountPath: /data
      volumes:
      - name: config
        configMap:
          name: elasticsearch-client-config
      - name: "storage"
        emptyDir:
          medium: ""
      initContainers:
      - name: increase-vm-max-map
        image: busybox
        command: ["sysctl", "-w", "vm.max_map_count=262144"]
        securityContext:
          privileged: true
```

 `elk` Namespace ë‚´ì— Ingest Node Deployment ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ 1ê°œì˜ Ingest Node íŒŒë“œë¥¼ ìƒì„±í•œë‹¤. 

**Opensearch Ingest Node container**

Opendistro ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´  íŒŒë“œë¥¼ ìƒì„±í•œë‹¤. Configmapì—ì„œ ì‚¬ìš©í•  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§€ì •í•´ì£¼ê³  ë¯¸ë¦¬ ìƒì„±í•´ ë†“ì€ Client Node ì„œë¹„ìŠ¤ì˜ í¬íŠ¸ë¡œ í¬íŠ¸ í¬ì›Œë”©í•œë‹¤. ì•ì„œ ìƒì„±í•œ Configmapì´ ì ìš©ë  ìˆ˜ ìˆë„ë¡ Configmap ë³¼ë¥¨ì„ ìƒì„±í•´ Opensearchì˜ ì„¤ì • íŒŒì¼ì— ë§ˆìš´íŠ¸í•œë‹¤. ë˜í•œ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ì„ì‹œ ë³¼ë¥¨ì„ ìƒì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ì— ë§ˆìš´íŠ¸í•œë‹¤.


**Opensearch Ingest Node initContainer**

Linux í™˜ê²½ì—ì„œ Elasticsearchê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê¸° ìœ„í•´ ì„¤ì •í•´ì•¼ í•  ìš”ì†Œë¥¼ ì´ˆê¸°í™”í•œë‹¤. `vm.max_map_count` ë³€ìˆ˜ ê°’ì„ ì¡°ì ˆí•˜ì—¬ Linux kernelì˜ ë©”ëª¨ë¦¬ ë§µ* ì˜ì—­ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ì¡°ì‘í•œë‹¤. 


# 2.4.1.5. Logstash

## Logstash ì‚¬ìš© ëª©ì 

LogstashëŠ” ëª¨ë“  í˜•íƒœ, í¬ê¸°, ì†ŒìŠ¤ì˜ ë°ì´í„° ìˆ˜ì§‘í•˜ê³  í˜•ì‹ì´ë‚˜ ë³µì¡ì„±ì— ê´€ê³„ì—†ì´ ë‹¤ìŒê³¼ ê°™ì´ ë°ì´í„°ë¥¼ ë™ì ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¤€ë¹„í•˜ì—¬ ì›í•˜ëŠ” ê³³ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¼ìš°íŒ…í•´ì¤€ë‹¤. í˜„ì¬ í”„ë¡œì íŠ¸ì—ì„œëŠ” Logstashë¥¼ Kafkaì—ì„œ ì‡¼í•‘ëª° ëŒ“ê¸€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í•„ë“œë¥¼ ë‚˜ëˆˆ ë‹¤ìŒ Opensearchë¡œ ì „ì†¡í•˜ëŠ” ìš©ë„ë¡œ ì‚¬ìš©í•œë‹¤.

## Logstash ì¸í”„ë¼ ìƒì„±

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/Elasticsearch/logstash`

### **Logstash Configmap ìƒì„±**

Configmapì€ Logstashë¥¼ ìœ„í•œ ì„¤ì • íŒŒì¼ì´ë‹¤. Logstashì—ì„œëŠ” ì´ íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ input, output, filterë¥¼ ì •ì˜í•œë‹¤.

íŒŒì¼ëª… : `logstash-configmap.yaml`

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-config
  namespace: elk
```

 `elk` Namespace ë‚´ì— Logstash ì„¤ì • ê°’ì„ ê°€ì§„ `ConfigMap` ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

```yaml
data:
  # logstash conf
  logstash.yml: |
    http.host: "0.0.0.0"
    path.config: /usr/share/logstash/pipeline
    config.reload.automatic: true
```

`logstash.conf`ëŠ” ë¡œê·¸ ë°ì´í„°ì˜ íŒŒì´í”„ ë¼ì¸ ì„¤ì • íŒŒì¼ì´ë‹¤. ì™¸ë¶€ ì ‘ì†ì„ í—ˆìš©í•˜ê³ ,  Logstash íŒŒì´í”„ë¼ì¸ êµ¬ì„± íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •í•œë‹¤. `config.reload.automatic` ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì„¤ì • íŒŒì¼ ë³€ê²½ ì‹œ Logstashë¥¼ ì¬ì‹œì‘ í•  í•„ìš” ì—†ì´ ìˆ˜ì •ëœ conf íŒŒì¼ì„ reload í•˜ì—¬ ì ìš©í•œë‹¤.

[ **Input ]**

```yaml
  logstash.conf: |
    input {
      kafka {
        bootstrap_servers => "" 
        topics => ["smartstore.goodnara.review","smartstore.drstyle.review","smartstore.thecheaper.review","smartstore.180store.review","smartstore.cloony.review","smartstore.theshopsw.review"]
        consumer_threads => 3
        isolation_level => "read_committed"
        value_deserializer_class => "org.apache.kafka.common.serialization.StringDeserializer"
        auto_offset_reset => "earliest"
        group_id => "smartstore"
      }
    }
```

Logstash Inputì„ Kafka ë¸Œë¡œì»¤ë¡œ ì§€ì •í•˜ì—¬ Kafkaì— íì‰ë˜ì–´ìˆëŠ” ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ì˜¨ë‹¤.

**Logstash Input Field**

| Field | Descriptions | Details |
| --- | --- | --- |
| bootstrap_servers | ë¸Œë¡œì»¤ ì£¼ì†Œ (IP:9092) | - |
| topics | ë¸Œë¡œì»¤ í† í”½ëª… ë¦¬ìŠ¤íŠ¸ | ì‡¼í•‘ëª° ë³„ í† í”½ ë¦¬ìŠ¤íŠ¸ë¥¼ í‘œê¸°í•œë‹¤ |
| consumer_threads | ì»¨ìŠˆë¨¸ ì“°ë ˆë“œ | íŒŒí‹°ì…˜ ê°¯ìˆ˜ì™€ ë™ì¼í•˜ë‹¤ |
| isolation_level | íŠ¸ëœì­ì…˜ ê²©ë¦¬ìˆ˜ì¤€ | í´ë§ ë©”ì„¸ì§€ëŠ” ì»¤ë°‹ëœ íŠ¸ëœì­ì…˜ ë©”ì„¸ì§€ë§Œ ë°˜í™˜í•œë‹¤ |
| value_deserializer_class | ë ˆì½”ë“œê°’ ì—­ì§ë ¬í™”ì— ì‚¬ìš©ë˜ëŠ” JAVA Class (String) | - |
| group_id | ì»¨ìŠˆë¨¸ ê·¸ë£¹ì´ë¦„ì„ ì§€ì • | - |
| auto_offset_reset | Consumer groupìœ¼ë¡œ ì²˜ìŒ ë¸Œë¡œì»¤ì— ì§„ì…í–ˆì„ë•Œ, ë°ì´í„°ë¥¼ ê°€ì§€ê³ ì˜¤ëŠ” ì‹œì‘ì ì„ ì§€ì • | default ê°’ì€ latest, earliestëŠ” ì´ˆê¸°ì— consumer groupì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì ìš©ë˜ë¯€ë¡œ, ì¶”í›„ ì»¨ìŠˆë¨¸ë¥¼ ì¬ì‹œì‘ í•˜ë”ë¼ë„ ë°ì´í„° ì¤‘ë³µ ì´ìŠˆë¥¼ í•´ê²°í•  ìˆ˜ ìˆë‹¤. |

â• auto_offset_reset ì¶”ê°€ì„¤ëª…

ìƒí™©ì— ë”°ë¼ ë°ì´í„° ëˆ„ë½ì´ ë°œìƒí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— earliestë¡œ ì„¤ì •í•œë‹¤. earliest ì„¤ì •ì€ brokerì— ì»¨ìŠˆë¨¸ ê·¸ë£¹ì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì ìš©ë˜ë¯€ë¡œ, ìƒˆë¡œ ì»¨ìŠˆë¨¸ ê·¸ë£¹ì´ ìƒì„±ë˜ì—ˆë‹¤ë©´ ë°ì´í„°ì˜ ì²˜ìŒë¶€í„° ì½ì–´ ì˜¤ê²Œ ëœë‹¤. 

ë§Œì•½ ê¸°ì¡´ ì»¨ìŠˆë¨¸ ê·¸ë£¹ì´ ì§€ì •ëœ ìƒíƒœì—ì„œ ì»¨ìŠˆë¨¸ë¥¼ ì¬ì‹œì‘í–ˆë‹¤ë©´, ì»¨ìŠˆë¨¸ ê·¸ë£¹ì— ì´ë¯¸ ì˜¤í”„ì…‹ ì •ë³´ ë° ë©”íƒ€ ë°ì´í„°ê°€ ë‚¨ì•„ìˆê¸° ë•Œë¬¸ì— earliest ì„¤ì •ì€ ì ìš©ë˜ì§€ ì•Šê³ , ì˜¤í”„ì…‹ ì •ë³´ë¥¼ ì‹œì‘ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ê¸° ë•Œë¬¸ì— ë°ì´í„° ì¤‘ë³µ ì´ìŠˆë¥¼ ì˜ˆë°©í•  ìˆ˜ ìˆë‹¤.

[ **Filter ]**

Logstash í•„í„°ëŠ” ë°ì´í„°ê°€ ì†ŒìŠ¤ì—ì„œ ì €ì¥ì†Œë¡œ ì´ë™í•˜ëŠ” ê³¼ì •ì—ì„œ ê° ì´ë²¤íŠ¸ë¥¼ êµ¬ë¬¸ ë¶„ì„í•˜ê³  ëª…ëª…ëœ í•„ë“œë¥¼ ì‹ë³„í•˜ì—¬ êµ¬ì¡°ë¥¼ êµ¬ì¶•í•˜ë©°, ì´ë¥¼ ê³µí†µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° í†µí•©í•œë‹¤. í˜„ì¬ í”„ë¡œì íŠ¸ì—ì„œëŠ” Logstash filterë¥¼ ì‚¬ìš©í•˜ì—¬ timestamp í•„ë“œì— ì‘ì„±ì¼ì ë°ì´í„°ë¥¼ ì •ì œí•˜ì—¬ ì¸ë±ì‹±í•˜ê³  ëŒ“ê¸€ ë°ì´í„°ì˜ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•œë‹¤.

 `Timestamp` Field

```yaml
filter {
      # ----------------------- UTC(default) Timestamp -> KST Timestampë¡œ ë³€í™˜í•˜ê¸° -----------------
        mutate {
          add_field => {
            "timestamp" => ""   # timestamp í•„ë“œ ìƒì„±(ìƒˆë¡œ ìƒì„±ëœ í•„ë“œì˜ ê¸°ë³¸ ë°ì´í„° íƒ€ì…ì€ Stringì´ë‹¤.)
          }
        }
        # ruby ì½”ë“œë¡œ "@timestamp" í•„ë“œì˜ UTC ê¸°ì¤€ í˜„ì¬ ì‹œê°„ì— 9ì‹œê°„ì„ ë”í•œ ê°’ì„ timestamp í•„ë“œì— ì €ì¥í•œë‹¤.
        ruby {
          code => "event.set('timestamp', event.get('@timestamp').time.localtime('+09:00').strftime('%Y-%m-%d %H:%M:%S'))"
        }
        # timestamp í•„ë“œì˜ ë°ì´í„°ëŠ” Stringì´ë¯€ë¡œ ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ì§€ì •í•¨(ISO8601)
        # ISO8601 = 2019-01-26T17:00:00.000Z
        date {
          match => ["timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss"]
          target => "timestamp"   # date í•„í„°ê°€ ì ìš©ë  í•„ë“œ ì§€ì •
        }
        # timestampë¥¼ íŒŒì‹±í•˜ì—¬ yy mm ddë§Œ ì¶”ì¶œí•´ yymmdd í•„ë“œë¡œ ì €ì¥í•œë‹¤.
        grok {
          match => {
            "timestamp" => "\d\d%{INT:yy}-%{MONTHNUM:mm}-%{MONTHDAY:dd}%{GREEDYDATA}"
          }
          # yymmddë¥¼ ë©”íƒ€í•„ë“œë¡œ ì €ì¥í•œë‹¤.
          add_field => {
            "[@metadata][yymmdd]" => "%{yy}%{mm}%{dd}"
          }
        }
```

ğŸ“Œ **ì£¼ì˜** 

Opensearchì˜ indexë¥¼ ì¼ë³„ë¡œ ìƒì„±í•˜ê³  yyMMddë¥¼ postfixë¡œ ì„¤ì •í•˜ë ¤ê³  í•œë‹¤. ex) index-220803

í•˜ì§€ë§Œ LogstashëŠ” ê¸°ë³¸ì ìœ¼ë¡œ @timestampë¥¼ UTC+0 í‘œì¤€ì‹œë¡œ ë‚˜íƒ€ë‚´ê¸° ë•Œë¬¸ì— í•œêµ­ ì‹œê°„ê³¼ëŠ” ì•½ 9ì‹œê°„ì˜ ì°¨ì´ê°€ ë°œìƒí•˜ê²Œ ëœë‹¤.  ë”°ë¼ì„œ UTC+0 ë¥¼ KST(UTC+9)ë¡œ ë°”ê¿”ì„œ ì‚¬ìš©í•´ì•¼ í•œë‹¤.

**Filtering ê³¼ì •**

1. `mutate` filter pluginìœ¼ë¡œ String íƒ€ì…ì˜ timestamp í•„ë“œ ìƒì„±í•œë‹¤.
2. `ruby` filter pluginìœ¼ë¡œ "@timestamp" í•„ë“œì˜ UTC ê¸°ì¤€ í˜„ì¬ ì‹œê°„ì— 9ì‹œê°„ì„ ë”í•œ ê°’ì„ timestamp í•„ë“œì— ì €ì¥í•œë‹¤.

 3. `date` filter pluginìœ¼ë¡œ `String` íƒ€ì…ì¸ timestamp í•„ë“œì˜ ë°ì´í„°ë¥¼ ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³ 

(ISO8601 = 2019-01-26T17:00:00.000Z)

1. `grok` filter pluginìœ¼ë¡œ date í•„í„°ê°€ ì ìš©ë  í•„ë“œ ì§€ì • timestampë¥¼ íŒŒì‹±í•˜ì—¬ yy mm ddë§Œ ì¶”ì¶œí•´ yymmdd í•„ë“œë¡œ ì €ì¥í•˜ê³  yymmddë¥¼ ë©”íƒ€í•„ë“œë¡œ ì €ì¥í•œë‹¤.
    
    

 `message` Field

```yaml
# ------------------------- message í•„ë“œ ì •ì œ ----------------------
        # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŠ¹ìˆ˜ë¬¸ì 1ì°¨ ì œê±°í•œë‹¤.
        mutate {
          gsub => ["message", "[\"/{}]", ""]
        }
        # commaë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë©”ì„¸ì§€ í•„ë“œë¥¼ ë‚˜ëˆˆ í›„, colonì„ ê¸°ì¤€ìœ¼ë¡œ Key, value í˜•ì‹ìœ¼ë¡œ í•„ë“œë¥¼ ìƒì„±í•œë‹¤.
        kv {
          field_split => "," 
          value_split => ":"
        }
        # ì‚¬ìš©í•˜ì§€ ì•Šì„ í•„ë“œë“¤ì„ ì œê±°í•˜ê³  í•„ë“œì˜ ì´ë¦„ì„ ì¬ì„¤ì •í•œë‹¤.
        mutate {
          remove_field => [ "port","@version","host","message","@timestamp", "yy", "mm", "dd" ]
          rename => {" comment" => "comment"}
          rename => {" date" => "date"}
          rename => { " star" => "star" }
        }
        # star í•„ë“œë¥¼ Stringì—ì„œ Integer íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
        mutate {
          convert => {
            "star" => "integer"
          }
        }
    }
```

**Filtering ê³¼ì •**

1. `mutate` filter pluginì„ ì‚¬ìš©í•˜ì—¬ ì •ê·œ í‘œí˜„ì‹ìœ¼ë¡œ íŠ¹ìˆ˜ ë¬¸ìë¥¼ 1ì°¨ë¡œ ì œê±°í•œë‹¤.
2. `kv` filter pluginì„ í†µí•´ commaë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë©”ì„¸ì§€ í•„ë“œë¥¼ ë‚˜ëˆˆ í›„, colonì„ ê¸°ì¤€ìœ¼ë¡œ Key, value í˜•ì‹ìœ¼ë¡œ í•„ë“œë¥¼ ìƒì„±í•œë‹¤
3. ë¶„ì„ì— í•„ìš”í•˜ì§€ ì•Šì€ í•„ë“œëŠ” ì œê±°í•˜ê³  í•„ë“œì˜ ì´ë¦„ì„ ì¬ì„¤ì •í•œë‹¤.
4. ë¶„ì„ì— í•„ìš”í•œ star(í‰ì ) í•„ë“œì˜ ë°ì´í„° íƒ€ì…ì„ Integerë¡œ ë³€í™˜í•œë‹¤.

**[ Output ]**

```yaml
output {
      stdout { codec => rubydebug }
      # ------------- ì‡¼í•‘ëª° í† í”½ì— ë”°ë¼ ì¸ë±ìŠ¤ë¥¼ ë‚˜ëˆ„ì–´ ì €ì¥í•œë‹¤. -------------
      # ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ ëª¨ì Topic
      if [topic] =~ "smartstore.goodnara.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.goodnara.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.drstyle.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.drstyle.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.thecheaper.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.thecheaper.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      # ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ í‹°ì…”ì¸  Topic
      else if [topic] =~ "smartstore.180store.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.180store.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.cloony.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.cloony.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
      else if [topic] =~ "smartstore.theshopsw.review" {
        elasticsearch {
          hosts => "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
          index => "smartstore.theshopsw.review-%{[@metadata][yymmdd]}"
          codec => "json"
          timeout => 120
        }
      } # if end
    } # output end
```

Opensearchì— í† í”½ì— ë”°ë¼ ì¸ë±ìŠ¤ë¥¼ ë‚˜ëˆ„ì–´ ì €ì¥í•˜ë„ë¡ ì„¤ì •í–ˆë‹¤. ì•ì„œ ìƒì„±í–ˆë˜ ë©”íƒ€ë°ì´í„° í•„ë“œì˜ KST yymmdd ë¥¼ í™œìš©í•´ í† í”½ì´ë¦„-yymmdd í˜•ì‹ìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•˜ì—¬ ê° í† í”½ì— ëŒ€í•œ ì¸ë±ìŠ¤ë¥¼ ì¼ì ë³„ë¡œ ë‚˜ëˆ„ì–´ ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í–ˆë‹¤.

ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ **ëª¨ì** Topic

| Topic | Hosts | Index |
| --- | --- | --- |
| smartstore.goodnara.review | http://elasticsearch-client-http.elk.svc.cluster.local:9200 | smartstore.goodnara.review-%{[@metadata][yymmdd]} |
| smartstore.drstyle.review | http://elasticsearch-client-http.elk.svc.cluster.local:9200 | smartstore.drstyle.review-%{[@metadata][yymmdd]} |
| smartstore.thecheaper.review | http://elasticsearch-client-http.elk.svc.cluster.local:9200 | smartstore.thecheaper.review-%{[@metadata][yymmdd]} |

ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ `í‹°ì…”ì¸ ` Topic

| Topic | Hosts | Index |
| --- | --- | --- |
| smartstore.180store.review | http://elasticsearch-client-http.elk.svc.cluster.local:9200 | smartstore.180store.review-%{[@metadata][yymmdd]} |
| smartstore.cloony.review | http://elasticsearch-client-http.elk.svc.cluster.local:9200 | smartstore.cloony.review-%{[@metadata][yymmdd]} |
| smartstore.theshopsw.review | http://elasticsearch-client-http.elk.svc.cluster.local:9200 | smartstore.theshopsw.review-%{[@metadata][yymmdd]} |

### **Logstash Service ìƒì„±**

íŒŒì¼ëª… : `logstash-svc-nodeport.yaml`

```yaml
apiVersion: v1
kind: Service
metadata:
  name: logstash
  namespace: elk
spec:
  type: NodePort
  ports:
  - port: 5000
    targetPort: 5000
  selector:
    app: logstash
```

 `elk` Namespace ë‚´ì— Logstashì— ëŒ€í•œ NodePort ì„œë¹„ìŠ¤ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.  `app=elasticsearch` ë ˆì´ë¸”ì„ ê°€ì§„ íŒŒë“œì˜ ì„œë¹„ìŠ¤ë¡œ ë™ì‘í•œë‹¤. Logstash íŒŒë“œì˜  TCP 5000 í¬íŠ¸ë¡œ ìš”ì²­ì´ ì „ì†¡ë˜ë„ë¡ ì„¤ì •í–ˆë‹¤.

### **Logstash Deployment ìƒì„±**

Logstash íŒŒë“œë¥¼ ë°°í¬í•œë‹¤.

íŒŒì¼ëª… : `logstash-deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: logstash
  namespace: elk
spec:
  replicas: 1
  selector:
    matchLabels:
      app: logstash
  template:
    metadata:
      labels:
        app: logstash

    spec:
      nodeSelector:
        Name: Logstash
      volumes:
        - name: logstash-config-volume
          configMap:
            name: logstash-config
            items:
              - key: logstash.yml
                path: logstash.yml
        - name: logstash-pipeline-volume
          configMap:
            name: logstash-config
            items:
              - key: logstash.conf
                path: logstash.conf
      containers:
        - name: logstash
          image: docker.elastic.co/logstash/logstash:7.10.2
          resources:
            limits:
              cpu: 2000m
              memory: 2Gi
            requests:
              cpu: 1500m
              memory: 1.5G
          env:
            - name: LS_JAVA_OPTS
              value: '-Xmx1G -Xms1G'
          ports:
            - name: tcp
              containerPort: 5000
              protocol: TCP
          volumeMounts:
            - name: logstash-config-volume
              mountPath: /usr/share/logstash/config

            - name: logstash-pipeline-volume
              mountPath: /usr/share/logstash/pipeline
```

`elk` Namespace ë‚´ì— Logstash Deployment ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ 1ê°œì˜ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤.

nodeSelector ì˜µì…˜ìœ¼ë¡œ Logstash ë…¸ë“œ ê·¸ë£¹ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ë§ ë˜ë„ë¡ ì„¤ì •í•œë‹¤. ì´í›„ íŒŒë“œì˜ ë¦¬ì†ŒìŠ¤ë¥¼ ì„¤ì •í•˜ê³  Logstash ì»¨í…Œì´ë„ˆ í¬íŠ¸ë¥¼ 5000ë²ˆìœ¼ë¡œ ë³€ê²½í•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ì•ì„œ ì„¤ì •í–ˆë˜ íŒŒì´í”„ë¼ì¸ íŒŒì¼ì„ volumeMounts ì˜µì…˜ì„ í†µí•´ ë§ˆìš´íŠ¸í•œë‹¤.

**Logstash Volume**

logstash.conf íŒŒì¼ì€ volumeì—ì„œ ë§ˆìš´íŒ… ì‹œí‚¨ë‹¤.

**Logstash Container**

Docker repositoryì—ì„œ logstash ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤. íŒŒë“œì˜ ë¦¬ì†ŒìŠ¤ë¥¼ cpu 1200~2000 ë©”ê°€ë°”ì´íŠ¸, memory 1.5~2ê¸°ê°€ë°”ì´íŠ¸ ë¶€ì—¬í•œë‹¤. 

ğŸ“Œ **ì£¼ì˜**

- ConfigMapì—ì„œ ì§€ì •í•œ ì´ë¦„ì„ ì •í™•í•˜ê²Œ ë§¤ì¹­
- ì •í™•í•œ ë³¼ë¥¨ ê²½ë¡œ ì§€ì •


# 2.4.1.6. Kibana

## **Kibana** ì‚¬ìš© ëª©ì 

KibanaëŠ” Elasticsearchì—ì„œ ìƒ‰ì¸ ëœ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì‹œê°í™”í•œë‹¤. í˜„ì¬ í”„ë¡œì íŠ¸ì—ì„œëŠ” Opensearchì— ì €ì¥ë˜ì–´ ìˆëŠ” ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê°ì„± ë¶„ì„ì´ ì™„ë£Œ ëœ í‚¤ì›Œë“œë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

## **Kibana** **ì¸í”„ë¼ ìƒì„±**

- kibana ìƒì„±
- ì¸ë±ìŠ¤ íŒ¨í„´ ì¶”ê°€
- ìŠ¬ë™ ì•ŒëŒ ì„¤ì •
- ë¶„ì„ ë°ì´í„° ì¸ë±ìŠ¤ ìƒì„±
- ëŒ€ì‹œë³´ë“œ ìƒì„±

ì‘ì—… ë””ë ‰í† ë¦¬ : Datapipeline_Project/Elasticsearch/kibana

### [ Kibana Configmap ìƒì„± ]

íŒŒì¼ëª… : kibana-configmap.yaml

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: elk
  name: kibana-config
  labels:
    app: kibana
data:
  kibana.yml: |-
    server.host: 0.0.0.0
    elasticsearch:
      hosts: ${ELASTICSEARCH_HOSTS}
```

elk Namespace ë‚´ì— Kibana Configmap ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

ìœ„ config íŒŒì¼ìœ¼ë¡œ Kibanaê°€ ì™¸ë¶€ì™€ ì†Œí†µí•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤.

### [ Kibana Service ìƒì„± ]

íŒŒì¼ëª… : kibana-service.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  namespace: elk
  name: kibana
  labels:
    app: kibana
spec:
  type: LoadBalancer
  ports:
  - port: 80
    name: webinterface
    targetPort: 5601
  selector:
    app: kibana
```

elk Namespace ë‚´ì— app=kibana labelì„ ê°€ì§„ ë¦¬ì†ŒìŠ¤ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ë¡œë“œë°¸ëŸ°ì„œ íƒ€ì… ì„œë¹„ìŠ¤ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤. í•´ë‹¹ ì„œë¹„ìŠ¤ì˜ ë…¸ë“œ í¬íŠ¸ 80ì€ TCP 5601 í¬íŠ¸ì— ë§¤í•‘ëœë‹¤.

### [ Kibana Deployment ìƒì„± ]

íŒŒì¼ëª… : kibana-deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: elk
  name: kibana
  labels:
    app: kibana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      nodeSelector:
        Name: Kibana
      containers:
      - name: kibana
        image: tjswl950/ek_kib01:pluginRemove
        command: 
        ports:
        - containerPort: 5601
          name: webinterface
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
        volumeMounts:
        - name: config
          mountPath: /usr/share/kibana/config/kibana.yml
          readOnly: true
          subPath: kibana.yml
      volumes:
      - name: config
        configMap:
          name: kibana-config
```

elk Namespace ë‚´ì— Kibana Deployment ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ 1ê°œì˜ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤.

### Kibana Containers

Kibana ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤. Configmapì—ì„œ ì‚¬ìš©í•  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§€ì •í•´ì£¼ê³  ë¯¸ë¦¬ ìƒì„±í•´ë†“ì€ ë¡œë“œë°¸ëŸ°ì„œ ì„œë¹„ìŠ¤ì˜ í¬íŠ¸ë¡œ í¬íŠ¸ í¬ì›Œë”©í•œë‹¤. ì•ì„œ ìƒì„±í•œ Configmapì´ ì ìš©ë  ìˆ˜ ìˆë„ë¡ Configmap ë³¼ë¥¨ì„ ìƒì„±í•´ Opensearchì˜ ì„¤ì • íŒŒì¼ì— ë§ˆìš´íŠ¸í•œë‹¤. config íŒŒì¼ì—ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬ Opensearchë¥¼ í˜¸ìŠ¤íŒ… í•˜ë„ë¡ ì„¤ì •í•œë‹¤.

Parameter

- name: í‚¤ë°”ë‚˜ íŒŒë“œ ì´ë¦„
- image : í‚¤ë°”ë‚˜ íŒŒë“œ ì´ë¯¸ì§€
- env : í‚¤ë°”ë‚˜ config íŒŒì¼ì— ëª…ì‹œë˜ì–´ìˆëŠ” í™˜ê²½ ë³€ìˆ˜
- ports : ë§¤í•‘ í•  í¬íŠ¸ ë° ì´ë¦„
- volumeMounts : config íŒŒì¼ ë§ˆìš´íŠ¸


# 2.4.1.7. Jupyter Notebook

## Ubuntu ê·¸ë˜í”½ ë“œë¼ì´ë²„ ì„¤ì¹˜

- í…ì„œí”Œë¡œìš°ì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ CUDA ë²„ì „ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

![Untitled](img/Untitled%2014.png)

- NVIDIA ê·¸ë˜í”½ ì¹´ë“œ ë“œë¼ì´ë²„ ì„¤ì¹˜

ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í˜„ì¬ ì‚¬ìš©ì¤‘ì¸ ê·¸ë˜í”½ ì¹´ë“œì— ì„¤ì¹˜í•  ìˆ˜ ìˆëŠ” ë“œë¼ì´ë²„ë¥¼ í™•ì¸

```bash
$ ubuntu-drivers devices
```

```bash
== /sys/devices/pci0000:00/0000:00:1e.0 ==
modalias : pci:v000010DEd00001EB8sv000010DEsd000012A2bc03sc02i00
vendor   : NVIDIA Corporation
model    : TU104GL [Tesla T4]
manual_install: True
**driver   : nvidia-driver-460-server - distro non-free**
driver   : nvidia-driver-470-server - distro non-free
driver   : nvidia-driver-418-server - distro non-free
driver   : nvidia-driver-470 - distro non-free recommended
driver   : xserver-xorg-video-nouveau - distro free builtin
```

í™•ì¸ëœ ë“œë¼ì´ë²„ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì¹˜

```bash
$ sudo apt install nvidia-driver-460
```

ì¬ë¶€íŒ… í›„ í„°ë¯¸ë„ì—ì„œ nvidia-smi ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•œ ë“œë¼ì´ë²„ ë²„ì „ì´ ë§ëŠ”ì§€ í™•ì¸

```bash
$ nvidia-smi
```

```bash
Thu Aug  4 00:58:02 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.23.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |
| N/A   46C    P8    16W /  70W |      2MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

ê¸°ì¡´ CUDA ì‚­ì œ

ë°ë¹„ì•ˆ íŒ¨í‚¤ì§€ë¡œ ì„¤ì¹˜í•œê²Œ ì•„ë‹ˆë¼ë©´ ê°„ë‹¨íˆ ê¸°ì¡´ì— ì„¤ì¹˜ëœ CUDAë¥¼ ì œê±°í•  ìˆ˜ ìˆë‹¤.

```bash
$ sudo rm -rf /usr/local/cuda*
```

~/.bashrcë‚˜ /etc/profileì— ì¶”ê°€ë˜ì–´ìˆëŠ” CUDA ê´€ë ¨ ë˜í•œ ì œê±°

```bash
...
export PATH=$PATH:/usr/local/cuda-11.0/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.0/lib64
export CUDADIR=/usr/local/cuda-11.0
...
```

## CUDA 11.2 ì„¤ì¹˜

ì•„ë˜ ë§í¬ì— ì ‘ì†í•˜ì—¬ CUDA Toolkit 11.2.2 ì„ íƒ

[CUDA Toolkit Archive](https://developer.nvidia.com/cuda-toolkit-archive)

![Untitled](img/Untitled%2015.png)

ì„ íƒ í›„ Base Installer ì•„ë˜ì— ë³´ì´ëŠ” ëª…ë ¹ëŒ€ë¡œ ì„¤ì¹˜ ì§„í–‰

```bash
$ wget https://developer.download.nvidia.com/compute/cuda/11.2.2/local_installers/cuda_11.2.2_460.32.03_linux.run
$ sudo sh cuda_11.2.2_460.32.03_linux.run
```

Continue ì„ íƒ

![Untitled](img/Untitled%2016.png)

ë§Œì•½ gcc versionì„ í™•ì¸í•˜ë¼ëŠ” ì—ëŸ¬ê°€ ë‚˜ì˜¨ë‹¤ë©´ ê°œë°œì„ ìœ„í•œ í•„ìˆ˜ í”„ë¡œê·¸ë¨ì„ ì„¤ì¹˜í•œë‹¤.

```bash
$ sudo apt install build-essential
```

accept ì…ë ¥ í›„ ì—”í„°

![Untitled](img/Untitled%2017.png)

Driver í•­ëª©ì„ ì œì™¸ í›„ ì„¤ì¹˜

![Untitled](img/Untitled%2018.png)

ë‹¤ìŒ ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ CUDA Toolkit ê´€ë ¨ ì„¤ì •ì„ í™˜ê²½ ë³€ìˆ˜ì— ì¶”ê°€í•˜ê³  ì ìš© `$source /etc/profile`

```bash
$ sudo sh -c "echo 'export PATH=$PATH:/usr/local/cuda-11.2/bin' >> /etc/profile"
$ sudo sh -c "echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.2/lib64' >> /etc/profile"
$ sudo sh -c "echo 'export CUDADIR=/usr/local/cuda-11.2' >> /etc/profile"
```

`$ nvcc -V`

```bash
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Mon_Nov_30_19:08:53_PST_2020
Cuda compilation tools, release 11.2, V11.2.67
Build cuda_11.2.r11.2/compiler.29373293_0
```

## cuDNN 8.1.0 ì„¤ì¹˜

ì•„ë˜ ë§í¬ì— ì ‘ì†

[CUDA Deep Neural Network](https://developer.nvidia.com/cudnn)

cuDNNì„ ë‹¤ìš´ë°›ê¸° ìœ„í•´ì„  íšŒì›ê°€ì…ì„ í•´ì•¼í•œë‹¤.

íšŒì›ê°€ì…ê³¼ ë¡œê·¸ì¸ ì´í›„

![Untitled](img/Untitled%2019.png)

Archived cuDNN Releases í´ë¦­

ëª©ë¡ì—ì„œ Download cuDNN v8.1.0 í´ë¦­

![Untitled](img/Untitled%2020.png)

cuDNN Library for Linux (x86_64) ë§í¬ ë³µì‚¬

```bash
$ wget https://developer.nvidia.com/compute/machine-learning/cudnn/secure/8.1.0.77/11.2_20210127/cudnn-11.2-linux-x64-v8.1.0.77.tgz
$ tar xvzf cudnn-11.2-linux-x64-v8.1.0.77.tgz
$ sudo cp cuda/include/cudnn* /usr/local/cuda/include
$ sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64
$ sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*
```

ë§í¬íŒŒì¼ ìƒì„±

```bash
$ sudo ln -sf /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.1.0 /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_adv_train.so.8
$ sudo ln -sf /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.1.0  /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8
$ sudo ln -sf /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.1.0  /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8
$ sudo ln -sf /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.1.0  /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8
$ sudo ln -sf /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.1.0  /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_ops_train.so.8
$ sudo ln -sf /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.1.0 /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8
$ sudo ln -sf /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn.so.8.1.0  /usr/local/cuda-11.2/targets/x86_64-linux/lib/libcudnn.so.8
```

## Ubuntu ì•„ë‚˜ì½˜ë‹¤

[Anaconda | The World's Most Popular Data Science Platform](https://www.anaconda.com/)

ì•„ë‚˜ì½˜ë‹¤: íŒ¨í‚¤ì§€ ê´€ë¦¬ì™€ ë””í”Œë¡œì´ë¥¼ ë‹¨ìˆœì¼€ í•  ëª©ì ìœ¼ë¡œ ê³¼í•™ ê³„ì‚°ì„ ìœ„í•œ íŒŒì´ì¬ê³¼ R í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì˜ ì˜¤í”ˆì†ŒìŠ¤ ë°°í¬íŒì´ë‹¤. íŒ¨í‚¤ì§€ ë²„ì „ë“¤ì€ íŒ¨í‚¤ì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ condaë¥¼ í†µí•´ ê´€ë¦¬ëœë‹¤. 

ì„¤ì¹˜

```bash
$ wget https://repo.anaconda.com/archive/Anaconda3-2022.05-Linux-x86_64.sh
$ bash Anaconda3-2022.05-Linux-x86_64.sh
```

Anaconda ê°€ìƒí™˜ê²½(base) í™œì„± / ë¹„í™œì„±

í™œì„± - `conda activate base`

ë¹„í™œì„± - `conda deactivate`

pipë¥¼ ì´ìš©í•´ì„œ Jupyter Notebook ì„¤ì¹˜

```bash
$ pip install notebook
```

config íŒŒì¼ ìƒì„±

```bash
$ jupyter notebook --generate-config
```

ì„œë²„ ë¹„ë°€ë²ˆí˜¸ ìƒì„± - python

```python
from notebook.auth import passwd
passwd()
```

ìƒì„±í•  ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ í›„ ìƒì„±ëœ í•´ì‰¬ ë³µì‚¬

ìƒì„±ëœ ê²½ë¡œì˜ íŒŒì¼ ì‹¤í–‰

```python
$ vi ~/.jupyter/jupyter_notebook_config.py
```

ì£¼ìš” ì„¤ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤

```python
#ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
c.NotebookApp.password # ì£¼ì„ í•´ì œ í›„ ë³µì‚¬í•´ë‘” í•´ì‰¬ ë¶™ì—¬ë„£ê¸°

#ê¸°ë³¸ ì‘ì—… ê²½ë¡œ ì„¤ì •
c.NotebookApp.notebook_dir # ì£¼ì„í•´ì œ í›„ ì‹¤í–‰í•˜ê³ ì í•˜ëŠ” dir ì§€ì •

#ì™¸ë¶€ ì ‘ì† í—ˆìš©
c.NotebookApp.allow_originÂ =Â '*'

#ì„œë²„ë¥¼ ë„ìš¸ ì•„ì´í”¼ ì„¤ì •
c.NotebookApp.ipÂ =Â '0.0.0.0'

#ì£¼í”¼í„° ì„œë²„ ì‹¤í–‰ ì‹œ ë¸Œë¼ìš°ì € ì‹¤í–‰ X
c.NotebookApp.open_browserÂ =Â False
```

Jupyter Notebook ì ‘ê·¼ ê°€ëŠ¥

![Untitled](img/Untitled%2021.png)


# 2.4.1.7. Kibana

## Kibana ì‚¬ìš© ëª©ì 

KibanaëŠ” Elasticsearchì—ì„œ ìƒ‰ì¸ ëœ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ì‹œê°í™”í•œë‹¤. í˜„ì¬ í”„ë¡œì íŠ¸ì—ì„œëŠ” Opensearchì— ì €ì¥ë˜ì–´ ìˆëŠ” ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì°¨íŠ¸ë¡œ ì‹œê°í™”í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ê°ì„± ë¶„ì„ì´ ì™„ë£Œ ëœ í‚¤ì›Œë“œë¥¼ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. 

## Kibana ì¸í”„ë¼ ìƒì„±

- kibana ìƒì„±
- ì¸ë±ìŠ¤ íŒ¨í„´ ì¶”ê°€
- ìŠ¬ë™ ì•ŒëŒ ì„¤ì •
- ë¶„ì„ ë°ì´í„° ì¸ë±ìŠ¤ ìƒì„±
- ëŒ€ì‹œë³´ë“œ ìƒì„±

ì‘ì—… ë””ë ‰í† ë¦¬ : `Datapipeline_Project/Elasticsearch/kibana`

### **Kibana Configmap ìƒì„±**

íŒŒì¼ëª… : `kibana-configmap.yaml`

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: elk
  name: kibana-config
  labels:
    app: kibana
data:
  kibana.yml: |-
    server.host: 0.0.0.0
    elasticsearch:
      hosts: ${ELASTICSEARCH_HOSTS}
```

`elk` Namespace ë‚´ì— Kibana Configmap ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

ìœ„ config íŒŒì¼ìœ¼ë¡œ Kibanaê°€ ì™¸ë¶€ì™€ ì†Œí†µí•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤.

### **Kibana Service ìƒì„±**

íŒŒì¼ëª… : `kibana-service.yaml`

```yaml
---
apiVersion: v1
kind: Service
metadata:
  namespace: elk
  name: kibana
  labels:
    app: kibana
spec:
  type: LoadBalancer
  ports:
  - port: 80
    name: webinterface
    targetPort: 5601
  selector:
    app: kibana
```

 `elk` Namespace ë‚´ì— `app=kibana` labelì„ ê°€ì§„ ë¦¬ì†ŒìŠ¤ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ” ë¡œë“œë°¸ëŸ°ì„œ íƒ€ì… ì„œë¹„ìŠ¤ ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•œë‹¤.  í•´ë‹¹ ì„œë¹„ìŠ¤ì˜ ë…¸ë“œ í¬íŠ¸ 80ì€ TCP 5601 í¬íŠ¸ì— ë§¤í•‘ëœë‹¤.

### **Kibana Deployment ìƒì„±**

íŒŒì¼ëª… : `kibana-deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: elk
  name: kibana
  labels:
    app: kibana
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      nodeSelector:
        Name: Kibana
      containers:
      - name: kibana
        image: tjswl950/ek_kib01:pluginRemove
        command: 
        ports:
        - containerPort: 5601
          name: webinterface
        env:
        - name: ELASTICSEARCH_HOSTS
          value: "http://elasticsearch-client-http.elk.svc.cluster.local:9200"
        volumeMounts:
        - name: config
          mountPath: /usr/share/kibana/config/kibana.yml
          readOnly: true
          subPath: kibana.yml
      volumes:
      - name: config
        configMap:
          name: kibana-config
```

 `elk` Namespace ë‚´ì— Kibana Deployment ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ 1ê°œì˜ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤.

**Kibana Containers**

Kibana ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ íŒŒë“œë¥¼ ìƒì„±í•œë‹¤. Configmapì—ì„œ ì‚¬ìš©í•  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì§€ì •í•´ì£¼ê³  ë¯¸ë¦¬ ìƒì„±í•´ë†“ì€ ë¡œë“œë°¸ëŸ°ì„œ ì„œë¹„ìŠ¤ì˜ í¬íŠ¸ë¡œ í¬íŠ¸ í¬ì›Œë”©í•œë‹¤. ì•ì„œ ìƒì„±í•œ Configmapì´ ì ìš©ë  ìˆ˜ ìˆë„ë¡ Configmap ë³¼ë¥¨ì„ ìƒì„±í•´ Opensearchì˜ ì„¤ì • íŒŒì¼ì— ë§ˆìš´íŠ¸í•œë‹¤. config íŒŒì¼ì—ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬ Opensearchë¥¼ í˜¸ìŠ¤íŒ…í•˜ë„ë¡ ì„¤ì •í•œë‹¤.

| Parameter | Descriptions |
| --- | --- |
| name | í‚¤ë°”ë‹¤ íŒŒë“œ ì´ë¦„ |
| image | í‚¤ë°”ë‚˜ íŒŒë“œ ì´ë¯¸ì§€ |
| env | í‚¤ë°”ë‚˜ config íŒŒì¼ì— ëª…ì‹œë˜ì–´ìˆëŠ” í™˜ê²½ ë³€ìˆ˜ |
| ports | ë§¤í•‘í•  í¬íŠ¸ ë²ˆí˜¸ ë° ì´ë¦„ |
| volumeMounts | config íŒŒì¼ ë§ˆìš´íŠ¸ |

## 2.4.2. Usecase ì‹œë‚˜ë¦¬ì˜¤ ì‹œí–‰

# [ SFR-001 ] ëŒ“ê¸€ í¬ë¡¤ë§ì„ í†µí•œ ì‡¼í•‘ëª° ë°ì´í„° ì¶”ì¶œ

## **í¬ë¡¤ëŸ¬ ë°°ì¹˜ ì‘ì—…**

ë§¤ì¼ 0ì‹œì— ë°°ì¹˜ ì‘ì—… ì§„í–‰í•˜ë©° ë¹„ìš© ì ˆê°ì„ ìœ„í•´ í´ëŸ¬ìŠ¤í„°ë¥¼ ì˜¤í† ìŠ¤ì¼€ì¼ë§í•œë‹¤. OOMKILLED(Out Of Memory Killed) ì˜¤ë¥˜ ì§€ì†ì  ë°œìƒí•˜ì—¬ t3.medium í´ëŸ¬ìŠ¤í„°ë¥¼ 6ê°œë¡œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ í•˜ë„ë¡ ì„¤ì •í•˜ì˜€ë‹¤.

(ê¸°ì¡´ 1ê°œì˜ í´ëŸ¬ìŠ¤í„°ì—ì„œ, ë°°ì¹˜ ì‘ì—… ì§„í–‰ì‹œ 6ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¡œ êµ¬ì„±)

ğŸ“Œ **í¬ë¡¤ëŸ¬ ë°°í¬ ì „ í•„ìˆ˜ ìˆ˜í–‰ ìš”ì†Œ**

Cluster Autoscaler ì‹œ ë…¸ë“œ ê°ì†Œ ì˜ˆì™¸ ì˜µì…˜ìœ¼ë¡œ ë…¸ë“œ ì‚¬ìš©ë¥ ì´ ì €ì¡°í•˜ì—¬ë„ í•´ë‹¹ ë…¸ë“œëŠ” ì¶•ì†Œë˜ì§€ ì•Šë„ë¡ í•œë‹¤.

1. EKSë¥¼ íŒ¨ì¹˜í•˜ì—¬Â `cluster-autoscaler.kubernetes.io/safe-to-evict`ì„ Cluster Autoscaler podsì— ì¶”ê°€

```bash
kubectl patch deployment cluster-autoscaler \
  -n kube-system \
  -p '{"spec":{"template":{"metadata":{"annotations":{"cluster-autoscaler.kubernetes.io/safe-to-evict": "false"}}}}}'
```

1. Cluster Autoscaler ë°°í¬ë¥¼ í¸ì§‘

```bash
kubectl -n kube-system edit deployment.apps/cluster-autoscaler
```

1. cluster-autoscaler ì»¨í…Œì´ë„ˆ ëª…ë ¹ì„ í¸ì§‘í•˜ì—¬ ë‹¤ìŒ ì˜µì…˜ì„ ì¶”ê°€

```yaml
...
spec:
      containers:
      - command
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/<YOUR CLUSTER NAME>
        - --balance-similar-node-groups
        - --skip-nodes-with-system-pods=false
...
```

1. Cluster Autoscaler ì´ë¯¸ì§€ íƒœê·¸ë¥¼ ì´ì „ ë‹¨ê³„ì—ì„œ ì ì–´ë‘” ë²„ì „ìœ¼ë¡œ ì„¤ì •í•œë‹¤. `1.22.n` ì„ ì‚¬ìš©ìì˜ ê³ ìœ í•œ ê°’ìœ¼ë¡œ êµì²´í•œë‹¤.

```yaml
kubectl set image deployment cluster-autoscaler \
  -n kube-system \
  cluster-autoscaler=k8s.gcr.io/autoscaling/cluster-autoscaler:v<1.22.n>
```

`kafka_producer_pod.yaml`

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  namespace: crawler
  name: crawler-1
  labels:
    app: crawler
spec:
  schedule: "00 00 * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: crawler
          annotations:
            "cluster-autoscaler.kubernetes.io/safe-to-evict": "false"
        spec:
          nodeSelector:
            Name: Crawler
          containers:
          - name: crawler-1
            image: ddung1203/kafkacrawler:10
            resources:
              requests:
                memory: "3000Mi"
                cpu: "1500m"
              limits:
                memory: "3000Mi"
                cpu: "1500m"
            env:
            - name: url
              value: 'https://smartstore.naver.com/goodnara/products/371623918?NaPm=ct%3Dl5w25k6o|ci%3D4e5b6e75c093e7e939dee9b6ff5db9194e928107|tr%3Dslsl|sn%3D197648|hk%3D86d8d2e3aaac865dd5cb51d5c5a1255db23627c9'
            - name: topic
              value: smartstore.goodnara.review
            - name: server
              value: "3.38.10.106:9092,3.34.18.190:9092,13.209.146.71:9092"
            command: ["/bin/sh", "-c"]
            args: ["cd /Datapipeline_Project/crawler; ./kafka_producer.py"]
          restartPolicy: Never
```

### í¬ë¡¤ëŸ¬ ì½”ë“œ ìƒì„¸ ì„¤ëª…

> **ëª¨ë“ˆ Import**
> 

```python
#!/usr/bin/python3
import os
import time
import json
from kafka import KafkaProducer
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException
from selenium.common.exceptions import ElementNotInteractableException
```

**ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í•¨ìˆ˜**

| Module | Function | Description |
| --- | --- | --- |
| os | - | OSì— ì˜ì¡´í•˜ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ ì œê³µ |
| time | - | ì‹œì‘ ì‹œê°„ ì¸¡ì •
sleep | - | ëª…ì‹œì  ëŒ€ê¸° |
| json | - | íŒŒì´ì¬ì—ì„œ JSON í˜•íƒœì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì‚¬ìš© |
| kafka | KafkaProducer | íŒŒì´ì¬ì—ì„œ ì¹´í”„ì¹´ í”„ë¡œë“€ì„œ í˜¸ì¶œ |
| selenium | webdriver | ë‹¤ì–‘í•œ ì…€ë ˆë‹ˆì›€ Browser ë“œë¼ì´ë²„ ì„¤ì¹˜ |
| selenium.webdriver.common.by | By | í•´ë‹¹ ê²½ë¡œì—ì„œ Elementë¥¼ ì°¾ê¸° ìœ„í•¨ |
| selenium.common.exceptions | NoSuchElementException | ì›¹ í˜ì´ì§€ ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ìš”ì†Œë¥¼ ì°¾ê±°ë‚˜ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ì„ ë•Œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸ ì²˜ë¦¬  |
| selenium.common.exceptions | ElementNotInteractableException | í´ë¦­í•  ì„±ì§ˆì˜ Elementê°€ ì¡´ì¬í•  ë•Œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸ ì²˜ë¦¬ |

> **ì…€ë ˆë‹ˆì›€ ì‚¬ìš©ì„ ìœ„í•œ í¬ë¡¬ ë“œë¼ì´ë²„ ë¶ˆëŸ¬ì˜¤ê¸°**
> 

í¬ë¡¬ ë“œë¼ì´ë²„ë¥¼ ì„¤ì¹˜í•œ ë‹¤ìŒ ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¥¼ ì‹¤í–‰í•œë‹¤.

`user_agent`ì™€ `options`ë¥¼ ìƒì„±í•˜ì—¬ Ubuntu í¬ë¡¤ëŸ¬ê°€ ì‡¼í•‘ëª°ì—ì„œ ì‚¬ìš©ìë¡œ ì¸ì‹ë  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

```python
def chromeWebdriver():
    options = webdriver.ChromeOptions()]
    driver = webdriver.Chrome('./chromedriver',options=options)
    # 1. User-Agent ì„¤ì •
    user_agent = 'Mozilla/5.0 (X11; Linux X86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'
    options.add_argument('user-agent={0}'.format(user_agent))
    # 2. Headless ëª¨ë“œ ì„¤ì •
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')

    return driver
```

**ì‚¬ìš© ë³€ìˆ˜**

| Parameter | Description |
| --- | --- |
| driver | í¬ë¡¬ ë“œë¼ì´ë²„ ì‹¤í–‰ |
| user_agent | í”„ë¡œê·¸ë¨ì„ ì‚¬ìš©ìë¡œ ì¸ì‹ |
| options | ì…€ë ˆë‹ˆì›€ì„ Headless ëª¨ë“œë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì˜µì…˜ |

1. User-Agent ì„¤ì •
    
    í•´ë‹¹ ì„¤ì •ì„ í†µí•´ ì‡¼í•‘ëª° ì‚¬ì´íŠ¸ê°€ í¬ë¡¤ë§ ì„œë²„ë¥¼ í”„ë¡œê·¸ë¨ì´ ì•„ë‹Œ ì‚¬ìš©ìë¡œ ì¸ì‹í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤.
    
2. Headless ëª¨ë“œ ì„¤ì •
    
    Ubuntu OSì—ì„œëŠ” GUIë¥¼ ì œê³µí•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Headless ëª¨ë“œë¡œ ì…€ë ˆë‹ˆì›€ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì›¹í˜ì´ì§€ë¥¼ ë Œë”ë§í•´ì•¼í•œë‹¤.
    

> **Kafka URL, Topic, Server ë¶ˆëŸ¬ì˜¤ê¸°**
> 

```python
url=os.environ.get("url")
topic=os.environ.get("topic")
server=os.environ.get("server")
print(url)
print(topic)
print(server)
```

í™˜ê²½ë³€ìˆ˜ë¡œ ì§€ì •í•œ `url`, `topic`, `server` ê°’ì„ ë¶ˆëŸ¬ ì˜¨ í›„ `print`ë¥¼ ì‚¬ìš©í•˜ì—¬ í™•ì¸í•œë‹¤.

> **í¬ë¡¬ ë“œë¼ì´ë²„ë¡œ urlì— ì ‘ì†**
> 

```python
driver = chromeWebdriver()
driver.get(url)
time.sleep(2)
```

`driver.get(url)` ë¥¼ í†µí•´ í¬ë¡¬ ë“œë¼ ì§€ì • ëœ urlì˜ ì›¹ í˜ì´ì§€ì— ì ‘ì†í•œë‹¤.

`time.sleep(2)` ì— ì˜í•´ ì ‘ì† ì§€ì—° ì‹œê°„ì´ 2ì´ˆë¡œ ì„¤ì •ë˜ì—ˆê¸° ë•Œë¬¸ì— í¬ë¡¤ëŸ¬ëŠ” 2ì´ˆ ë‚´ì— ì ‘ì†ì„ ì™„ë£Œí•´ì•¼í•œë‹¤.

> **ë³€ìˆ˜ ì´ˆê¸°í™”**
> 

```python
comment=[]
star=[]
date=[]

# ëŒ“ê¸€ í˜ì´ì§€ ì¸ë±ìŠ¤ (1-10:ë‹¤ìŒ)
num = 2
```

`comment`(ëŒ“ê¸€), `star`(ë³„ì ), `date`(ì‘ì„± ì¼ì) listì™€ ëŒ“ê¸€ í˜ì´ì§€ ì¸ë±ìŠ¤ ë³€ìˆ˜ `num`ì„ ì´ˆê¸°í™” í•œë‹¤.

> **Kafka Producer ìƒì„±**
> 

```python
# kafka producer
producer = KafkaProducer(acks=1, compression_type='gzip', bootstrap_servers=[server], value_serializer=lambda x: json.dumps(x, ensure_ascii=False).encode('utf-8'))
```

í”„ë¡œì íŠ¸ì˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì—ì„œ Python í¬ë¡¤ëŸ¬ëŠ” Kafkaì˜ Producerë¡œ ë™ì‘í•œë‹¤.

KafkaëŠ” ê¸°ë³¸ì ìœ¼ë¡œ Javaë¥¼ ì œê³µí•˜ì§€ë§Œ Python ë“± ThirdPartyì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•´ì¤€ë‹¤.

**í”„ë¡œë“€ì„œ ì†ì„±**

| Option | Description | Details |
| --- | --- | --- |
| acks | ë©”ì„¸ì§€ ìš”ì²­ í›„
ìš”ì²­ ì™„ë£Œ ì „ ìŠ¹ì¸ ìˆ˜ | ë©”ì„¸ì§€ ë°›ì€ ì‚¬ëŒì´ ë©”ì„¸ì§€ë¥¼ ì˜ ë°›ì•˜ëŠ”ì§€ ì²´í¬í•˜ëŠ” ì˜µì…˜ |
| compression_type | ë°ì´í„° ì••ì¶• í¬ë©§
(None, gzip, snappy, lz4 ì¤‘ ì„ íƒ) | gzip í˜•ì‹ìœ¼ë¡œ ì••ì¶•í•˜ì—¬ ì „ë‹¬ |
|  bootstrap_servers | ìµœì´ˆ ì—°ê²°ì„ ìœ„í•œ ë¸Œë¡œì»¤ ì„œë²„ ëª©ë¡ | ê³ ì • IPê°€ ë¶€ì—¬ ëœ Kafka Broker ì„œë²„ ì£¼ì†Œ ëª©ë¡ |
| value_serializer | ë©”ì„¸ì§€ì˜ ê°’ì„ ì§ë ¬í™” í• 
ì§ë ¬ì²˜ë¦¬ê¸° | - json.dump() ë©”ì†Œë“œ
  : json ë”•ì…”ë„ˆë¦¬ë¥¼ ìœ ë‹ˆì½”ë“œë¡œ í‘œí˜„
- ensure_ascii=False ì˜µì…˜
  : ë°ì´í„°ë¥¼ í•œê¸€ë¡œ ì €ì¥
- encode('utf-8') 
  : ë¬¸ìì—´(ìœ ë‹ˆì½”ë“œ)ì„ byte ì½”ë“œë¡œ ë³€í™˜ |

> **í¬ë¡¤ë§ ì‹œì‘**
> 

**ì½”ë“œ ìƒì„¸ ì„¤ëª…**

- ì‹œê°„ ì¸¡ì •

```python
start=time.time()
```

í¬ë¡¤ë§ì„ ì‹œì‘í•˜ê¸° ì „, time ëª¨ë“ˆì˜ time() í•¨ìˆ˜ë¥¼ `start` ë³€ìˆ˜ë¡œ ì§€ì •í•˜ì—¬ í¬ë¡¤ë§ ì‹œê°„ì„ ì¸¡ì •í•œë‹¤.

- í˜ì´ì§€ë¥¼ ë„˜ê²¨ê°€ë©° ê³„ì†ì ìœ¼ë¡œ í¬ë¡¤ë§ ì‹¤í–‰

```python
         while True:

          ...

          num += 1
          if num == 13:
            num = 2
```

í¬ë¡¤ë§ì´ ê³„ì†ì ìœ¼ë¡œ ì§„í–‰ë  ìˆ˜ ìˆë„ë¡ ë¬´í•œ ë°˜ë³µë¬¸ `while True` ë¥¼ ì‚¬ìš©í•œë‹¤.

ëŒ“ê¸€ í˜ì´ì§€ëŠ” ì´ 10ê°œì˜ ì¸ë±ìŠ¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆê¸° ë•Œë¬¸ì— `num` ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì—¬ 10ê°œì˜ ì¸ë±ìŠ¤ê°€ ì§€ë‚˜ë©´ ë‹¤ìŒ ëŒ“ê¸€í˜ì´ì§€ë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤.

```python
  time.sleep(1)
  tmp = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[2]/div[2]/div/div[3]/div[6]/div/div[3]/div/div[2]/div/div/a[{}]'.format(num))
  tmp.send_keys("\n")
```

ì‚¬ìš© í•¨ìˆ˜

| Function | Description |
| --- | --- |
| time.sleep() | ì§€ì—°ì‹œê°„ ì¸¡ì • (ì‹¤ìˆ˜ ë‹¨ìœ„ ì§€ì • ê°€ëŠ¥) |
| driver.find_element(By.<ì†ì„±>, '<ì†ì„± ê°’>') | By.XPATH : íƒœê·¸ì˜ ê²½ë¡œì—ì„œ ì¶”ì¶œ |
| tmp.send_keys("\n") | ê²€ìƒ‰ì°½ì— ì—”í„° ì…ë ¥ |

ìš°ì„  `time.sleep()` í•¨ìˆ˜ë¡œ 1ì´ˆ ì§€ì—°ì‹œê°„ì„ ì„¤ì •í•œë‹¤. ì´ëŠ” í¬ë¡¤ëŸ¬ê°€ ë‹¤ìŒ ëŒ“ê¸€ í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ê¸° ìœ„í•´ ë„˜ì–´ê°ˆ ë•Œ ë°œìƒí•˜ëŠ” ì§€ì—°ì„ ê³ ë ¤í•˜ì—¬ ì„¤ì •í•˜ì˜€ë‹¤. (ì‹¤í—˜ ê²°ê³¼ 1ì´ˆì˜ ì§€ì—°ì‹œê°„ì„ ì„¤ì •í–ˆì„ ë•Œê°€ ê°€ì¥ ë¬¸ì œ ì—†ì´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆì—ˆë‹¤.) 

`driver.find_element(By.<ì†ì„±>, '<ì†ì„± ê°’>')` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ íƒœê·¸ì˜ ê²½ë¡œì— í•´ë‹¹í•˜ëŠ” ê³³(ëŒ“ê¸€ í˜ì´ì§€ ì¸ë±ìŠ¤)ì—ì„œ ì—”í„°ë¥¼ ì…ë ¥í•˜ì—¬ ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™í•œë‹¤. 

- ëŒ“ê¸€, ë³„ì , ì‘ì„±ì¼ì í¬ë¡¤ë§

```python
 for cmt in range(1,21):
          #comment
          time.sleep(1)
          list_comnt = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[2]/div[2]/div/div[3]/div[6]/div/div[3]/div/div[2]/ul/li[{}]/div/div/div/div[1]/div/div[1]/div[2]/div/span'.format(cmt))
          if list_comnt.text == 'í•œë‹¬ì‚¬ìš©ê¸°':
              list_comnt = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[2]/div[2]/div/div[3]/div[6]/div/div[3]/div/div[2]/ul/li[{}]/div/div/div/div[1]/div/div[1]/div[2]/div/span[2]'.format(cmt))
            if list_comnt.text == 'ì¬êµ¬ë§¤':
                list_comnt = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[2]/div[2]/div/div[3]/div[6]/div/div[3]/div/div[2]/ul/li[{}]/div/div/div/div[1]/div/div[1]/div[2]/div/span[3]'.format(cmt))
          elif list_comnt.text == 'ì¬êµ¬ë§¤':
              list_comnt = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[2]/div[2]/div/div[3]/div[6]/div/div[3]/div/div[2]/ul/li[{}]/div/div/div/div[1]/div/div[1]/div[2]/div/span[2]'.format(cmt))
          comment.append(list_comnt.text)

          #star
          list_star = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[2]/div[2]/div/div[3]/div[6]/div/div[3]/div/div[2]/ul/li[{}]/div/div/div/div[1]/div/div[1]/div[1]/div[2]/div[1]/em'.format(cmt))
          star.append(list_star.text)
          
          #date
          list_date = driver.find_element(By.XPATH, '/html/body/div/div/div[3]/div[2]/div[2]/div/div[3]/div[6]/div/div[3]/div/div[2]/ul/li[{}]/div/div/div/div[1]/div/div[1]/div[1]/div[2]/div[2]/span'.format(cmt))
          date.append(list_date.text)
```

ë³€ìˆ˜

| Parameter | Description |
| --- | --- |
| list_comnt | ëŒ“ê¸€ì„ í¬ë¡¤ë§í•´ì„œ ì €ì¥í•˜ëŠ” list |
| list_star | ë³„ì ì„ í¬ë¡¤ë§í•´ì„œ ì €ì¥í•˜ëŠ” list |
| list_date | ì‘ì„±ì¼ìë¥¼ í¬ë¡¤ë§í•´ì„œ ì €ì¥í•˜ëŠ” list |

í•œ í˜ì´ì§€ì— ëŒ“ê¸€ì´ 20ê°œì”© ì¡´ì¬í•˜ë¯€ë¡œ ë°˜ë³µë¬¸(for)ì„ ì„¤ì •í•˜ì—¬ ëŒ“ê¸€ì„ í¬ë¡¤ë§í•œë‹¤.

ìš°ì„  `time.sleep()` í•¨ìˆ˜ë¡œ 1ì´ˆ ì§€ì—°ì‹œê°„ì„ ì„¤ì •í•œë‹¤. ì´ëŠ” í¬ë¡¤ëŸ¬ê°€ ë‹¤ìŒ ëŒ“ê¸€ì„ í¬ë¡¤ë§ í•˜ê¸° ìœ„í•´ ì´ë™í•  ë•Œ ë°œìƒí•˜ëŠ” ì§€ì—°ì„ ê³ ë ¤í•˜ì—¬ ì„¤ì •í•˜ì˜€ë‹¤.

`driver.find_element` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ê²½ë¡œë¥¼ í†µí•´ ëŒ“ê¸€ì„ í¬ë¡¤ë§ í•´ì˜¨ë‹¤.

![Untitled](img/Untitled%2022.png)

![Untitled](img/Untitled%2023.png)

ë§Œì•½ ìœ„ ì‚¬ì§„ê³¼ ê°™ì´ ëŒ“ê¸€ì˜ ì•ë¶€ë¶„ì— â€œí•œë‹¬ì‚¬ìš©ê¸°, ì¬êµ¬ë§¤+í•œë‹¬ì‚¬ìš©ê¸°, ì¬êµ¬ë§¤â€ í‚¤ì›Œë“œê°€ ì•ì— ì¡´ì¬í•˜ëŠ” ê²½ìš°, ifë¬¸ì„ í™œìš©í•˜ì—¬ í‚¤ì›Œë“œê°€ ì•„ë‹Œ ëŒ“ê¸€ì„ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ í¬ë¡¤ë§ ê²½ë¡œë¥¼ ìˆ˜ì •í•œë‹¤. ë³„ì ê³¼ ì‘ì„±ì¼ìëŠ” ì¶”ê°€ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë¯€ë¡œ ì¶”ê°€ ì¡°ê±´ ì—†ì´ í¬ë¡¤ë§ì„ ì§„í–‰í•˜ì—¬ liss, lisss ë¦¬ìŠ¤íŠ¸ì— ì¶”ì¶œí•œ ê°’ì„ ë„£ëŠ”ë‹¤.

- Kafkaì— ì¶”ì¶œê°’ í¼ë¸”ë¦¬ì‹±(ì „ì†¡)

```python
tmp={'star':star.pop(), 'comment':comment.pop(), 'date':date.pop()}
producer.send(topic, value=tmp)

producer.flush()
```

tmp ë”•ì…”ë„ˆë¦¬ì˜ keyë¥¼ í¬ë¡¤ë§ í•œ ìš”ì†Œë“¤ë¡œ ë¼ë²¨ë§í•˜ê³ , pop() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ star, comment, date ë¦¬ìŠ¤íŠ¸ì˜ ë‚´ë¶€ ìš”ì†Œë¥¼ ë”•ì…”ë„ˆë¦¬ì˜ value ê°’ìœ¼ë¡œ ë„£ì–´ì¤€ë‹¤.

`producer.send()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œë“€ì„œëŠ” Kafka ë¸Œë¡œì»¤ì˜ í† í”½ì— tmp ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ì†¡í•œë‹¤.

`producer.flush()` ë¥¼ ì¶”ê°€í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ê°€ ë¯¸í•´ê²° ë©”ì‹œì§€ê°€ ë¸Œë¡œì»¤ì— ì „ë‹¬ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ë„ë¡ ì„¤ì •í•œë‹¤.

- í¬ë¡¤ë§ ì¤‘ì§€

```python
		# í¬ë¡¤ë§ í•  ëŒ“ê¸€ì´ ì—†ì„ ê²½ìš°, í¬ë¡¤ë§ ì„±ê³µ                          
    except NoSuchElementException:
            print("elapsed :", time.time() - start)
            tmp={'status':'Success', 'elapsed':time.time()-start}
            producer.send(topic, value=tmp)
            driver.quit()
  
  # ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ì„ ê²½ìš°, í¬ë¡¤ë§ ì„±ê³µ
  except ElementNotInteractableException:
          print("elapsed :", time.time() - start)
          tmp={'status':'Success', 'elapsed':time.time()-start}
          producer.send(topic,value=tmp)
          driver.quit()

# ê¸°íƒ€ ì˜¤ë¥˜
except:
    tmp={'status':'Failed', 'elapsed':time.time()-start}
    producer.send(topic,value=tmp)
```

ìœ„ì˜ ì½”ë“œë¡œ í¬ë¡¤ë§ì´ ì„±ê³µí•œ ê²½ìš°ë¥¼ ì˜ˆì™¸ì²˜ë¦¬ í•´ì¤€ë‹¤.

í¬ë¡¤ë§ì— ì„±ê³µí•œ ê²½ìš° Successë¥¼ ë°˜í™˜í•˜ê³ , ì‹¤íŒ¨í•œ ê²½ìš° Failedë¥¼ ë°˜í™˜í•œë‹¤.

- í¬ë¡¤ë§ í•  ëŒ“ê¸€ì´ ì—†ì„ ê²½ìš° (ì„±ê³µ)
- ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ì„ ê²½ìš° (ì„±ê³µ)
- ê¸°íƒ€ ì˜¤ë¥˜ (ì‹¤íŒ¨)


# [ SFR-002 ] ëŒ“ê¸€ ë°ì´í„° ì ì¬ ì•Œë¦¼ ì „ì†¡

## Slack ì•Œë¦¼ ì„¤ì •

ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ ì‡¼í•‘ëª° ë³„ë¡œ ë§¤ì¼ ì •í•´ì§„ ì‹œê°„ì— ìˆ˜í–‰ë˜ì–´ì•¼ í•˜ëŠ” ë°°ì¹˜ë“¤ì´ ìˆë‹¤. ì´ ë°°ì¹˜ë“¤ì´ ì‹¤í–‰ë˜ì–´ ë¸Œë¡œì»¤ì— ë°ì´í„°ê°€ ì ì¬ë˜ë©´ Logstash ì»¨ìŠˆë¨¸ì—ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ì™€ Opensearchì— ì ì¬í•˜ê²Œ ëœë‹¤.

ë°ì´í„°ê°€ Logstashë¥¼ í†µí•´ Opensearchì— ì •ìƒì ìœ¼ë¡œ ì ì¬ë˜ì—ˆëŠ”ì§€ ë§¤ì¼ í™•ì¸í•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì— ì•Œë¦¼ì„ì„ ì„¤ì •í•˜ì˜€ë‹¤. Opendistro for elasticsearchì˜ `Alert` ê¸°ëŠ¥ì„ í™œì„±í™”í•˜ê³ , Crawler íŒŒë“œê°€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ ìŠ¤í† ì–´ì˜ ëª¨ë“  ë¦¬ë·°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ë‹¤ë©´ status í•„ë“œì— Successë¼ëŠ” ë©”ì„¸ì§€ë¥¼ ë³´ë‚´ë„ë¡ ì„¤ì •í•´ë‘ì–´ì•¼ í•œë‹¤.

- **Destination ì„¤ì •**

![Untitled](img/Untitled%2024.png)

![Untitled](img/Untitled%2025.png)

ë¨¼ì € ë©”ì„¸ì§€ë¥¼ ë³´ë‚¼ Destinationì„ ì„¤ì •í•œë‹¤. Name, Type, webhook urlì„ ì…ë ¥í•˜ì—¬ ìƒì„±í•œë‹¤.

- **Monitor ì„¤ì •**

![Untitled](img/Untitled%2026.png)

ëª¨ë‹ˆí„° ìƒì„± í™”ë©´ì— ë“¤ì–´ê°€ì„œ Monitorì˜ ì´ë¦„ì„ ì…ë ¥í•œë‹¤.

![Untitled](img/Untitled%2027.png)

![Untitled](img/Untitled%2028.png)

Define Monitor íƒ­ì—ì„œ Define using exraction queryë¥¼ ì„ íƒí•˜ê³   ì¡°íšŒí•  indexë¥¼ ì„ íƒí•œ í›„, ì–´ë–¤ ì¿¼ë¦¬ë¡œ ì¡°íšŒí•  ì§€ ì…ë ¥í•œë‹¤.  ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” í˜„ì¬ ì‹œê°„ë¶€í„° 2ë¶„ ì´ë‚´ì— ë“¤ì–´ì˜¨ status í•„ë“œ ê°’ ì¤‘ Success ì¸ ê°’ì„ ì¡°íšŒí•˜ë„ë¡ ì„¤ì •í–ˆë‹¤. ì¡°ê±´ì„ ì„¤ì •í•œ ì¿¼ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

**Opendisro-Alerting-Slack**

```json
{
    "size": 0,
    "query": {
        "bool": {
            "filter": [
                {
                    "range": {
                        "timestamp": {
                            "from": "{{period_end}}||+9h-2m",
                            "to": "{{period_end}}||+9h",
                            "include_lower": true,
                            "include_upper": true,
                            "format": "epoch_millis",
                            "boost": 1
                        }
                    }
                },
                {
                    "match": {
                        " status": {
                            "query": "Success",
                            "operator": "OR",
                            "prefix_length": 0,
                            "max_expansions": 50,
                            "fuzzy_transpositions": true,
                            "lenient": false,
                            "zero_terms_query": "NONE",
                            "auto_generate_synonyms_phrase_query": true,
                            "boost": 1
                        }
                    }
                }
            ],
            "adjust_pure_negative": true,
            "boost": 1
        }
    }
}
```

- range : ë°ì´í„°ê°€ ì¡°íšŒë  ë²”ìœ„ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. í˜„ì¬ ì‹œê°„ë¶€í„° 2ë¶„ ì´ë‚´ì— ë“¤ì–´ì˜¨ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ë„ë¡ ì„¤ì •í–ˆë‹¤. ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ì ì€ opensearchì˜ period_endëŠ” `UTC+0`ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤ëŠ” ì ì´ë‹¤.
    
    ì•ì„œ ì„¤ì •í–ˆë˜ KST Timestampì™€ ì•½ 9ì‹œê°„ì˜ ì°¨ì´ê°€ ìˆê¸° ë•Œë¬¸ì— period_endì— 9ì‹œê°„ì„ ë”í•´ ì‹œê°„ ê°’ì„ ì¡°ì •í•œ í›„ 2ë¶„ì˜ ë²”ìœ„ë¥¼ ì„¤ì •í–ˆë‹¤.
    
- match : status í•„ë“œì— `Success` ë¼ëŠ” ê°’ì„ ì¡°íšŒí•˜ë„ë¡ ì„¤ì •í–ˆë‹¤.

![Untitled](img/Untitled%2029.png)

ë§ˆì§€ë§‰ìœ¼ë¡œ Monitor scheduleì„ ì„¤ì •í•˜ê³  Monitor ì„¤ì •ì„ ë§ˆë¬´ë¦¬í•œë‹¤. `By interval`ë¡œ 1ë¶„ë§ˆë‹¤ ì¡°íšŒí•˜ë„ë¡ ì„¤ì •í–ˆë‹¤.

- **Trigger ì„¤ì •**

Monitor ì„¤ì •ì„ ì™„ë£Œí•œ í›„, Triggerë¥¼ ì„¤ì •í•œë‹¤. Trigger Nameì„ ì…ë ¥í•˜ê³  Trigger Condition í•­ëª©ì„ ì„¤ì •í•œë‹¤. ì •í•´ì§„ ì‹œê°„ ë²”ìœ„ ë‚´ì— ì ì¬ ì„±ê³µ ë©”ì„¸ì§€ê°€ 1ê°œ ì´ìƒ ë°œìƒí•˜ë©´ ì•Œë¦¼ì„ ë°›ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ ì„¤ì •í•œë‹¤.

ì´ê±´ ë¬´ìŠ¨ íŒŒì¼ìˆëŠ”ê±°ì§€

```
ctx.results[0].hits.total.value > 0
```

ë§ˆì§€ë§‰ìœ¼ë¡œ trigger ìƒì„± í™”ë©´ì˜ ì œì¼ í•˜ë‹¨ì— ìˆëŠ” Configure Action ë¶€ë¶„ì„ ì„¤ì •í•œë‹¤. Action Nameì„ ì…ë ¥í•˜ê³  ì•ì„œ ìƒì„±í•œ Destinationì„ ì„ íƒí•œë‹¤. 

Message ì™€ Message Preview í•„ë“œ ì¤‘ê°„ì— ìˆëŠ” ë²„íŠ¼ì„ ëˆŒëŸ¬ Slackìœ¼ë¡œ ë©”ì‹œì§€ê°€ ìˆ˜ì‹  ë˜ëŠ”ì§€ í™•ì¸í•œ í›„ Triggerë¥¼ ìƒì„±í•œë‹¤.

![Untitled](img/Untitled%2030.png)

![Untitled](img/Untitled%2031.png)

ìŠ¬ë™ ë©”ì„¸ì§€ì— ì ì¬ ì™„ë£Œ ì‹œê°„ê³¼ ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” URLì„ ë©”ì„¸ì§€ë¡œ ì„¤ì •í•œë‹¤.

![Untitled](img/Untitled%2032.png)

ì•ŒëŒ ë©”ì„¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.


# [ SFR-003 ] ì˜¨ë¼ì¸ ì‡¼í•‘ëª° ëŒ“ê¸€ì„ ë¶„ì„í•˜ê¸° ìœ„í•œ NLP

## ì½”ë“œ ì‹¤í–‰ ë°©ë²•

### ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í•¨ìˆ˜

ëª¨ë“ˆì„ ì„¤ì¹˜í•´ì•¼ í•˜ëŠ” ëª©ë¡ì€ ì•„ë˜ì™€ ê°™ë‹¤.

Mecab ì„¤ì¹˜ ë°©ë²•ì„ ì œì™¸í•˜ê³ ëŠ” `pip install ...` ìœ¼ë¡œ ì„¤ì¹˜ê°€ ê°€ëŠ¥í•˜ë‹¤.

```python
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import urllib.request
import tensorflow as tf
from hanspell import spell_checker
from collections import Counter
from konlpy.tag import Mecab
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
```

### Mecab ì„¤ì¹˜

Mecabì˜ ê²½ìš° ì–´ëŠ í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì¤‘ ê°€ì¥ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ê°€ì§„ë‹¤. Mecabì€ ì¼ë³¸ì–´ìš© ë¶„ì„ê¸°ë¥¼ í•œêµ­ì–´ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •í•œ ê²ƒì´ë‹¤.

KkmaëŠ” ì•½ 438ì´ˆ, Komoranì€ ì•½ 12ì´ˆ, OktëŠ” ì•½ 46ì´ˆ, Mecabì€ ì•½ 1ì´ˆ ê°€ëŸ‰ì˜ ì‹œê°„ì´ ì†Œìš”ë˜ì—ˆë‹¤. ì†ë„ ë©´ì—ì„œëŠ” Kkmaê°€ ë…ë³´ì ìœ¼ë¡œ ëŠë¦¬ê³ , Mecabì´ ë…ë³´ì ìœ¼ë¡œ ë¹ ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![Untitled](img/Untitled%2033.png)

ì¶œì²˜: 

[[Python] í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì²´í—˜ ë° ë¹„êµ(Okt, Mecab, Komoran, Kkma)](https://soohee410.github.io/compare_tagger)

Mecab ì„¤ì¹˜

```bash
$ wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz
$ tar xvfz mecab-0.996-ko-0.9.2.tar.gz
$ cd mecab-0.996-ko-0.9.2
$ ./configure
$ sudo make
$ sudo make check
$ sudo make install
$ sudo ldconfig
```

Mecab-ko-dic ì„¤ì¹˜

```bash
$ wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz
$ tar xvfz mecab-ko-dic-2.1.1-20180720.tar.gz
$ cd mecab-ko-dic-2.1.1-20180720
$ ./configure
$ sudo make
$ sudo make install
```

## ì½”ë“œ ìƒì„¸ ì„¤ëª…

íŒŒì¼ëª… : `Naver_Shopping_Review_Sentiment_Analysis.ipynb`

```python
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import urllib.request
import boto3
from smart_open import smart_open
from collections import Counter
from konlpy.tag import Mecab
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.python.client import device_lib

# GPUê°€ tensorflow ì—°ì‚°ì— í™œìš© ê°€ëŠ¥í•œì§€ ì²´í¬
device_lib.list_local_devices()
tf.test.is_gpu_available()

# S3ì— ì €ì¥ëœ TXT íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
session = boto3.Session(profile_name='default')
s3 = session.resource('s3')
bucket = s3.Bucket('potatoes3')
with smart_open('s3://potatoes3/naver_shopping.txt', 'rt', encoding='UTF8') as f2:
    data=f2.read()

total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])

# í‰ì ì´ 4, 5ì¸ ë¦¬ë·°ì—ëŠ” ë ˆì´ë¸” 1ì„, í‰ì ì´ 1, 2ì¸ ë¦¬ë·°ì—ëŠ” ë ˆì´ë¸” 0ì„ ë¶€ì—¬
total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)

# ê° ì—­ì— ëŒ€í•´ì„œ ì¤‘ë³µì¸ ìƒ˜í”Œ ë°ì´í„° ì‚­ì œ
total_data.drop_duplicates(subset=['reviews'], inplace=True)

# í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ 3:1 ë¹„ìœ¨ë¡œ ë¶„ë¦¬
train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state = 42)

# ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì œì™¸í•˜ê³  ëª¨ë‘ ì œê±°
train_data['reviews'] = train_data['reviews'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","")
train_data['reviews'].replace('', np.nan, inplace=True)

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œë„ ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ í•œê¸€ì„ ì œì™¸í•˜ê³  ëª¨ë‘ ì œê±°
# ì¤‘ë³µ ì œê±°
test_data.drop_duplicates(subset = ['reviews'], inplace=True) 
# ì •ê·œ í‘œí˜„ì‹ ìˆ˜í–‰
test_data['reviews'] = test_data['reviews'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","") 
# ê³µë°±ì€ Null ê°’ìœ¼ë¡œ ë³€ê²½
test_data['reviews'].replace('', np.nan, inplace=True) 
# Null ê°’ ì œê±°
test_data = test_data.dropna(how='any') 

#í˜•íƒœì†Œ ë¶„ì„ê¸° Mecab
from eunjeon import Mecab
mecab = Mecab()

# ë¶ˆìš©ì–´ë¥¼ ì§€ì •í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‚´ í•„ìš”ì—†ëŠ” í† í°ë“¤ì„ ì œê±°
stopwords = ['ë„', 'ëŠ”', 'ë‹¤', 'ì˜', 'ê°€', 'ì´', 'ì€', 'í•œ', 'ì—', 'í•˜', 'ê³ ', 'ì„', 'ë¥¼', 'ì¸', 'ë“¯', 'ê³¼', 'ì™€', 'ë„¤', 'ë“¤', 'ë“¯', 'ì§€', 'ì„', 'ê²Œ']

train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)
train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])
test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)
test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])

X_train = train_data['tokenized'].values
y_train = train_data['label'].values
X_test= test_data['tokenized'].values
y_test = test_data['label'].values

# ê¸°ê³„ê°€ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í›ˆë ¨ ë°ì´í„°ì™€ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ì •ìˆ˜ ì¸ì½”ë”© ìˆ˜í–‰
tokenizer = Tokenizer()
tokenizer.fit_on_texts(X_train)

# ë‹¨ì–´ ì§‘í•©ì´ ìƒì„±ë˜ëŠ” ë™ì‹œì— ê° ë‹¨ì–´ì— ê³ ìœ í•œ ì •ìˆ˜ ë¶€ì—¬
# ë“±ì¥ íšŸìˆ˜ê°€ 1íšŒì¸ ë‹¨ì–´ë“¤ì€ ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë°°ì œ

threshold = 2
total_cnt = len(tokenizer.word_index) # ë‹¨ì–´ì˜ ìˆ˜
rare_cnt = 0 # ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ì€ ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ ì¹´ìš´íŠ¸
total_freq = 0 # í›ˆë ¨ ë°ì´í„°ì˜ ì „ì²´ ë‹¨ì–´ ë¹ˆë„ìˆ˜ ì´ í•©
rare_freq = 0 # ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ì€ ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„ìˆ˜ì˜ ì´ í•©

# ë‹¨ì–´ì™€ ë¹ˆë„ìˆ˜ì˜ ìŒ(pair)ì„ keyì™€ valueë¡œ ë°›ëŠ”ë‹¤.
for key, value in tokenizer.word_counts.items():
    total_freq = total_freq + value

    # ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„ìˆ˜ê°€ thresholdë³´ë‹¤ ì‘ìœ¼ë©´
    if(value < threshold):
        rare_cnt = rare_cnt + 1
        rare_freq = rare_freq + value

print('ë‹¨ì–´ ì§‘í•©(vocabulary)ì˜ í¬ê¸° :',total_cnt)
print('ë“±ì¥ ë¹ˆë„ê°€ %së²ˆ ì´í•˜ì¸ í¬ê·€ ë‹¨ì–´ì˜ ìˆ˜: %s'%(threshold - 1, rare_cnt))
print("ë‹¨ì–´ ì§‘í•©ì—ì„œ í¬ê·€ ë‹¨ì–´ì˜ ë¹„ìœ¨:", (rare_cnt / total_cnt)*100)
print("ì „ì²´ ë“±ì¥ ë¹ˆë„ì—ì„œ í¬ê·€ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ë¹„ìœ¨:", (rare_freq / total_freq)*100)

# ë‹¨ì–´ ì§‘í•© í¬ê¸°ë¥¼ í† í¬ë‚˜ì´ì €ì˜ ì¸ìë¡œ ë„˜ê²¨ì£¼ê³ , í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜
# ì •ìˆ˜ ì¸ì½”ë”© ê³¼ì •ì—ì„œ ì´ë³´ë‹¤ í° ìˆ«ìê°€ ë¶€ì—¬ëœ ë‹¨ì–´ë“¤ì€ OOVë¡œ ë³€í™˜

# ì „ì²´ ë‹¨ì–´ ê°œìˆ˜ ì¤‘ ë¹ˆë„ìˆ˜ 2ì´í•˜ì¸ ë‹¨ì–´ ê°œìˆ˜ëŠ” ì œê±°.
# 0ë²ˆ íŒ¨ë”© í† í°ê³¼ 1ë²ˆ OOV í† í°ì„ ê³ ë ¤í•˜ì—¬ +2
vocab_size = total_cnt - rare_cnt + 2
print('ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸° :',vocab_size)

tokenizer = Tokenizer(vocab_size, oov_token = 'OOV') 
tokenizer.fit_on_texts(X_train)
X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)

# íŒ¨ë”©
# ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ìƒ˜í”Œë“¤ì˜ ê¸¸ì´ë¥¼ ë™ì¼í•˜ê²Œ ë§ì¶°ì£¼ëŠ” ì‘ì—…
def below_threshold_len(max_len, nested_list):
  count = 0
  for sentence in nested_list:
    if(len(sentence) <= max_len):
        count = count + 1
  print('ì „ì²´ ìƒ˜í”Œ ì¤‘ ê¸¸ì´ê°€ %s ì´í•˜ì¸ ìƒ˜í”Œì˜ ë¹„ìœ¨: %s'%(max_len, (count / len(nested_list))*100))

max_len = 80
below_threshold_len(max_len, X_train)

# í›ˆë ¨ìš© ë¦¬ë·°ì˜ 99.99ê°€ 80ì´í•˜ì˜ ê¸¸ì´ë¥¼ ê°€ì§€ê¸° ë•Œë¬¸ì—, í›ˆë ¨ìš© ë¦¬ë·°ë¥¼ ê¸¸ì´ 80ìœ¼ë¡œ íŒ¨ë”©
X_train = pad_sequences(X_train, maxlen=max_len)
X_test = pad_sequences(X_test, maxlen=max_len)

# GRUë¡œ ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° ê°ì„± ë¶„ë¥˜
# í•˜ì´í¼íŒŒë¼ë¯¸í„°ì¸ ì„ë² ë”© ë°±í„°ì˜ ì°¨ì›ì€ 100, ì€ë‹‰ ìƒíƒœì˜ í¬ê¸°ëŠ” 128ì´ë‹¤. ëª¨ë¸ì€ ë‹¤ëŒ€ì¼ êµ¬ì¡°ì˜ LSTMì„ ì‚¬ìš©í•œë‹¤.
# í•´ë‹¹ ëª¨ë¸ì€ ë§ˆì§€ë§‰ ì‹œì ì—ì„œ ë‘ ê°œì˜ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ë¬¸ì œë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì´ë‹¤.
# ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì˜ ê²½ìš°, ì¶œë ¥ì¸µì— ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ë¯€ë¡œ í™œì„±í™” í•¨ìˆ˜ë¡œëŠ” ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³ , ì†ì‹¤ í•¨ìˆ˜ë¡œ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤.
# í•˜ì´í¼íŒŒë¼ë¯¸í„°ì¸ ë°°ì¹˜ í¬ê¸°ëŠ” 64ì´ë©°, 15 ì—í¬í¬ë¥¼ ìˆ˜í–‰í•œë‹¤.

#EarlyStoppingì€ ê²€ì¦ ë°ì´í„° ì†ì‹¤ì´ ì¦ê°€í•˜ë©´, ê³¼ì í•© ì§•í›„ì´ë¯€ë¡œ ê²€ì¦ ë°ì´í„° ì†ì‹¤ì´ 4íšŒ ì¦ê°€í•˜ë©´ ì •í•´ì§„ ì—í¬í¬ê°€ ë„ë‹¬í•˜ì§€ ëª»í•˜ì˜€ë”ë¼ë„ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œí•œë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.
#ModelCheckpointë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ì¦ ë°ì´í„°ì˜ ì •í™•ë„ê°€ ì´ì „ë³´ë‹¤ ì¢‹ì•„ì§ˆ ê²½ìš°ì—ë§Œ ëª¨ë¸ì„ ì €ì¥í•œë‹¤.
#validation_split=0.2ì„ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ì˜ 20%ë¥¼ ê²€ì¦ ë°ì´í„°ë¡œ ë¶„ë¦¬í•´ì„œ ì‚¬ìš©í•˜ê³ , ê²€ì¦ ë°ì´í„°ë¥¼ í†µí•´ì„œ í›ˆë ¨ì´ ì ì ˆíˆ ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•œë‹¤.
# ê²€ì¦ ë°ì´í„°ëŠ” ê¸°ê³„ê°€ í›ˆë ¨ ë°ì´í„°ì— ê³¼ì í•©ë˜ê³  ìˆëŠ”ì§€ ì•Šì€ì§€ í™•ì¸í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ì‚¬ìš©ëœë‹¤.

from tensorflow.keras.layers import Embedding, Dense, GRU
from tensorflow.keras.models import Sequential
from tensorflow.keras.models import load_model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
    
embedding_dim = 100
hidden_units = 128

model = Sequential()
model.add(Embedding(vocab_size, embedding_dim))
model.add(GRU(hidden_units))
model.add(Dense(1, activation='sigmoid'))

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)
mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])
history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)

loaded_model = load_model('best_model.h5')
print("\n í…ŒìŠ¤íŠ¸ ì •í™•ë„: %.4f" % (loaded_model.evaluate(X_test, y_test)[1]))

# ì„ì˜ì˜ ë¬¸ì¥ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìœ„í•´ì„œëŠ” í•™ìŠµí•˜ê¸° ì „ ì „ì²˜ë¦¬ë¥¼ ë™ì¼í•˜ê²Œ ì ìš©í•´ì¤€ë‹¤. ì „ì²˜ë¦¬ì˜ ìˆœì„œëŠ” ì •ê·œ í‘œí˜„ì‹ì„ í†µí•œ í•œêµ­ì–´ ì™¸ ë¬¸ì ì œê±°, í† í°í™”, ë¶ˆìš©ì–´ ì œê±°, ì •ìˆ˜ ì¸ì½”ë”©, íŒ¨ë”© ìˆœì´ë‹¤.
def sentiment_predict(new_sentence):
  new_sentence = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£ ]','', new_sentence)
  new_sentence = mecab.morphs(new_sentence)
  new_sentence = [word for word in new_sentence if not word in stopwords]
  encoded = tokenizer.texts_to_sequences([new_sentence])
  pad_new = pad_sequences(encoded, maxlen = max_len)

  score = float(loaded_model.predict(pad_new))
  if(score > 0.5):
    print("{:.2f}% í™•ë¥ ë¡œ ê¸ì • ë¦¬ë·°ì…ë‹ˆë‹¤.".format(score * 100))
    return 1
  else:
    print("{:.2f}% í™•ë¥ ë¡œ ë¶€ì • ë¦¬ë·°ì…ë‹ˆë‹¤.".format((1 - score) * 100))
    return 0
```

`ES_to_Jupyter.ipynb`

```python
import pandas as pd
from elasticsearch import Elasticsearch
from pandas.io.json import json_normalize
import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)
import datetime

# í† í”½ë³„ë¡œ DataFrame ìƒì„±
goodnara = pd.DataFrame()

# ElasticSearchì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
headers = {'Content-type': 'application/json'}
es = Elasticsearch('http://43.200.70.69:30000', headers = headers)
doc={"query":{"match_all":{}}}
res=es.search(index="smartstore.goodnara.review-220803", body=doc, size=50000)
for doc in res['hits']['hits']:
    goodnara=goodnara.append(doc['_source'],ignore_index=True)
len(res)

# ë¶„ì„ì— ë¶ˆí•„ìš”í•œ Column ì‚­ì œ
goodnara=goodnara.loc[:, ['comment', 'date', 'star', 'topic']].dropna()

# Date í˜•ì‹ ë³€ê²½
goodnara['date'] = pd.to_datetime(goodnara['date'])
goodnara_date = pd.DataFrame()
year='20'+goodnara['date'].dt.strftime('%d') # to year
month=goodnara['date'].dt.strftime('%m') # to month
day=goodnara['date'].dt.strftime('%Y').str[2:4] # to date
goodnara_date=goodnara_date.append([year, month, day]).T
goodnara_date.columns = ['year', 'month', 'day']
goodnara_date['date'] = goodnara_date['year']+"-"+goodnara_date['month']+'-'+goodnara_date['day']
goodnara_date=goodnara_date.loc[:, ['date']]
goodnara['date']=goodnara_date['date']

for i in goodnara['date']:
    i=datetime.datetime.strptime(i, "%Y-%m-%d").isoformat()

# ì„ì‹œì €ì¥
goodnara.to_csv("goodnara.csv",encoding='utf-8-sig')
```

`Comment_Sentiment_Analysis.ipynb`

```python
# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data1 = pd.read_csv('goodnara.csv')
data2 = pd.read_csv('drstyle.csv')
data3 = pd.read_csv('thecheaper.csv')
data4 = pd.read_csv('theshopsw.csv')
data5 = pd.read_csv('cloony.csv')
data6 = pd.read_csv('store180.csv')
data=pd.concat([data1, data2, data3, data4, data5, data6], ignore_index=True)
data=data.loc[:, ['comment', 'date', 'star', 'topic']].dropna()

# í•œêµ­ì–´ ë§ì¶¤ë²• ê²€ì‚¬
for i in range(len(data)):
    sent = data['comment'][i]
    spelled_sent = spell_checker.check(sent)
    hanspell_sent = spelled_sent.checked
    data['comment'][i] = hanspell_sent

# ì¤‘ë³µ ì œê±°
data.drop_duplicates(subset = ['comment'], inplace=True, ignore_index=True) 
# ì •ê·œ í‘œí˜„ì‹ ìˆ˜í–‰
data['comment'] = data['comment'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]","") 
# ê³µë°±ì€ Null ê°’ìœ¼ë¡œ ë³€ê²½
data['comment'].replace('', np.nan, inplace=True) 
# Null ê°’ ì œê±°
data = data.dropna(how='any')

stopwords = ['ë„', 'ëŠ”', 'ë‹¤', 'ì˜', 'ê°€', 'ì´', 'ì€', 'í•œ', 'ì—', 'í•˜', 'ê³ ', 'ì„', 'ë¥¼', 'ì¸', 'ë“¯', 'ê³¼', 'ì™€', 'ë„¤', 'ë“¤', 'ë“¯', 'ì§€', 'ì„', 'ê²Œ']

data=data.reset_index(drop=False)
data=data.loc[:, ['comment', 'date', 'star', 'topic']].dropna()

# ë°ì´í„° ë¼ë²¨ë§
data['label'] = np.select([data.star > 3], ['ê¸ì •'], default='ë¶€ì •')
data['new_label']=None
data['tokenized_comment']=None

for i in range(len(data)):
        
    # ê°ì„±ë¶„ì„
    sp = sentiment_predict(data['comment'][i])
    if sp == 1:
        data['new_label'][i] = 'ê¸ì •'
    elif sp == -1:
        data['new_label'][i] = 'ë¶€ì •'
    elif sp == 0:
        data['new_label'][i] = 'ì¤‘ë¦½'
    
    # ëŒ“ê¸€ í† í°í™”
    data['tokenized_comment'][i] = mecab.nouns(data['comment'][i])
```

`Jupyter_to_ES.ipynb`

```python
from elasticsearch import Elasticsearch
def insertData(tokenized_comment, date, star, topic, label, new_label):
    headers = {'Content-type': 'application/json'}
    es = Elasticsearch('http://43.200.70.69:30000', headers = headers)
    
    index="analyzed_data"
    
    doc = {
        "Name": topic,
        "Star": star,
        "Date": date,
        "Word": tokenized_comment,
        "Sentiment": label,
        "Adjustment-sentiment": new_label
    }
    
    es.index(index="analyzed_data", doc_type="_doc", body=doc)

for i in range(len(data)):
    insertData(data['tokenized_comment'][i], data['date'][i], data['star'][i], data['topic'][i], data['label'][i], data['new_label'][i])
```

## ëª¨ë¸ ê²€ì¦

GRUë¡œ ë„¤ì´ë²„ ì‡¼í•‘ ë¦¬ë·° ê°ì„± ë¶„ë¥˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì¸ ì„ë² ë”© ë°±í„°ì˜ ì°¨ì›ì€ 100, ì€ë‹‰ ìƒíƒœì˜ í¬ê¸°ëŠ” 128ì´ë‹¤. ëª¨ë¸ì€ ë‹¤ëŒ€ì¼ êµ¬ì¡°ì˜ LSTMì„ ì‚¬ìš©í•œë‹¤. í•´ë‹¹ ëª¨ë¸ì€ ë§ˆì§€ë§‰ ì‹œì ì—ì„œ ë‘ ê°œì˜ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ë¬¸ì œë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì´ë‹¤. ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì˜ ê²½ìš°, ì¶œë ¥ì¸µì— ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ë¯€ë¡œ í™œì„±í™” í•¨ìˆ˜ë¡œëŠ” ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê³ , ì†ì‹¤ í•¨ìˆ˜ë¡œ í¬ë¡œìŠ¤ ì—”íŠ¸ë¡œí”¼ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„°ì¸ ë°°ì¹˜ í¬ê¸°ëŠ” 64ì´ë©°, 15 ì—í¬í¬ë¥¼ ìˆ˜í–‰í•œë‹¤.

ë”¥ëŸ¬ë‹ì—ì„œ ì—í¬í¬ëŠ” ì „ì²´ íŠ¸ë ˆì´ë‹ ì…‹ì´ ì‹ ê²½ë§ì„ í†µê³¼í•œ íšŸìˆ˜ì´ë‹¤. ì‹ ê²½ë§ì„ ì—¬ëŸ¬ ë²ˆ í†µê³¼í•˜ë©´ì„œ ì •í™•ë„ê°€ ë†’ì•„ì§ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì‹¤ì œë¡  15 ì—í¬í¬ë¡œ ì„¤ì •ë˜ì–´ ìˆì§€ë§Œ, EarlyStopping ì˜µì…˜ìœ¼ë¡œ ê²€ì¦ ë°ì´í„° ì†ì‹¤ì´ ì¦ê°€í•˜ë©´, ê³¼ì í•© ì§•í›„ì´ë¯€ë¡œ ê²€ì¦ ë°ì´í„° ì†ì‹¤ì´ 4íšŒ ì¦ê°€í•˜ë©´ ì •í•´ì§„ ì—í¬í¬ê°€ ë„ë‹¬í•˜ì§€ ëª»í•˜ì˜€ë”ë¼ë„ í•™ìŠµì„ ì¡°ê¸° ì¢…ë£Œí•œë‹¤.

![Untitled](img/Untitled%2034.png)

![Untitled](img/Untitled%2035.png)

## ëª¨í˜¸í•œ ëŒ“ê¸€ì˜ ê°ì„±ë¶„ì„

`Customize_Sentiment_Result.ipynb`

```python
def sentiment_adjustment_manual(new_sentence, i):
  ns = new_sentence
  new_sentence = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£ ]','', new_sentence)
  new_sentence = mecab.morphs(new_sentence)
  new_sentence = [word for word in new_sentence if not word in stopwords]
  encoded = tokenizer.texts_to_sequences([new_sentence])
  pad_new = pad_sequences(encoded, maxlen = max_len)

  score = float(loaded_model.predict(pad_new))
  if(score > 0.4) & (score < 0.6):
    print(ns)
    print('ê¸°ì¡´ ë³„ì : ' + str(data['star'][i]))
    new_label=input('Input Adjustment Data: ')
    return new_label

# ëª¨í˜¸í•œ ê²°ê³¼ ì‚¬ìš©ì ì¡°ì •

for i in range(len(data)):
    sp = sentiment_adjustment_manual(data['comment'][i], i)
    data['new_label'] = sp
print('Done')
```

ê¸Â·ë¶€ì •ì´ ëª¨í˜¸í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” ë¦¬ë·°ì€ ìì²´ íŒë‹¨ í›„ ê¸Â·ë¶€ì •ì„ íƒœê¹…í•œë‹¤.

## ê¸°ì¡´ 20ë§Œê±´ ë°ì´í„°ì— í¬ë¡¤ë§í•œ ë°ì´í„° ì¶”ê°€

`Data_Append.ipynb`

```python
# S3ì—ì„œ 20ë§Œê±´ ë¶ˆëŸ¬ì˜¤ê¸°
session = boto3.Session(profile_name='default')
s3 = session.resource('s3')
bucket = s3.Bucket('potatoes3')
with smart_open('s3://potatoes3/naver_shopping.txt', 'rt', encoding='UTF8') as f2:
    data=f2.read()

total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])

# ì„ì‹œì €ì¥í•œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data1 = pd.read_csv('goodnara.csv')
data2 = pd.read_csv('drstyle.csv')
data3 = pd.read_csv('thecheaper.csv')
data4 = pd.read_csv('theshopsw.csv')
data5 = pd.read_csv('cloony.csv')
data6 = pd.read_csv('store180.csv')
data=pd.concat([data1, data2, data3, data4, data5, data6], ignore_index=True)
data=data.loc[:, ['comment', 'star']].dropna()

data=data.rename(columns={'comment':'reviews', 'star':'ratings'})

# ë™ì¼í•œ í˜•íƒœì˜ Dataframe í•©ì¹˜ê¸°
total_data=pd.concat([total_data, data], ignore_index=True)

# í•©ì¹œ ë°ì´í„° ì„ì‹œ ì €ì¥
file = open("naver_shopping.txt", "w", encoding="UTF-8")
file.write(data)
file.close()

# S3 ì—…ë¡œë“œ
file_name = 'naver_shopping.txt'
bucket='potatoes3'
key='naver_shopping.txt'
s3 = boto3.client('s3')

res = s3.upload_file(file_name, bucket, key)
```


# [ SFR-004 ] ì‹œê°í™”ë¥¼ í†µí•œ ëŒ€ì‹œë³´ë“œ ìƒì„±

## **ì¸ë±ìŠ¤ íŒ¨í„´ ì¶”ê°€**

ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ì„ ìœ„í•œ visualizationë¥¼ ë§Œë“¤ê¸° ì „ì— Kibanaì— `ì¸ë±ìŠ¤ íŒ¨í„´`ì„ ì„¤ì •í•´ì•¼ í•œë‹¤. ì¸ë±ìŠ¤ íŒ¨í„´ì€ ê²€ìƒ‰ ë° ë¶„ì„ì„ ì‹¤í–‰í•˜ëŠ” `opensearch Index`ë¥¼ ì‹ë³„í•˜ê±°ë‚˜ í•„ë“œë¥¼ ì„¤ì •í•˜ëŠ”ë° ì‚¬ìš©í•œë‹¤. ì¸ë±ìŠ¤ íŒ¨í„´ì€ ì—¬ëŸ¬ ì¸ë±ìŠ¤ì— ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ì„ íƒì  `ì™€ì¼ë“œ ì¹´ë“œ`ë¥¼ í¬í•¨í•œ ë¬¸ìì—´ì´ë‹¤.

![Untitled](img/Untitled%2036.png)

Kibanaì— ì ‘ì†í•´ì„œ `Discover` íƒ­ì— ë“¤ì–´ê°€ë©´ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ íŒ¨í„´ì„ ì¶”ê°€í•  ìˆ˜ ìˆë‹¤. 

![Untitled](img/Untitled%2037.png)

ì¸ë±ìŠ¤ íŒ¨í„´ì„ `smartstore*`ë¡œ ì„¤ì •í•œë‹¤.

![Untitled](img/Untitled%2038.png)

![Untitled](img/Untitled%2039.png)

time fieldë¥¼ timestampë¡œ ì„¤ì •í•˜ê³  ìƒì„± ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì„±ê³µì ìœ¼ë¡œ ì¸ë±ìŠ¤ íŒ¨í„´ì´ ìƒì„±ëœë‹¤.

![Untitled](img/Untitled%2040.png)

ì¸ë±ìŠ¤ íŒ¨í„´ì´ ìƒì„±ë˜ë©´ Kibanaì˜ Discovery íƒ­ì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ë¡œê·¸ë“¤ì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.

## ìì—°ì–´ ì²˜ë¦¬ ë°ì´í„° ì¸ë±ìŠ¤ ìƒì„±

Jupyter Notebook ì—ì„œ ìì—°ì–´ ì²˜ë¦¬ ëœ ë°ì´í„°ë¡œ ì‹œê°í™”ë¥¼ ì§„í–‰í•œë‹¤. ë¶„ì„ ë°ì´í„°ë¥¼ ë‹´ì„ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•œë‹¤.

```json
## ë¶„ì„ê²°ê³¼ ì¸ë±ìŠ¤ mapping ì„¤ì •
PUT analyzed_data
{
  "settings": {
    "number_of_shards": 5,
    "number_of_replicas": 3
  }, 
  "mappings": {
    "properties": {
      "Name" : {
        "type": "keyword"
      },
      "Star" : {
        "type": "long"
      },
      "Date" : {
        "type" : "date"
      },
      "Word" : {
        "type": "keyword"
      },
      "Sentiment" : {
        "type" : "keyword"
      },
      "Adjustment-sentiment" : {
        "type" : "keyword"
      }
    }
  }
}
```

- number_of_shards : í•´ë‹¹ ì¸ë±ìŠ¤ì˜ í”„ë¼ì´ë¨¸ë¦¬ ìƒ¤ë“œì˜ ìˆ˜
- number_of_replicas : í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ë³µì œë³¸ ìƒ¤ë“œì˜ ìˆ˜
- properties : í•„ë“œì˜ ì´ë¦„ê³¼ ë°ì´í„° íƒ€ì… (RDBMSì˜ schemaì— í•´ë‹¹)
    
    
    | Field | Descriptions | Type |
    | --- | --- | --- |
    | Name | ì‡¼í•‘ëª° ì´ë¦„ | keyword |
    | Star | í‰ì  | long |
    | Date | ë¦¬ë·° ì‘ì„±ì¼ | date |
    | Word | í† í°í™” ëœ ë¦¬ë·° ë‹¨ì–´ | keyword |
    | Sentiment | ì¡°ì • ì „ ê°ì„± ë¶„ì„ ê²°ê³¼ (ê¸ì •, ë¶€ì •) | keyword |
    | Adjustment-sentiment | ì¡°ì • í›„ ê°ì„± ë¶„ì„ ê²°ê³¼ (ê¸ì •, ë¶€ì •) | keyword |

## 2.4.3. ì •ìƒ ì‘ë™í™•ì¸

**í¬ë¡¤ë§**

![Untitled](img/Untitled%2041.png)

í•œ ì¤„ë¡œ í‘œí˜„ ëœ JSON ë°ì´í„° ë¦¬ìŠ¤íŠ¸ê°€ ì¶”ì¶œëœë‹¤.

**ë°ì´í„° ì ì¬**

![Untitled](img/Untitled%2042.png)

ë°ì´í„° ì •ì œë‹¨ì—ì„œ Opensearchë¡œ ì‡¼í•‘ëª° ë¦¬ë·° ë°ì´í„°ê°€ ì ì¬ë˜ê³ 

Jupyter Notebookì—ì„œ Opensearchë¡œ ì‡¼í•‘ëª° ë¦¬ë·° ê°ì„± ë¶„ì„ ë°ì´í„°ê°€ ì ì¬ëœë‹¤.

**ë¦¬ë·° NLP**

![Untitled](img/Untitled%2043.png)

Jupyter Notebookì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° í•™ìŠµ ëª¨ë¸ì— ë¦¬ë·°ë¥¼ ì…ë ¥í•˜ì—¬ ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. í•´ë‹¹ ë°ì´í„° ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì‡¼í•‘ëª° ë¦¬ë·°ì˜ ê°ì„± ë¶„ì„ì„ ì§„í–‰í•œë‹¤.

**ìŠ¬ë™ ì•Œë¦¼**

![Untitled](img/Untitled%2044.png)

Opensearchì— ë°ì´í„° ì ì¬ ì™„ë£Œ ì‹œ Slackìœ¼ë¡œ ì•Œë¦¼ ë©”ì‹œì§€ê°€ ì „ì†¡ëœë‹¤.

**ëŒ€ì‹œë³´ë“œ**

![Untitled](img/Untitled%2045.png)

ì‡¼í•‘ëª° ì œí’ˆì˜ ì´ë¯¸ì§€ì™€ ìì‚¬ ê¸ì • í‚¤ì›Œë“œ(íƒœê·¸ í´ë¼ìš°ë“œ), ìì‚¬ ë¶€ì • í‚¤ì›Œë“œ (íƒœê·¸ í´ë¼ìš°ë“œ), íƒ€ì‚¬ ê¸ì • í‚¤ì›Œë“œ(íƒœê·¸ í´ë¼ìš°ë“œ), ìì‚¬ ìƒìœ„ í‚¤ì›Œë“œ ì¹´ìš´íŠ¸ ë°ì´í„° í…Œì´ë¸”, íƒ€ì‚¬ ìƒìœ„ í‚¤ì›Œë“œ ì¹´ìš´íŠ¸ ë°ì´í„° í…Œì´ë¸”, ê¸Â·ë¶€ì • ì¶”ì´ ê·¸ë˜í”„ë¥¼ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

# 3. ê²°ë¡ 


## 3.1. ê²°ê³¼ë¬¼ í™œìš© ë°©ì•ˆ

í•œêµ­ ì†Œë¹„ì ì—°ë§¹ì— ë”°ë¥´ë©´ ì¸í„°ë„· ì‡¼í•‘ëª° ì†Œë¹„ìë“¤ì˜ 97.2%ê°€ ì œí’ˆ êµ¬ë§¤ ì‹œ ë¦¬ë·°ë¥¼ ì°¸ê³ í•˜ì—¬ ì œí’ˆì„ êµ¬ë§¤í•œë‹¤. ê·¸ë¦¬ê³  ì œí’ˆì´ ì•„ë¬´ë¦¬ ì¢‹ì•„ ë³´ì—¬ë„ ë¦¬ë·°ê°€ ì¢‹ì§€ ì•Šìœ¼ë©´ 96.7%ê°€ ì œí’ˆì„ êµ¬ë§¤í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ì²˜ëŸ¼ ì¸í„°ë„· ì‡¼í•‘ëª°ì„ ìš´ì˜í•˜ëŠ”ë° ì¤‘ìš”í•œ ìš”ì†Œì¸ ë¦¬ë·°ë¥¼ í•´ë‹¹ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ì‰½ê²Œ ê´€ë¦¬ í•  ìˆ˜ ìˆë‹¤. ê°ì„± ë¶„ì„ì„ í†µí•´ ë¶€ì •ì ì¸ ë¦¬ë·° ë° ì‡¼í•‘ëª°ì˜ ê°•ì ë„ íŒŒì•…í•˜ë©° ê²½ìŸì‚¬ë“¤ì˜ ë¦¬ë·°ê¹Œì§€ í•œëˆˆì— íŒŒì•…í•˜ë©° ì¼ì ë³„ë¡œ ì¶”ì -ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.

## 3.2. **ë°œìƒ ë¬¸ì œ(ì—ëŸ¬) ë° í•´ê²° ë°©ì•ˆ**

**ğŸ’¡ í¬ë¡¤ë§ ì½”ë“œ ì‘ë™ ì˜¤ë¥˜**


- **ì˜¤ë¥˜ ë° ì›ì¸**
    
    í¬ë¡¤ë§í•˜ëŠ” ë°ì´í„° ì–‘ì´ ë°©ëŒ€í•´ì§ˆ ê²½ìš° íŠ¹ì • ì‚¬ì´íŠ¸ì—ì„œì˜ IP ì°¨ë‹¨
    
    ì´ëŸ° ê²½ìš° í•´ë‹¹ ì„œë²„ì— ë¶€í•˜ê°€ ê±¸ë¦´ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í¬ë¡¤ë§ í™œë™ì„ ì°¨ë‹¨í•˜ê²Œ ëœë‹¤. ë˜í•œ í•œë™ì•ˆ í•´ë‹¹ ì‚¬ì´íŠ¸ì— ì ‘ì†ì´ ë¶ˆê°€ëŠ¥í•´ì§„ë‹¤.
    

- **í•´ê²° ë°©ë²•**
    
    íŒŒì´ì¬ì˜ time.sleep() ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì¤‘ê°„ì— ì§€ì—°ì‹œê°„ì„ ë‘ê²Œ í•œë‹¤.
    
    í¬ë¡¤ëŸ¬ê°€ ë‹¤ìŒ ëŒ“ê¸€ í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ê¸° ìœ„í•´ ë„˜ì–´ê°ˆ ë•Œ ë°œìƒí•˜ëŠ” ì§€ì—°ì„ ê³ ë ¤í•˜ì—¬ 1ì´ˆë¡œ ì„¤ì •
    


**ğŸ’¡ OOMKilled ì˜¤ë¥˜ë¡œ ì¸í•œ í¬ë¡¤ëŸ¬ íŒŒë“œ ê°•ì œ ì¢…ë£Œ**

- **ì˜¤ë¥˜ ë° ì›ì¸**
    
    ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ì—¬ íŒŒë“œë¥¼ ê°•ì œ ì¢…ë£Œ
    

- **í•´ê²° ë°©ë²•**
ê¸°ë³¸ì ìœ¼ë¡œ BestEffort â†’ Burstable â†’ Guranteed ìˆœì„œë¡œ ì¢…ë£Œëœë‹¤. 
ê°€ìš© ë©”ëª¨ë¦¬ëŠ” `Podì˜ ì‚¬ìš©ì¤‘ì¸ ë©”ëª¨ë¦¬ / í•œê³„ ë©”ëª¨ë¦¬ * 100%`ë¡œ ê³„ì‚°ëœë‹¤.
    
    
    Guranteed QoS í´ë˜ìŠ¤ê°€ í• ë‹¹ë˜ëŠ” íŒŒë“œë¥¼ ìƒì„±í•˜ì˜€ë‹¤. ì „ì œ ì¡°ê±´ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
    
    - íŒŒë“œ ë‚´ ëª¨ë“  ì»¨í…Œì´ë„ˆëŠ” ë©”ëª¨ë¦¬ ìƒí•œê³¼ ë©”ëª¨ë¦¬ ìš”ì²­ëŸ‰ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•œë‹¤.
    - íŒŒë“œ ë‚´ ëª¨ë“  ì»¨í…Œì´ë„ˆì˜ ë©”ëª¨ë¦¬ ìƒí•œì´ ë©”ëª¨ë¦¬ ìš”ì²­ëŸ‰ê³¼ ì¼ì¹˜í•´ì•¼ í•œë‹¤.
    - íŒŒë“œ ë‚´ ëª¨ë“  ì»¨í…Œì´ë„ˆëŠ” CPU ìƒí•œê³¼ CPU ìš”ì²­ëŸ‰ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•œë‹¤.
    - íŒŒë“œ ë‚´ ëª¨ë“  ì»¨í…Œì´ë„ˆì˜ CPU ìƒí•œì´ CPU ìš”ì²­ëŸ‰ê³¼ ì¼ì¹˜í•´ì•¼ í•œë‹¤.
    
    í•´ë‹¹ í¬ë¡¤ëŸ¬ ì»¨í…Œì´ë„ˆëŠ” ë©”ëª¨ë¦¬ ìƒí•œì„ ê³¼ ë©”ëª¨ë¦¬ ìš”ì²­ëŸ‰ì„ 3000Mi, CPU ìƒí•œê³¼ ìš”ì²­ëŸ‰ì€ 1500më¡œ ì„¤ì •í•˜ì˜€ë‹¤.
    
    ë˜í•œ ë§¤ì¼ 0ì‹œì— ë°°ì¹˜ ì‘ì—… ì§„í–‰í•˜ë©° ë¹„ìš© ì ˆê°ì„ ìœ„í•´ í´ëŸ¬ìŠ¤í„°ë¥¼ t3.medium 6ê°œë¡œ ì˜¤í† ìŠ¤ì¼€ì¼ë§ í•˜ë„ë¡ ì„¤ì •í•˜ì˜€ë‹¤.
    
    (ê¸°ì¡´ 1ê°œì˜ í´ëŸ¬ìŠ¤í„°ì—ì„œ, ë°°ì¹˜ ì‘ì—… ì§„í–‰ì‹œ 6ê°œì˜ í´ëŸ¬ìŠ¤í„°ë¡œ êµ¬ì„±)
    


**ğŸ’¡ í¬ë¡¤ë§ ì§„í–‰ ì¤‘ íŒŒì´ì¬ í¬ë¡¤ëŸ¬  íŒŒë“œ ì¬ë¶€íŒ…**


- **ì˜¤ë¥˜**
    
    í¬ë¡¤ë§ ì§„í–‰ ì¤‘ì¸ íŒŒë“œê°€ ì†Œë©¸ëœ í›„ ë‹¤ì‹œ ì‹œì‘ë˜ëŠ” ì˜¤ë¥˜
    

- **ì›ì¸**
    
    CAì˜ ìŠ¤ì¼€ì¼ ë‹¤ìš´ìœ¼ë¡œ ì¸í•œ ì‘ì—…ì´ ë°°ì •ë˜ì–´ ìˆëŠ” í´ëŸ¬ìŠ¤í„° ìŠ¤ì¼€ì¼ ë‹¤ìš´
    
    ë”°ë¼ì„œ í¬ë¡¤ë§ì´ ì§„í–‰ ì¤‘ì¸ íŒŒë“œê°€ ì†Œë©¸ëœ í›„ ë‹¤ì‹œ ì‹œì‘ë˜ëŠ” ì˜¤ë¥˜ ë°œìƒ
    
- **í•´ê²° ë°©ë²•**
    
    ì•„ë¬´ ì‘ì—…ë„ ë°°ì •ë˜ì§€ ì•Šì€ í´ëŸ¬ìŠ¤í„°ë¥¼ ìŠ¤ì¼€ì¼ ë‹¤ìš´í•˜ë„ë¡ ì„¤ì •í•œë‹¤.
    `"cluster-autoscaler.kubernetes.io/safe-to-evict": "false"` ì„ annotations ë‚´ ì‚½ì…ì„ í†µí•´ CAê°€ íŒŒë“œê°€ ì˜¬ë¼ì™€ìˆëŠ” í´ëŸ¬ìŠ¤í„° ë…¸ë“œë¥¼ ì œê±°í•˜ì§€ ëª»í•˜ë„ë¡ ì„¤ì •í•œë‹¤. 
    

ì°¸ê³ : [https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-types-of-pods-can-prevent-ca-from-removing-a-node](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-types-of-pods-can-prevent-ca-from-removing-a-node)

![Untitled](img/Untitled%2046.png)

**ğŸ’¡ Replication Factor ì—ëŸ¬**

- **ì˜¤ë¥˜**
    
    Kafka ë¸Œë¡œì»¤ì™€ í†µì‹ í•˜ì—¬ í† í”½ ìƒì„± ì‹œ ì¶œë ¥ ë˜ëŠ” ì˜¤ë¥˜
    

```powershell
Error while executing topic command : Replication factor: 1 larger than available brokers: 0.
[2022-07-22 03:19:23,022] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 1 larger than available brokers: 0
```

- **ì›ì¸**
    
    Kafka ì„¤ì •íŒŒì¼(Kafka ì„¤ì¹˜ ë””ë ‰í† ë¦¬ / config / server.properties)ì— ì„¤ì •ë˜ì–´ ìˆëŠ” Zookeeper ì •ë³´ì™€ í† í”½ ìƒì„± ì‹œ ì…ë ¥í•œ Zookeeper ì •ë³´ê°€ ë¶ˆì¼ì¹˜ í•´ì„œ ë°œìƒ
    
- **í•´ê²° ë°©ë²•**
    
    Kafka ì„¤ì • íŒŒì¼ì— ëª…ì‹œë˜ì–´ ìˆëŠ” Zookeeper ì •ë³´ë¥¼ í† í”½ ìƒì„± ëª…ë ¹ì–´ì— ë™ì¼í•˜ê²Œ ì…ë ¥
    

**ğŸ’¡ Zookeeper í´ëŸ¬ìŠ¤í„° ì‹¤í–‰ ì˜¤ë¥˜**


- **ì˜¤ë¥˜**
    
    EC2 3ëŒ€ì— ê°ê° Kafkaì™€ Zookeeperë¥¼ ì„¤ì¹˜í•˜ê³  ì£¼í‚¤í¼ë¥¼ ì‹¤í–‰í•  ë•Œ ì¶œë ¥ ë˜ëŠ” ì˜¤ë¥˜
    

```powershell
I won't be able to participate in leader election any longer Use zookeeper.electionPortBindRetry property to increase retry count. (org.apache.zookeeper.server.quorum.QuorumCnxManager)
```

- **ì›ì¸**
    
    Zookeeper ì„¤ì • íŒŒì¼ì¸ zookeeper.properties íŒŒì¼ì— í•´ë‹¹ ì„œë²„ì˜ ê³µì¸ IPë¥¼ ì„¤ì •í•˜ë©´ í•´ë‹¹ portë¥¼ ì¸ì‹í•˜ì§€ ëª»í•´ì„œ ë°œìƒ
    
- **í•´ê²° ë°©ë²•**
    
    @@ë¥¼ 0.0.0.0:2181ë¡œ ì„¤ì •
    

**ğŸ’¡ Logstash Timestamp UTC ì„¤ì •**

- **ì˜¤ë¥˜**
    
    Opensearchì˜ indexë¥¼ ì¼ ë³„ë¡œ ìƒì„±í•˜ê³  yymmddë¥¼ postfixë¡œ ì„¤ì •í•˜ë ¤ê³  í•  ë•Œ ì˜¤ë¥˜ ë°œìƒ 
    

- **ì›ì¸**
    
    Logstashì˜ TimestampëŠ” UTC+0 ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê¸° ë•Œë¬¸ì— í•œêµ­ì‹œê°„ê³¼ ì•½ 9ì‹œê°„ì˜ ì°¨ì´ê°€ ë°œìƒ
    
- **í•´ê²° ë°©ë²•**
    
    UTC+0 ì„ KST (UTC+9) ë¡œ ë°”ê¿”ì„œ íŒŒì‹±ì— ì‚¬ìš©.
    
    ê¸°ì¡´ timestamp í•„ë“œì— 9ì‹œê°„ì„ ë”í•´ ìƒˆë¡œìš´ timestamp í•„ë“œë¥¼ ìƒì„±í•´ ì‚¬ìš©
    

## 3.3. **í”„ë¡œì íŠ¸ ê²°ê³¼ ë° í–¥í›„ ê°œì„ ì **

### **[Â  í”„ë¡œì íŠ¸ ê²°ê³¼Â  ]**

- EKS ìœ„ì— ë…¸ë“œ ê·¸ë£¹ ìƒì„±í•˜ì—¬ ë¦¬ì†ŒìŠ¤ ë°°í¬ (íŒŒì´ì¬ í¬ë¡¤ëŸ¬, ELK Stack)
- ì›¹ í¬ë¡¤ë§ ë°ì´í„° íì‰
- ë¦¬ë·° ë°ì´í„° ì •ì œ ë° ì¸ë±ì‹±
- ë°ì´í„° ì ì¬
- ë°ì´í„° ê°ì„ ë¶„ì„ ëª¨ë¸ì„ ì´ìš©í•œ ì‡¼í•‘ëª° ë¦¬ë·° ìì—°ì–´ ì²˜ë¦¬
- ë¦¬ë·° ë°ì´í„°ë¥¼ í™œìš©í•œ ì‹œê°í™”

### **[Â  í–¥í›„ ê°œì„ ì Â  ]**

- ë¦¬ë·° ë°ì´í„°ë¥¼ ì¶”ê°€ë¡œ ìˆ˜ì§‘í•˜ì—¬ HDFSë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¶„ì‚° ì²˜ë¦¬
- EKSì—ì„œ Kafka ë°°í¬
- ë°ì´í„° ì „ì†¡ ë‹¨ì˜ ë¡œê·¸ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ìƒì„± (Grafana Dashboard)
- íš¨ìœ¨ì ì¸ í˜‘ì—… íˆ´ ì‚¬ìš©
